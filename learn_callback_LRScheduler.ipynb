{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8acaf3f8-72f5-4777-b905-1992132bae2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T12:50:41.348250Z",
     "iopub.status.busy": "2022-11-21T12:50:41.347590Z",
     "iopub.status.idle": "2022-11-21T12:50:45.595316Z",
     "shell.execute_reply": "2022-11-21T12:50:45.594394Z",
     "shell.execute_reply.started": "2022-11-21T12:50:41.348203Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values [0.001, 0.0001, 1.0000000000000003e-05]\r\n",
      "boundaries [5, 8]\r\n",
      "Epoch 0: PiecewiseDecay set learning rate to 0.001.\r\n",
      "Epoch 0: LinearWarmup set learning rate to 0.0002.\r\n"
     ]
    }
   ],
   "source": [
    "import paddle\r\n",
    "import paddle.vision.transforms as T\r\n",
    "from paddle.static import InputSpec\r\n",
    "\r\n",
    "inputs = [InputSpec([-1, 1, 28, 28], 'float32', 'image')]\r\n",
    "labels = [InputSpec([None, 1], 'int64', 'label')]\r\n",
    "\r\n",
    "transform = T.Compose([\r\n",
    "    T.Transpose(),\r\n",
    "    T.Normalize([127.5], [127.5])\r\n",
    "])\r\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\r\n",
    "eval_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\r\n",
    "lenet = paddle.vision.models.LeNet()\r\n",
    "model = paddle.Model(lenet,\r\n",
    "                     inputs, labels)\r\n",
    "\r\n",
    "base_lr = 1e-3\r\n",
    "boundaries = [5, 8]\r\n",
    "wamup_steps = 4\r\n",
    "\r\n",
    "def make_optimizer(parameters=None):\r\n",
    "    momentum = 0.9\r\n",
    "    weight_decay = 5e-4\r\n",
    "    values = [base_lr * (0.1**i) for i in range(len(boundaries) + 1)]\r\n",
    "    print('values',values)\r\n",
    "    print('boundaries',boundaries)\r\n",
    "    learning_rate = paddle.optimizer.lr.PiecewiseDecay(boundaries=boundaries, values=values,verbose=True)\r\n",
    "    learning_rate = paddle.optimizer.lr.LinearWarmup(\r\n",
    "        learning_rate=learning_rate,\r\n",
    "        warmup_steps=wamup_steps,\r\n",
    "        start_lr=base_lr / 5.,\r\n",
    "        end_lr=base_lr,\r\n",
    "        verbose=True)\r\n",
    "    optimizer = paddle.optimizer.Momentum(\r\n",
    "        learning_rate=learning_rate,\r\n",
    "        weight_decay=weight_decay,\r\n",
    "        momentum=momentum,\r\n",
    "        parameters=parameters)\r\n",
    "    return optimizer\r\n",
    "\r\n",
    "optim = make_optimizer(parameters=lenet.parameters())\r\n",
    "model.prepare(optimizer=optim,\r\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\r\n",
    "              metrics=paddle.metric.Accuracy())\r\n",
    "\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c237ba9b-d2ad-4e63-b5da-27f1a0c58856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T12:50:55.376058Z",
     "iopub.status.busy": "2022-11-21T12:50:55.375409Z",
     "iopub.status.idle": "2022-11-21T12:51:12.290513Z",
     "shell.execute_reply": "2022-11-21T12:51:12.289611Z",
     "shell.execute_reply.started": "2022-11-21T12:50:55.376015Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\r\n",
      "Epoch 1/1\r\n",
      "Epoch 1: LinearWarmup set learning rate to 0.0004.\r\n",
      "Epoch 2: LinearWarmup set learning rate to 0.0006000000000000001.\r\n",
      "Epoch 3: LinearWarmup set learning rate to 0.0008.\r\n",
      "Epoch 0: PiecewiseDecay set learning rate to 0.001.\r\n",
      "Epoch 4: LinearWarmup set learning rate to 0.001.\r\n",
      "Epoch 1: PiecewiseDecay set learning rate to 0.001.\r\n",
      "Epoch 5: LinearWarmup set learning rate to 0.001.\r\n",
      "Epoch 2: PiecewiseDecay set learning rate to 0.001.\r\n",
      "Epoch 6: LinearWarmup set learning rate to 0.001.\r\n",
      "Epoch 3: PiecewiseDecay set learning rate to 0.001.\r\n",
      "Epoch 7: LinearWarmup set learning rate to 0.001.\r\n",
      "Epoch 4: PiecewiseDecay set learning rate to 0.001.\r\n",
      "Epoch 8: LinearWarmup set learning rate to 0.001.\r\n",
      "Epoch 5: PiecewiseDecay set learning rate to 0.0001.\r\n",
      "Epoch 9: LinearWarmup set learning rate to 0.0001.\r\n",
      "step  10/469 - loss: 2.5466 - acc: 0.0867 - 39ms/step\r\n",
      "Epoch 6: PiecewiseDecay set learning rate to 0.0001.\r\n",
      "Epoch 10: LinearWarmup set learning rate to 0.0001.\r\n",
      "Epoch 7: PiecewiseDecay set learning rate to 0.0001.\r\n",
      "Epoch 11: LinearWarmup set learning rate to 0.0001.\r\n",
      "Epoch 8: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 12: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 9: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 13: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 10: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 14: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 11: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 15: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 12: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 16: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 13: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 17: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 14: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 18: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 15: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 19: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step  20/469 - loss: 2.5799 - acc: 0.1359 - 37ms/step\r\n",
      "Epoch 16: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 20: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 17: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 21: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 18: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 22: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 19: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 23: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 20: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 24: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 21: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 25: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 22: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 26: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 23: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 27: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 24: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 28: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 25: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 29: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step  30/469 - loss: 2.3863 - acc: 0.1648 - 36ms/step\r\n",
      "Epoch 26: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 30: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 27: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 31: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 28: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 32: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 29: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 33: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 30: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 34: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 31: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 35: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 32: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 36: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 33: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 37: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 34: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 38: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 35: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 39: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step  40/469 - loss: 2.3923 - acc: 0.1863 - 37ms/step\r\n",
      "Epoch 36: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 40: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 37: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 41: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 38: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 42: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 39: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 43: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 40: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 44: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 41: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 45: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 42: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 46: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 43: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 47: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 44: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 48: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 45: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 49: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step  50/469 - loss: 2.4035 - acc: 0.1945 - 37ms/step\r\n",
      "Epoch 46: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 50: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 47: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 51: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 48: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 52: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 49: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 53: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 50: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 54: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 51: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 55: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 52: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 56: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 53: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 57: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 54: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 58: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 55: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 59: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step  60/469 - loss: 2.5937 - acc: 0.1982 - 36ms/step\r\n",
      "Epoch 56: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 60: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 57: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 61: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 58: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 62: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 59: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 63: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 60: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 64: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 61: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 65: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 62: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 66: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 63: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 67: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 64: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 68: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 65: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 69: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step  70/469 - loss: 2.3397 - acc: 0.2016 - 36ms/step\r\n",
      "Epoch 66: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 70: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 67: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 71: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 68: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 72: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 69: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 73: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 70: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 74: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 71: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 75: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 72: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 76: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 73: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 77: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 74: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 78: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 75: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 79: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step  80/469 - loss: 2.5565 - acc: 0.2039 - 36ms/step\r\n",
      "Epoch 76: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 80: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 77: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 81: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 78: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 82: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 79: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 83: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 80: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 84: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 81: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 85: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 82: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 86: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 83: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 87: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 84: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 88: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 85: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 89: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step  90/469 - loss: 2.4987 - acc: 0.2054 - 36ms/step\r\n",
      "Epoch 86: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 90: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 87: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 91: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 88: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 92: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 89: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 93: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 90: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 94: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 91: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 95: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 92: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 96: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 93: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 97: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 94: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 98: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 95: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 99: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 100/469 - loss: 2.3663 - acc: 0.2080 - 36ms/step\r\n",
      "Epoch 96: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 100: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 97: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 101: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 98: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 102: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 99: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 103: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 100: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 104: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 101: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 105: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 102: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 106: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 103: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 107: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 104: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 108: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 105: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 109: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 110/469 - loss: 2.3360 - acc: 0.2093 - 35ms/step\r\n",
      "Epoch 106: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 110: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 107: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 111: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 108: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 112: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 109: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 113: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 110: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 114: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 111: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 115: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 112: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 116: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 113: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 117: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 114: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 118: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 115: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 119: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 120/469 - loss: 2.1863 - acc: 0.2106 - 36ms/step\r\n",
      "Epoch 116: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 120: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 117: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 121: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 118: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 122: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 119: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 123: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 120: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 124: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 121: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 125: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 122: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 126: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 123: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 127: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 124: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 128: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 125: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 129: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 130/469 - loss: 2.3162 - acc: 0.2143 - 36ms/step\r\n",
      "Epoch 126: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 130: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 127: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 131: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 128: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 132: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 129: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 133: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 130: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 134: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 131: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 135: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 132: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 136: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 133: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 137: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 134: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 138: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 135: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 139: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 140/469 - loss: 2.4765 - acc: 0.2144 - 36ms/step\r\n",
      "Epoch 136: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 140: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 137: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 141: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 138: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 142: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 139: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 143: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 140: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 144: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 141: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 145: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 142: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 146: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 143: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 147: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 144: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 148: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 145: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 149: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 150/469 - loss: 2.2680 - acc: 0.2150 - 36ms/step\r\n",
      "Epoch 146: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 150: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 147: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 151: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 148: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 152: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 149: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 153: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 150: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 154: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 151: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 155: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 152: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 156: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 153: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 157: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 154: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 158: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 155: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 159: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 160/469 - loss: 2.4929 - acc: 0.2162 - 36ms/step\r\n",
      "Epoch 156: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 160: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 157: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 161: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 158: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 162: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 159: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 163: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 160: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 164: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 161: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 165: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 162: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 166: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 163: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 167: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 164: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 168: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 165: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 169: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 170/469 - loss: 2.1955 - acc: 0.2174 - 36ms/step\r\n",
      "Epoch 166: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 170: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 167: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 171: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 168: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 172: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 169: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 173: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 170: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 174: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 171: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 175: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 172: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 176: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 173: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 177: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 174: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 178: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 175: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 179: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 180/469 - loss: 2.6245 - acc: 0.2182 - 36ms/step\r\n",
      "Epoch 176: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 180: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 177: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 181: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 178: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 182: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 179: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 183: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 180: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 184: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 181: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 185: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 182: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 186: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 183: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 187: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 184: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 188: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 185: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 189: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 190/469 - loss: 2.1959 - acc: 0.2193 - 36ms/step\r\n",
      "Epoch 186: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 190: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 187: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 191: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 188: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 192: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 189: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 193: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 190: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 194: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 191: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 195: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 192: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 196: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 193: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 197: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 194: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 198: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 195: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 199: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 200/469 - loss: 2.0991 - acc: 0.2201 - 36ms/step\r\n",
      "Epoch 196: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 200: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 197: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 201: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 198: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 202: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 199: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 203: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 200: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 204: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 201: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 205: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 202: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 206: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 203: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 207: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 204: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 208: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 205: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 209: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 210/469 - loss: 2.2327 - acc: 0.2209 - 36ms/step\r\n",
      "Epoch 206: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 210: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 207: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 211: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 208: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 212: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 209: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 213: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 210: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 214: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 211: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 215: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 212: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 216: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 213: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 217: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 214: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 218: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 215: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 219: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 220/469 - loss: 2.1456 - acc: 0.2221 - 36ms/step\r\n",
      "Epoch 216: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 220: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 217: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 221: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 218: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 222: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 219: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 223: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 220: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 224: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 221: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 225: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 222: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 226: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 223: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 227: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 224: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 228: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 225: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 229: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 230/469 - loss: 2.1473 - acc: 0.2239 - 36ms/step\r\n",
      "Epoch 226: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 230: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 227: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 231: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 228: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 232: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 229: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 233: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 230: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 234: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 231: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 235: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 232: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 236: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 233: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 237: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 234: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 238: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 235: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 239: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 240/469 - loss: 2.2219 - acc: 0.2246 - 36ms/step\r\n",
      "Epoch 236: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 240: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 237: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 241: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 238: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 242: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 239: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 243: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 240: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 244: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 241: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 245: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 242: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 246: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 243: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 247: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 244: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 248: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 245: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 249: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 250/469 - loss: 2.1652 - acc: 0.2265 - 36ms/step\r\n",
      "Epoch 246: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 250: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 247: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 251: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 248: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 252: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 249: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 253: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 250: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 254: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 251: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 255: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 252: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 256: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 253: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 257: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 254: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 258: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 255: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 259: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 260/469 - loss: 2.2752 - acc: 0.2283 - 36ms/step\r\n",
      "Epoch 256: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 260: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 257: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 261: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 258: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 262: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 259: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 263: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 260: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 264: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 261: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 265: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 262: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 266: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 263: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 267: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 264: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 268: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 265: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 269: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 270/469 - loss: 2.1795 - acc: 0.2301 - 36ms/step\r\n",
      "Epoch 266: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 270: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 267: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 271: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 268: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 272: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 269: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 273: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 270: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 274: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 271: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 275: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 272: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 276: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 273: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 277: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 274: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 278: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 275: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 279: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 280/469 - loss: 2.1158 - acc: 0.2308 - 36ms/step\r\n",
      "Epoch 276: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 280: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 277: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 281: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 278: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 282: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 279: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 283: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 280: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 284: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 281: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 285: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 282: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 286: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 283: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 287: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 284: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 288: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 285: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 289: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 290/469 - loss: 2.3627 - acc: 0.2316 - 36ms/step\r\n",
      "Epoch 286: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 290: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 287: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 291: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 288: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 292: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 289: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 293: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 290: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 294: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 291: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 295: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 292: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 296: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 293: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 297: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 294: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 298: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 295: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 299: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 300/469 - loss: 2.1972 - acc: 0.2326 - 36ms/step\r\n",
      "Epoch 296: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 300: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 297: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 301: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 298: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 302: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 299: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 303: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 300: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 304: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 301: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 305: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 302: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 306: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 303: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 307: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 304: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 308: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 305: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 309: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 310/469 - loss: 2.1759 - acc: 0.2332 - 36ms/step\r\n",
      "Epoch 306: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 310: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 307: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 311: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 308: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 312: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 309: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 313: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 310: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 314: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 311: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 315: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 312: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 316: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 313: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 317: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 314: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 318: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 315: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 319: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 320/469 - loss: 2.2850 - acc: 0.2336 - 36ms/step\r\n",
      "Epoch 316: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 320: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 317: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 321: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 318: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 322: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 319: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 323: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 320: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 324: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 321: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 325: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 322: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 326: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 323: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 327: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 324: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 328: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 325: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 329: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 330/469 - loss: 2.1964 - acc: 0.2342 - 36ms/step\r\n",
      "Epoch 326: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 330: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 327: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 331: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 328: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 332: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 329: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 333: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 330: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 334: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 331: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 335: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 332: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 336: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 333: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 337: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 334: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 338: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 335: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 339: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 340/469 - loss: 2.1672 - acc: 0.2353 - 36ms/step\r\n",
      "Epoch 336: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 340: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 337: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 341: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 338: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 342: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 339: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 343: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 340: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 344: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 341: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 345: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 342: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 346: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 343: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 347: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 344: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 348: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 345: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 349: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 350/469 - loss: 2.1108 - acc: 0.2366 - 36ms/step\r\n",
      "Epoch 346: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 350: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 347: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 351: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 348: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 352: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 349: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 353: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 350: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 354: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 351: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 355: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 352: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 356: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 353: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 357: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 354: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 358: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 355: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 359: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 360/469 - loss: 2.1262 - acc: 0.2380 - 36ms/step\r\n",
      "Epoch 356: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 360: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 357: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 361: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 358: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 362: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 359: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 363: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 360: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 364: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 361: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 365: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 362: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 366: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 363: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 367: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 364: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 368: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 365: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 369: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 370/469 - loss: 2.0890 - acc: 0.2399 - 36ms/step\r\n",
      "Epoch 366: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 370: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 367: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 371: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 368: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 372: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 369: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 373: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 370: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 374: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 371: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 375: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 372: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 376: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 373: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 377: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 374: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 378: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 375: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 379: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 380/469 - loss: 2.0440 - acc: 0.2412 - 36ms/step\r\n",
      "Epoch 376: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 380: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 377: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 381: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 378: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 382: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 379: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 383: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 380: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 384: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 381: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 385: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 382: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 386: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 383: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 387: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 384: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 388: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 385: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 389: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 390/469 - loss: 2.1693 - acc: 0.2430 - 36ms/step\r\n",
      "Epoch 386: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 390: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 387: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 391: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 388: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 392: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 389: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 393: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 390: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 394: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 391: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 395: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 392: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 396: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 393: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 397: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 394: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 398: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 395: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 399: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 400/469 - loss: 2.1466 - acc: 0.2442 - 36ms/step\r\n",
      "Epoch 396: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 400: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 397: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 401: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 398: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 402: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 399: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 403: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 400: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 404: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 401: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 405: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 402: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 406: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 403: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 407: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 404: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 408: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 405: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 409: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 410/469 - loss: 2.1045 - acc: 0.2446 - 36ms/step\r\n",
      "Epoch 406: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 410: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 407: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 411: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 408: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 412: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 409: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 413: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 410: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 414: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 411: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 415: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 412: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 416: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 413: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 417: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 414: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 418: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 415: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 419: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 420/469 - loss: 2.1873 - acc: 0.2455 - 36ms/step\r\n",
      "Epoch 416: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 420: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 417: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 421: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 418: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 422: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 419: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 423: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 420: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 424: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 421: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 425: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 422: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 426: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 423: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 427: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 424: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 428: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 425: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 429: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 430/469 - loss: 2.0880 - acc: 0.2469 - 36ms/step\r\n",
      "Epoch 426: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 430: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 427: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 431: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 428: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 432: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 429: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 433: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 430: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 434: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 431: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 435: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 432: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 436: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 433: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 437: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 434: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 438: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 435: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 439: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 440/469 - loss: 2.0551 - acc: 0.2482 - 36ms/step\r\n",
      "Epoch 436: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 440: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 437: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 441: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 438: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 442: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 439: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 443: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 440: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 444: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 441: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 445: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 442: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 446: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 443: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 447: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 444: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 448: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 445: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 449: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 450/469 - loss: 2.0586 - acc: 0.2495 - 36ms/step\r\n",
      "Epoch 446: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 450: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 447: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 451: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 448: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 452: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 449: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 453: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 450: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 454: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 451: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 455: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 452: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 456: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 453: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 457: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 454: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 458: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 455: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 459: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 460/469 - loss: 2.0915 - acc: 0.2505 - 36ms/step\r\n",
      "Epoch 456: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 460: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 457: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 461: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 458: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 462: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 459: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 463: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 460: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 464: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 461: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 465: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 462: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 466: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 463: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 467: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 464: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 468: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 465: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\r\n",
      "Epoch 469: LinearWarmup set learning rate to 1.0000000000000003e-05.\r\n",
      "step 469/469 - loss: 1.9367 - acc: 0.2519 - 36ms/step\r\n"
     ]
    }
   ],
   "source": [
    "# if LRScheduler callback not set, an instance LRScheduler update by step\r\n",
    "# will be created auto.\r\n",
    "callbacks=[]\r\n",
    "model.fit(train_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b728e-f492-4037-b2b3-20540ae085cd",
   "metadata": {},
   "source": [
    "# 以上结果解释\n",
    "最开始看到也是不明白\n",
    "```python\n",
    "base_lr = 1e-3\n",
    "boundaries = [5, 8]\n",
    "wamup_steps = 4\n",
    "\n",
    "def make_optimizer(parameters=None):\n",
    "    momentum = 0.9\n",
    "    weight_decay = 5e-4\n",
    "    values = [base_lr * (0.1**i) for i in range(len(boundaries) + 1)]\n",
    "    print('values',values)\n",
    "    print('boundaries',boundaries)\n",
    "    learning_rate = paddle.optimizer.lr.PiecewiseDecay(boundaries=boundaries, values=values,verbose=True)\n",
    "    learning_rate = paddle.optimizer.lr.LinearWarmup(\n",
    "        learning_rate=learning_rate,\n",
    "        warmup_steps=wamup_steps,\n",
    "        start_lr=base_lr / 5.,\n",
    "        end_lr=base_lr,\n",
    "        verbose=True)\n",
    "```\n",
    "输出结果如下：\n",
    "```plain\n",
    "\n",
    "values [0.001, 0.0001, 1.0000000000000003e-05]\n",
    "boundaries [5, 8]\n",
    "Epoch 0: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 0: LinearWarmup set learning rate to 0.0002.\n",
    "\n",
    "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
    "Epoch 1/1\n",
    "Epoch 1: LinearWarmup set learning rate to 0.0004.\n",
    "Epoch 2: LinearWarmup set learning rate to 0.0006000000000000001.\n",
    "Epoch 3: LinearWarmup set learning rate to 0.0008.\n",
    "Epoch 0: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 4: LinearWarmup set learning rate to 0.001.\n",
    "Epoch 1: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 5: LinearWarmup set learning rate to 0.001.\n",
    "Epoch 2: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 6: LinearWarmup set learning rate to 0.001.\n",
    "Epoch 3: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 7: LinearWarmup set learning rate to 0.001.\n",
    "Epoch 4: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 8: LinearWarmup set learning rate to 0.001.\n",
    "Epoch 5: PiecewiseDecay set learning rate to 0.0001.\n",
    "Epoch 9: LinearWarmup set learning rate to 0.0001.\n",
    "step  10/469 - loss: 2.5466 - acc: 0.0867 - 39ms/step\n",
    "Epoch 6: PiecewiseDecay set learning rate to 0.0001.\n",
    "Epoch 10: LinearWarmup set learning rate to 0.0001.\n",
    "Epoch 7: PiecewiseDecay set learning rate to 0.0001.\n",
    "Epoch 11: LinearWarmup set learning rate to 0.0001.\n",
    "Epoch 8: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\n",
    "Epoch 12: LinearWarmup set learning rate to 1.0000000000000003e-05.\n",
    "```\n",
    "看结果比较奇怪，为何是这种结果？\n",
    "其中LinearWarmup的代码如下：\n",
    "```python\n",
    "def get_lr(self):\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            return (self.end_lr - self.start_lr) * float(\n",
    "                self.last_epoch) / float(self.warmup_steps) + self.start_lr\n",
    "        else:\n",
    "            if isinstance(self.learning_rate, LRScheduler):\n",
    "                lr_value = self.learning_rate()\n",
    "                self.learning_rate.step()\n",
    "                return lr_value\n",
    "\n",
    "            return self.learning_rate\n",
    "\n",
    "```\n",
    "从get_lr可以看到当代数小于预热代数时，也就是4时，学习率是线性预热中定义的线性学习率，0代是2e-4,然后在1、2、3代依次为4e-4、6e-4、8e-4。注意这时候分段学习率PiecewiseDecay仍为0代，和LinearWarmup处于不同代。\n",
    "从4代开始，转到else部分，从PiecewiseDecay取学习率，分段学习率为\n",
    "```plain\n",
    "values [0.001, 0.0001, 1.0000000000000003e-05]\n",
    "boundaries [5, 8]\n",
    "```\n",
    "代数<5为0.001，代数在\\[5,8)之间为e-4，大于8代为e-5。\n",
    "LinearWarmup为4代，PiecewiseDecay为0代，学习率为0.001\n",
    "所以有如下结果\n",
    "```palin\n",
    "Epoch 0: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 4: LinearWarmup set learning rate to 0.001.\n",
    "\n",
    "Epoch 1: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 5: LinearWarmup set learning rate to 0.001.\n",
    "\n",
    "Epoch 2: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 6: LinearWarmup set learning rate to 0.001.\n",
    "\n",
    "Epoch 3: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 7: LinearWarmup set learning rate to 0.001.\n",
    "\n",
    "Epoch 4: PiecewiseDecay set learning rate to 0.001.\n",
    "Epoch 8: LinearWarmup set learning rate to 0.001.\n",
    "\n",
    "Epoch 5: PiecewiseDecay set learning rate to 0.0001.\n",
    "Epoch 9: LinearWarmup set learning rate to 0.0001.\n",
    "\n",
    "Epoch 6: PiecewiseDecay set learning rate to 0.0001.\n",
    "Epoch 10: LinearWarmup set learning rate to 0.0001.\n",
    "\n",
    "Epoch 7: PiecewiseDecay set learning rate to 0.0001.\n",
    "Epoch 11: LinearWarmup set learning rate to 0.0001.\n",
    "\n",
    "Epoch 8: PiecewiseDecay set learning rate to 1.0000000000000003e-05.\n",
    "Epoch 12: LinearWarmup set learning rate to 1.0000000000000003e-05.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a24a402-70df-4ee5-8386-745c8c1143f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-21T12:51:12.307101Z",
     "iopub.status.busy": "2022-11-21T12:51:12.306741Z",
     "iopub.status.idle": "2022-11-21T12:51:33.691197Z",
     "shell.execute_reply": "2022-11-21T12:51:33.690354Z",
     "shell.execute_reply.started": "2022-11-21T12:51:12.307076Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values [0.001, 0.0001, 1.0000000000000003e-05]\r\n",
      "boundaries [5, 8]\r\n",
      "Epoch 0: PiecewiseDecay set learning rate to 0.001.\r\n",
      "Epoch 0: LinearWarmup set learning rate to 0.0002.\r\n",
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\r\n",
      "Epoch 1/1\r\n",
      "step  10/938 - loss: 1.9463 - acc: 0.3438 - 25ms/step\r\n",
      "step  20/938 - loss: 1.8681 - acc: 0.3430 - 23ms/step\r\n",
      "step  30/938 - loss: 1.8197 - acc: 0.3557 - 22ms/step\r\n",
      "step  40/938 - loss: 1.7500 - acc: 0.3730 - 21ms/step\r\n",
      "step  50/938 - loss: 1.6359 - acc: 0.3922 - 21ms/step\r\n",
      "step  60/938 - loss: 1.3407 - acc: 0.4125 - 21ms/step\r\n",
      "step  70/938 - loss: 1.5479 - acc: 0.4317 - 21ms/step\r\n",
      "step  80/938 - loss: 1.4480 - acc: 0.4465 - 21ms/step\r\n",
      "step  90/938 - loss: 1.3629 - acc: 0.4663 - 21ms/step\r\n",
      "step 100/938 - loss: 1.2381 - acc: 0.4808 - 21ms/step\r\n",
      "step 110/938 - loss: 1.3117 - acc: 0.4950 - 21ms/step\r\n",
      "step 120/938 - loss: 1.2857 - acc: 0.5076 - 22ms/step\r\n",
      "step 130/938 - loss: 1.1125 - acc: 0.5206 - 22ms/step\r\n",
      "step 140/938 - loss: 0.9816 - acc: 0.5305 - 22ms/step\r\n",
      "step 150/938 - loss: 1.1160 - acc: 0.5410 - 22ms/step\r\n",
      "step 160/938 - loss: 0.9715 - acc: 0.5510 - 22ms/step\r\n",
      "step 170/938 - loss: 0.9240 - acc: 0.5596 - 22ms/step\r\n",
      "step 180/938 - loss: 1.0725 - acc: 0.5661 - 22ms/step\r\n",
      "step 190/938 - loss: 0.9720 - acc: 0.5740 - 22ms/step\r\n",
      "step 200/938 - loss: 1.0347 - acc: 0.5815 - 22ms/step\r\n",
      "step 210/938 - loss: 0.7961 - acc: 0.5888 - 22ms/step\r\n",
      "step 220/938 - loss: 0.6841 - acc: 0.5967 - 22ms/step\r\n",
      "step 230/938 - loss: 0.8661 - acc: 0.6028 - 22ms/step\r\n",
      "step 240/938 - loss: 0.7957 - acc: 0.6089 - 22ms/step\r\n",
      "step 250/938 - loss: 0.6917 - acc: 0.6165 - 22ms/step\r\n",
      "step 260/938 - loss: 0.6931 - acc: 0.6231 - 22ms/step\r\n",
      "step 270/938 - loss: 0.5915 - acc: 0.6295 - 22ms/step\r\n",
      "step 280/938 - loss: 0.8261 - acc: 0.6356 - 22ms/step\r\n",
      "step 290/938 - loss: 0.7755 - acc: 0.6399 - 22ms/step\r\n",
      "step 300/938 - loss: 0.5923 - acc: 0.6448 - 22ms/step\r\n",
      "step 310/938 - loss: 0.8018 - acc: 0.6494 - 22ms/step\r\n",
      "step 320/938 - loss: 0.6504 - acc: 0.6546 - 22ms/step\r\n",
      "step 330/938 - loss: 0.7065 - acc: 0.6592 - 22ms/step\r\n",
      "step 340/938 - loss: 0.9045 - acc: 0.6629 - 22ms/step\r\n",
      "step 350/938 - loss: 0.6609 - acc: 0.6670 - 22ms/step\r\n",
      "step 360/938 - loss: 0.8030 - acc: 0.6703 - 21ms/step\r\n",
      "step 370/938 - loss: 0.5976 - acc: 0.6745 - 21ms/step\r\n",
      "step 380/938 - loss: 0.6180 - acc: 0.6782 - 21ms/step\r\n",
      "step 390/938 - loss: 0.6414 - acc: 0.6812 - 21ms/step\r\n",
      "step 400/938 - loss: 0.5374 - acc: 0.6853 - 21ms/step\r\n",
      "step 410/938 - loss: 0.4773 - acc: 0.6893 - 21ms/step\r\n",
      "step 420/938 - loss: 0.5921 - acc: 0.6926 - 22ms/step\r\n",
      "step 430/938 - loss: 0.4831 - acc: 0.6962 - 21ms/step\r\n",
      "step 440/938 - loss: 0.5360 - acc: 0.6994 - 21ms/step\r\n",
      "step 450/938 - loss: 0.4998 - acc: 0.7026 - 21ms/step\r\n",
      "step 460/938 - loss: 0.6511 - acc: 0.7053 - 21ms/step\r\n",
      "step 470/938 - loss: 0.5214 - acc: 0.7083 - 21ms/step\r\n",
      "step 480/938 - loss: 0.5297 - acc: 0.7116 - 21ms/step\r\n",
      "step 490/938 - loss: 0.6888 - acc: 0.7145 - 21ms/step\r\n",
      "step 500/938 - loss: 0.5267 - acc: 0.7175 - 21ms/step\r\n",
      "step 510/938 - loss: 0.3453 - acc: 0.7201 - 21ms/step\r\n",
      "step 520/938 - loss: 0.3669 - acc: 0.7227 - 21ms/step\r\n",
      "step 530/938 - loss: 0.4020 - acc: 0.7252 - 21ms/step\r\n",
      "step 540/938 - loss: 0.3896 - acc: 0.7277 - 21ms/step\r\n",
      "step 550/938 - loss: 0.4934 - acc: 0.7300 - 21ms/step\r\n",
      "step 560/938 - loss: 0.4662 - acc: 0.7323 - 21ms/step\r\n",
      "step 570/938 - loss: 0.4749 - acc: 0.7346 - 21ms/step\r\n",
      "step 580/938 - loss: 0.4309 - acc: 0.7362 - 21ms/step\r\n",
      "step 590/938 - loss: 0.3301 - acc: 0.7383 - 21ms/step\r\n",
      "step 600/938 - loss: 0.4734 - acc: 0.7407 - 21ms/step\r\n",
      "step 610/938 - loss: 0.3868 - acc: 0.7428 - 21ms/step\r\n",
      "step 620/938 - loss: 0.5663 - acc: 0.7447 - 21ms/step\r\n",
      "step 630/938 - loss: 0.4049 - acc: 0.7467 - 21ms/step\r\n",
      "step 640/938 - loss: 0.3503 - acc: 0.7486 - 21ms/step\r\n",
      "step 650/938 - loss: 0.4106 - acc: 0.7503 - 21ms/step\r\n",
      "step 660/938 - loss: 0.4269 - acc: 0.7519 - 21ms/step\r\n",
      "step 670/938 - loss: 0.5038 - acc: 0.7535 - 21ms/step\r\n",
      "step 680/938 - loss: 0.2465 - acc: 0.7551 - 21ms/step\r\n",
      "step 690/938 - loss: 0.3574 - acc: 0.7567 - 21ms/step\r\n",
      "step 700/938 - loss: 0.4694 - acc: 0.7582 - 21ms/step\r\n",
      "step 710/938 - loss: 0.6215 - acc: 0.7596 - 21ms/step\r\n",
      "step 720/938 - loss: 0.3047 - acc: 0.7612 - 21ms/step\r\n",
      "step 730/938 - loss: 0.3821 - acc: 0.7627 - 21ms/step\r\n",
      "step 740/938 - loss: 0.3951 - acc: 0.7641 - 21ms/step\r\n",
      "step 750/938 - loss: 0.4910 - acc: 0.7656 - 21ms/step\r\n",
      "step 760/938 - loss: 0.3036 - acc: 0.7669 - 21ms/step\r\n",
      "step 770/938 - loss: 0.4985 - acc: 0.7684 - 21ms/step\r\n",
      "step 780/938 - loss: 0.5875 - acc: 0.7699 - 21ms/step\r\n",
      "step 790/938 - loss: 0.3000 - acc: 0.7713 - 21ms/step\r\n",
      "step 800/938 - loss: 0.3114 - acc: 0.7729 - 21ms/step\r\n",
      "step 810/938 - loss: 0.4452 - acc: 0.7742 - 21ms/step\r\n",
      "step 820/938 - loss: 0.3683 - acc: 0.7754 - 21ms/step\r\n",
      "step 830/938 - loss: 0.3374 - acc: 0.7767 - 21ms/step\r\n",
      "step 840/938 - loss: 0.4054 - acc: 0.7780 - 21ms/step\r\n",
      "step 850/938 - loss: 0.3117 - acc: 0.7792 - 21ms/step\r\n",
      "step 860/938 - loss: 0.2969 - acc: 0.7804 - 21ms/step\r\n",
      "step 870/938 - loss: 0.3055 - acc: 0.7821 - 21ms/step\r\n",
      "step 880/938 - loss: 0.4908 - acc: 0.7830 - 21ms/step\r\n",
      "step 890/938 - loss: 0.4996 - acc: 0.7840 - 21ms/step\r\n",
      "step 900/938 - loss: 0.3818 - acc: 0.7851 - 21ms/step\r\n",
      "step 910/938 - loss: 0.3494 - acc: 0.7862 - 21ms/step\r\n",
      "step 920/938 - loss: 0.4137 - acc: 0.7875 - 21ms/step\r\n",
      "step 930/938 - loss: 0.4475 - acc: 0.7887 - 21ms/step\r\n",
      "step 938/938 - loss: 0.2984 - acc: 0.7895 - 21ms/step\r\n",
      "Epoch 1: LinearWarmup set learning rate to 0.0004.\r\n",
      "Eval begin...\r\n",
      "step  10/157 - loss: 0.4635 - acc: 0.8844 - 11ms/step\r\n",
      "step  20/157 - loss: 0.6576 - acc: 0.8781 - 10ms/step\r\n",
      "step  30/157 - loss: 0.3996 - acc: 0.8719 - 9ms/step\r\n",
      "step  40/157 - loss: 0.4319 - acc: 0.8715 - 9ms/step\r\n",
      "step  50/157 - loss: 0.3815 - acc: 0.8722 - 9ms/step\r\n",
      "step  60/157 - loss: 0.7476 - acc: 0.8719 - 9ms/step\r\n",
      "step  70/157 - loss: 0.4694 - acc: 0.8683 - 9ms/step\r\n",
      "step  80/157 - loss: 0.3485 - acc: 0.8711 - 9ms/step\r\n",
      "step  90/157 - loss: 0.2621 - acc: 0.8799 - 9ms/step\r\n",
      "step 100/157 - loss: 0.1266 - acc: 0.8834 - 8ms/step\r\n",
      "step 110/157 - loss: 0.1243 - acc: 0.8848 - 8ms/step\r\n",
      "step 120/157 - loss: 0.1552 - acc: 0.8898 - 8ms/step\r\n",
      "step 130/157 - loss: 0.4639 - acc: 0.8919 - 8ms/step\r\n",
      "step 140/157 - loss: 0.0708 - acc: 0.8980 - 8ms/step\r\n",
      "step 150/157 - loss: 0.2528 - acc: 0.9012 - 8ms/step\r\n",
      "step 157/157 - loss: 0.1006 - acc: 0.8985 - 8ms/step\r\n",
      "Eval samples: 10000\r\n"
     ]
    }
   ],
   "source": [
    "optim = make_optimizer(parameters=lenet.parameters())\r\n",
    "model.prepare(optimizer=optim,\r\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\r\n",
    "              metrics=paddle.metric.Accuracy())\r\n",
    "# create a learning rate scheduler update by epoch\r\n",
    "callback = [paddle.callbacks.LRScheduler(by_step=False, by_epoch=True),\r\n",
    "            paddle.callbacks.VisualDL(log_dir='logdir')]\r\n",
    "model.fit(train_dataset, eval_data=eval_dataset,batch_size=64, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0bb489-ff25-4fff-8217-9a87bc06e556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip show paddlepaddle-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe31cc-94e1-4909-b2c0-69b3a7349b49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
