{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2022.11.28 visual显示图片\n",
    "\n",
    "## 任务描述：\n",
    "\n",
    "如何根据据图像的视觉内容为图像赋予一个语义类别是**图像分类**的目标，也是图像检索、图像内容分析和目标识别等问题的基础。\n",
    "\n",
    "实践内容：利用飞桨动态图搭建一个**卷积神经网络**，对包含斑马线的马路和不包含斑马线的马路图像进行分类。\n",
    "\n",
    "特别提示：本实践所用数据集均来自互联网，请勿用于商务用途。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T08:53:33.287303Z",
     "iopub.status.busy": "2022-11-28T08:53:33.286346Z",
     "iopub.status.idle": "2022-11-28T08:53:35.128498Z",
     "shell.execute_reply": "2022-11-28T08:53:35.127648Z",
     "shell.execute_reply.started": "2022-11-28T08:53:33.287262Z"
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path,PosixPath\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import paddle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "from paddle.io import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-28T08:53:38.734955Z",
     "iopub.status.busy": "2022-11-28T08:53:38.734165Z",
     "iopub.status.idle": "2022-11-28T08:53:38.740758Z",
     "shell.execute_reply": "2022-11-28T08:53:38.739999Z",
     "shell.execute_reply.started": "2022-11-28T08:53:38.734916Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "参数配置\n",
    "'''\n",
    "train_parameters = {\n",
    "    \"input_size\": [3, 50, 50],                                #输入图片的shape\n",
    "    \"class_dim\": 2,                                          #分类数\n",
    "    \"src_path\":\"data/data55791/Zebra.zip\",                    #原始数据集路径\n",
    "    \"target_path\":\"/home/aistudio/data/\",                     #要解压的路径\n",
    "    \"train_list_path\": \"/home/aistudio/data/train.txt\",       #train.txt路径\n",
    "    \"eval_list_path\": \"/home/aistudio/data/eval.txt\",         #eval.txt路径\n",
    "    \"label_dict\":{'0':'zebra crossing','1':'others'},         #标签字典\n",
    "    \"num_epochs\": 2,                                         #训练轮数\n",
    "    \"train_batch_size\": 16,                                   #训练时每个批次的大小\n",
    "    \"learning_strategy\": {                                    #优化函数相关的配置\n",
    "        \"lr\": 0.01                                            #超参数学习率\n",
    "    }, \n",
    "    'skip_steps': 5,                                         #每N个批次打印一次结果\n",
    "    'save_steps': 10,                                         #每N个批次保存一次模型参数\n",
    "    \"checkpoints\": \"/home/aistudio/work/checkpoints\"          #保存的路径\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **一、数据准备**\n",
    "\n",
    "### （1）解压原始数据集\n",
    "\n",
    "### （2）按照比例划分训练集与验证集\n",
    "\n",
    "### （3）乱序，生成数据列表\n",
    "\n",
    "### （4）定义数据读取器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T08:53:44.971266Z",
     "iopub.status.busy": "2022-11-28T08:53:44.970633Z",
     "iopub.status.idle": "2022-11-28T08:53:46.930587Z",
     "shell.execute_reply": "2022-11-28T08:53:46.929550Z",
     "shell.execute_reply.started": "2022-11-28T08:53:44.971225Z"
    },
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip show pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade visualdl  -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-28T08:53:49.425329Z",
     "iopub.status.busy": "2022-11-28T08:53:49.424696Z",
     "iopub.status.idle": "2022-11-28T08:53:49.431109Z",
     "shell.execute_reply": "2022-11-28T08:53:49.430262Z",
     "shell.execute_reply.started": "2022-11-28T08:53:49.425281Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#解压原始数据集\n",
    "def unzip_data(src_path,target_path):\n",
    "    '''\n",
    "    解压原始数据集，将src_path路径下的zip包解压至target_path目录下\n",
    "    '''\n",
    "    if(not os.path.isdir(target_path + \"zebra crossing\")):     \n",
    "        z = zipfile.ZipFile(src_path, 'r')\n",
    "        z.extractall(path=target_path)\n",
    "        z.close()\n",
    "        print('数据集解压完成')\n",
    "    else:\n",
    "        print('文件已存在')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T08:53:50.803405Z",
     "iopub.status.busy": "2022-11-28T08:53:50.802690Z",
     "iopub.status.idle": "2022-11-28T08:53:50.808546Z",
     "shell.execute_reply": "2022-11-28T08:53:50.807803Z",
     "shell.execute_reply.started": "2022-11-28T08:53:50.803358Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件已存在\r\n"
     ]
    }
   ],
   "source": [
    "#参数初始化\n",
    "src_path=train_parameters['src_path']\n",
    "target_path=train_parameters['target_path']\n",
    "train_list_path=train_parameters['train_list_path']\n",
    "eval_list_path=train_parameters['eval_list_path']\n",
    "\n",
    "#解压原始数据到指定路径\n",
    "unzip_data(src_path,target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T08:53:54.618786Z",
     "iopub.status.busy": "2022-11-28T08:53:54.617600Z",
     "iopub.status.idle": "2022-11-28T08:53:54.641585Z",
     "shell.execute_reply": "2022-11-28T08:53:54.640801Z",
     "shell.execute_reply.started": "2022-11-28T08:53:54.618732Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/aistudio/data/zebra crossing/29.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/aistudio/data/others/195.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/aistudio/data/others/68.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/aistudio/data/others/61.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/aistudio/data/zebra crossing/23.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    img_path  label\n",
       "0  /home/aistudio/data/zebra crossing/29.png      0\n",
       "1         /home/aistudio/data/others/195.png      1\n",
       "2          /home/aistudio/data/others/68.png      1\n",
       "3          /home/aistudio/data/others/61.png      1\n",
       "4  /home/aistudio/data/zebra crossing/23.png      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "def get_data_list(target_path,label,file_name):\n",
    "    lst_imgs=[]    \n",
    "    datas=Path(target_path).glob('*.png')\n",
    "    datas=list(map(str,datas))\n",
    "    lst_imgs.extend(zip(datas,[label]*len(datas)))        \n",
    "    return lst_imgs\n",
    "     \n",
    "data1=get_data_list(target_path+\"zebra crossing/\",0,'train.json')\n",
    "data2=get_data_list(target_path+\"others/\",1,'eval.json')\n",
    "data1.extend(data2)\n",
    "random.shuffle(data1)\n",
    "df=pd.DataFrame(data1,columns=['img_path','label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T08:53:56.866053Z",
     "iopub.status.busy": "2022-11-28T08:53:56.864953Z",
     "iopub.status.idle": "2022-11-28T08:53:56.875887Z",
     "shell.execute_reply": "2022-11-28T08:53:56.874958Z",
     "shell.execute_reply.started": "2022-11-28T08:53:56.866010Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 2)\r\n"
     ]
    }
   ],
   "source": [
    "train_data_len=int(len(df)*0.9)\n",
    "print(df.shape)\n",
    "train_df=df.iloc[:train_data_len,:]\n",
    "eval_df=df.iloc[train_data_len:,:]\n",
    "train_df.to_json(\"train.json\")\n",
    "eval_df.to_json(\"eval.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(train_df.describe())\n",
    "print(eval_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-28T08:53:58.783152Z",
     "iopub.status.busy": "2022-11-28T08:53:58.782031Z",
     "iopub.status.idle": "2022-11-28T08:53:58.791425Z",
     "shell.execute_reply": "2022-11-28T08:53:58.790597Z",
     "shell.execute_reply.started": "2022-11-28T08:53:58.783107Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class dataset(Dataset):\n",
    "    def __init__(self, mode='train'):\n",
    "        \"\"\"\n",
    "        数据读取器\n",
    "        :param data_path: 数据集所在路径\n",
    "        :param mode: train or eval\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        '''self.data_path = data_path\n",
    "        self.img_paths = []\n",
    "        self.labels = []'''\n",
    "        self.df=pd.read_json(mode+'.json')\n",
    "\n",
    "        '''\n",
    "        if mode == 'train':\n",
    "            with open(os.path.join(self.data_path, \"train.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "                self.info = f.readlines()\n",
    "            for img_info in self.info:\n",
    "                img_path, label = img_info.strip().split('\\t')\n",
    "                self.img_paths.append(img_path)\n",
    "                self.labels.append(int(label))\n",
    "\n",
    "        else:\n",
    "            with open(os.path.join(self.data_path, \"eval.txt\"), \"r\", encoding=\"utf-8\") as f:\n",
    "                self.info = f.readlines()\n",
    "            for img_info in self.info:\n",
    "                img_path, label = img_info.strip().split('\\t')\n",
    "                self.img_paths.append(img_path)\n",
    "                self.labels.append(int(label))\n",
    "        '''        \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        获取一组数据\n",
    "        :param index: 文件索引号\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 第一步打开图像文件并获取label值\n",
    "        img_path = self.df.iloc[index,0]\n",
    "        img = Image.open(img_path)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB') \n",
    "        img = np.array(img).astype('float32')\n",
    "        img = img.transpose((2, 0, 1)) / 255\n",
    "        label = self.df.iloc[index,1]\n",
    "        label = np.array([label], dtype=\"int64\")\n",
    "        return img, label\n",
    "\n",
    "    def print_sample(self, index: int = 0):\n",
    "        print(\"文件名\", self.df.iloc[index,0], \"\\t标签值\", self.df.iloc[index,1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-28T08:54:02.391649Z",
     "iopub.status.busy": "2022-11-28T08:54:02.390964Z",
     "iopub.status.idle": "2022-11-28T08:54:02.410611Z",
     "shell.execute_reply": "2022-11-28T08:54:02.409848Z",
     "shell.execute_reply.started": "2022-11-28T08:54:02.391608Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#训练数据加载\n",
    "train_dataset = dataset(mode='train')\n",
    "train_loader = paddle.io.DataLoader(train_dataset, \n",
    "                                    batch_size=train_parameters['train_batch_size'], \n",
    "                                    shuffle=True\n",
    "                                    )\n",
    "#测试数据加载\n",
    "eval_dataset = dataset(mode='eval')\n",
    "eval_loader = paddle.io.DataLoader(eval_dataset,\n",
    "                                   batch_size=train_parameters['train_batch_size'], \n",
    "                                   shuffle=False\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-28T08:54:04.421855Z",
     "iopub.status.busy": "2022-11-28T08:54:04.421256Z",
     "iopub.status.idle": "2022-11-28T08:54:04.440326Z",
     "shell.execute_reply": "2022-11-28T08:54:04.439553Z",
     "shell.execute_reply.started": "2022-11-28T08:54:04.421814Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件名 /home/aistudio/data/zebra crossing/44.png \t标签值 0\r\n",
      "397\r\n",
      "文件名 /home/aistudio/data/zebra crossing/92.png \t标签值 0\r\n",
      "45\r\n",
      "(3, 50, 50)\r\n",
      "(1,)\r\n"
     ]
    }
   ],
   "source": [
    "train_dataset.print_sample(200)\n",
    "print(train_dataset.__len__())\n",
    "eval_dataset.print_sample(0)\n",
    "print(eval_dataset.__len__())\n",
    "print(eval_dataset.__getitem__(10)[0].shape)\n",
    "print(eval_dataset.__getitem__(10)[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **二、模型配置**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积网络示例：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/51015c9299b645d6b6c8256eeddb6e43c87eaf2e05044ddd9f250571343cd687)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-28T08:54:06.771866Z",
     "iopub.status.busy": "2022-11-28T08:54:06.771253Z",
     "iopub.status.idle": "2022-11-28T08:54:06.779970Z",
     "shell.execute_reply": "2022-11-28T08:54:06.779222Z",
     "shell.execute_reply.started": "2022-11-28T08:54:06.771826Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#定义卷积网络\n",
    "class MyCNN(paddle.nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(MyCNN,self).__init__()\n",
    "        self.hidden1 = paddle.nn.Conv2D(in_channels=3,            #通道数\n",
    "                                            out_channels=32,      #卷积核个数\n",
    "                                            kernel_size=3,        #卷积核大小\n",
    "                                            stride=1)             #卷积步长1, 特征图48*48\n",
    "        self.relu1 = paddle.nn.ReLU()\n",
    "        self.hidden2 = paddle.nn.Conv2D(in_channels=32,           #通道数\n",
    "                                            out_channels = 32,   #卷积核个数\n",
    "                                            kernel_size=3,        #卷积核大小\n",
    "                                            stride=1)             #卷积步长1, 特征图46*46\n",
    "        self.hidden3 = paddle.nn.MaxPool2D(kernel_size=2,         #池化核大小\n",
    "                                            stride=2)             #池化步长2, 特征图23*23\n",
    "        self.hidden4 = paddle.nn.Linear(32*23*23, 2)\n",
    "    #网络的前向计算过程\n",
    "    def forward(self,_input):\n",
    "        x1 = self.hidden1(_input)\n",
    "        x2 = self.relu1(x1)        \n",
    "        x3 = self.hidden2(x2)\n",
    "        x4 = self.hidden3(x3)        \n",
    "        x5 = paddle.reshape(x4, shape=[-1, 32*23*23])        \n",
    "        out = self.hidden4(x5)\n",
    "        print(\"hidden后\",out.shape)\n",
    "        return out,[_input,x1,x2,x3,x4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-28T08:54:12.009161Z",
     "iopub.status.busy": "2022-11-28T08:54:12.008107Z",
     "iopub.status.idle": "2022-11-28T08:54:12.013659Z",
     "shell.execute_reply": "2022-11-28T08:54:12.012949Z",
     "shell.execute_reply.started": "2022-11-28T08:54:12.009122Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def draw_process(title,color,iters,data,label):\n",
    "    plt.title(title, fontsize=24)\n",
    "    plt.xlabel(\"iter\", fontsize=20)\n",
    "    plt.ylabel(label, fontsize=20)\n",
    "    plt.plot(iters, data,color=color,label=label) \n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-28T08:54:13.150398Z",
     "iopub.status.busy": "2022-11-28T08:54:13.149791Z",
     "iopub.status.idle": "2022-11-28T08:54:13.154533Z",
     "shell.execute_reply": "2022-11-28T08:54:13.153848Z",
     "shell.execute_reply.started": "2022-11-28T08:54:13.150355Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_out_img(_img):\n",
    "    # print(_img.shape)    \n",
    "    _img=_img.numpy()+1    \n",
    "    # if len(_img.shape)==3:_img=np.transpose(_img,(1,2,0))\n",
    "    _img=_img*127.5\n",
    "    return _img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-28T09:16:03.819588Z",
     "iopub.status.busy": "2022-11-28T09:16:03.818582Z",
     "iopub.status.idle": "2022-11-28T09:16:03.877224Z",
     "shell.execute_reply": "2022-11-28T09:16:03.875218Z",
     "shell.execute_reply.started": "2022-11-28T09:16:03.819538Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden后 [16, 2]\r\n",
      "original [16, 3, 50, 50]\r\n",
      "conv1 [16, 32, 48, 48]\r\n",
      "conv2 [16, 32, 46, 46]\r\n",
      "pool [16, 32, 23, 23]\r\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3476/2460425210.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     27\u001B[0m         \u001B[0mlog_writer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtag\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'input_mycnn/original'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconvert_out_img\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdataformats\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"NCHW\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 28\u001B[0;31m         \u001B[0mlog_writer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtag\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'input_mycnn/conv1'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconvert_out_img\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdataformats\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"NCHW\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     29\u001B[0m         \u001B[0mlog_writer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtag\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'input_mycnn/conv2'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconvert_out_img\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdataformats\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"CHW\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     30\u001B[0m         \u001B[0mlog_writer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtag\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'input_mycnn/pool'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconvert_out_img\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdataformats\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"CHW\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/visualdl/writer/writer.py\u001B[0m in \u001B[0;36madd_image\u001B[0;34m(self, tag, img, step, walltime, dataformats)\u001B[0m\n\u001B[1;32m    215\u001B[0m                 \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    216\u001B[0m                 \u001B[0mwalltime\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mwalltime\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 217\u001B[0;31m                 dataformats=dataformats))\n\u001B[0m\u001B[1;32m    218\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    219\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0madd_figure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtag\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfigure\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwalltime\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/visualdl/component/base_component.py\u001B[0m in \u001B[0;36mimage\u001B[0;34m(tag, image_array, step, walltime, dataformats)\u001B[0m\n\u001B[1;32m    169\u001B[0m     \"\"\"\n\u001B[1;32m    170\u001B[0m     \u001B[0mimage_array\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdenormalization\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_array\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 171\u001B[0;31m     \u001B[0mimage_array\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvert_to_HWC\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_array\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdataformats\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    172\u001B[0m     \u001B[0mimage_bytes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mimgarray2bytes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimage_array\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    173\u001B[0m     \u001B[0mimage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRecord\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mImage\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mencoded_image_string\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mimage_bytes\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/visualdl/component/base_component.py\u001B[0m in \u001B[0;36mconvert_to_HWC\u001B[0;34m(tensor, input_format)\u001B[0m\n\u001B[1;32m    123\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0minput_format\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mc\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m'NCHW'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    124\u001B[0m         \u001B[0mtensor_NCHW\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m         \u001B[0mtensor_CHW\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmake_grid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor_NCHW\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mtensor_CHW\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/visualdl/component/base_component.py\u001B[0m in \u001B[0;36mmake_grid\u001B[0;34m(I, ncols)\u001B[0m\n\u001B[1;32m     85\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     86\u001B[0m         \u001B[0mI\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconcatenate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mI\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# noqa: E741\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 87\u001B[0;31m     \u001B[0;32massert\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mndim\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m4\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m3\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m4\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     88\u001B[0m     \u001B[0mnimg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     89\u001B[0m     \u001B[0mH\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mI\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from visualdl import LogWriter\n",
    "model = MyCNN()\n",
    "model.train()\n",
    "cross_entropy = paddle.nn.CrossEntropyLoss()\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=train_parameters['learning_strategy']['lr'],\n",
    "                                  parameters=model.parameters()) \n",
    "                                  \n",
    "steps = 0\n",
    "Iters, total_loss, total_acc = [], [], []\n",
    "date_str=datetime.datetime.strftime(datetime.datetime.now(),'%Y%m%d_%H%M%S')\n",
    "log_dir=os.path.join('./log/mycnn',date_str)\n",
    "log_writer = LogWriter(log_dir)\n",
    "epoches=train_parameters['num_epochs']\n",
    "epoches=1\n",
    "for epo in range(epoches):\n",
    "    for _, data in enumerate(train_loader()):\n",
    "        steps += 1\n",
    "        x_data = data[0]\n",
    "        y_data = data[1]\n",
    "        predicts,conv = model(x_data)\n",
    "        print('original',conv[0].shape)\n",
    "        print('conv1',conv[1].shape)\n",
    "        print('conv2',conv[3].shape)\n",
    "        print('pool',conv[4].shape)\n",
    "        \n",
    "        # 同时显示一批里的所有图片\n",
    "        log_writer.add_image(tag='input_mycnn/original', img=convert_out_img(conv[0]),dataformats=\"NCHW\",step=steps)             \n",
    "        log_writer.add_image(tag='input_mycnn/conv1', img=convert_out_img(conv[1]),dataformats=\"NCHW\",step=steps)             \n",
    "        log_writer.add_image(tag='input_mycnn/conv2', img=convert_out_img(conv[3][0][:3]),dataformats=\"CHW\",step=steps)             \n",
    "        log_writer.add_image(tag='input_mycnn/pool', img=convert_out_img(conv[4][0][:3]),dataformats=\"CHW\",step=steps)             \n",
    "\n",
    "\n",
    "        loss = cross_entropy(predicts, y_data)\n",
    "        acc = paddle.metric.accuracy(predicts, y_data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "        if steps % train_parameters[\"skip_steps\"] == 0:\n",
    "            Iters.append(steps)\n",
    "            total_loss.append(loss.numpy()[0])\n",
    "            total_acc.append(acc.numpy()[0])\n",
    "            #打印中间过程\n",
    "            print('epo: {}, step: {}, loss is: {}, acc is: {}'\\\n",
    "                  .format(epo, steps, loss.numpy(), acc.numpy()))\n",
    "        #保存模型参数\n",
    "        if steps % train_parameters[\"save_steps\"] == 0:\n",
    "            save_path = train_parameters[\"checkpoints\"]+\"/\"+\"save_dir_\" + str(steps) + '.pdparams'\n",
    "            print('save model to: ' + save_path)\n",
    "            paddle.save(model.state_dict(),save_path)\n",
    "paddle.save(model.state_dict(),train_parameters[\"checkpoints\"]+\"/\"+\"save_dir_final.pdparams\")\n",
    "draw_process(\"trainning loss\",\"red\",Iters,total_loss,\"trainning loss\")\n",
    "draw_process(\"trainning acc\",\"green\",Iters,total_acc,\"trainning acc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 四、模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "模型预测\n",
    "'''\n",
    "model__state_dict = paddle.load('work/checkpoints/save_dir_final.pdparams')\n",
    "model_eval = MyCNN()\n",
    "model_eval.set_state_dict(model__state_dict) \n",
    "model_eval.eval()\n",
    "accs = []\n",
    "\n",
    "for _, data in enumerate(eval_loader()):\n",
    "    x_data = data[0]\n",
    "    y_data = data[1]\n",
    "    predicts = model_eval(x_data)\n",
    "    acc = paddle.metric.accuracy(predicts, y_data)\n",
    "    accs.append(acc.numpy()[0])\n",
    "print('模型在验证集上的准确率为：',np.mean(accs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **五、模型预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_image(img_path):\n",
    "    '''\n",
    "    预测图片预处理\n",
    "    '''\n",
    "    img = Image.open(img_path)\n",
    "    # print(img.mode)\n",
    "    if img.mode != 'RGB': \n",
    "        img = img.convert('RGB') \n",
    "    img = img.resize((50, 50), Image.ANTIALIAS)\n",
    "    img = np.array(img).astype('float32') \n",
    "    img = img.transpose((2, 0, 1)) / 255  # HWC to CHW 并像素归一化\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model__state_dict = paddle.load('work/checkpoints/save_dir_final.pdparams')\n",
    "model_predict = MyCNN()\n",
    "model_predict.set_state_dict(model__state_dict) \n",
    "model_predict.eval()\n",
    "for file in Path('work').glob('*.jpg'):\n",
    "    infer_path=file\n",
    "    infer_img = Image.open(infer_path)\n",
    "    plt.imshow(infer_img)          #根据数组绘制图像\n",
    "    plt.show()                     #显示图像\n",
    "    #对预测图片进行预处理\n",
    "    infer_img = load_image(infer_path)\n",
    "    # print(type(infer_img))\n",
    "    infer_img = infer_img[np.newaxis,:, : ,:]  #reshape(-1,3,50,50)\n",
    "    infer_img = paddle.to_tensor(infer_img)\n",
    "    results = model_predict(infer_img)\n",
    "    print(results)\n",
    "    results = paddle.nn.functional.softmax(results)\n",
    "    print(\"Zebra crossing:{:.2f}, Others:{:.2f}\" .format(results.numpy()[0][0],results.numpy()[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "from pathlib import Path\n",
    "import os\n",
    "for file in Path('chk_points').iterdir():\n",
    "    if file.stem=='5':\n",
    "        continue\n",
    "    print(file.stem)    \n",
    "    os.remove(file)\n",
    "'''    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
