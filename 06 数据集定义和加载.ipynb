{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "[数据集定义与加载-使用文档-PaddlePaddle深度学习平台](https://www.paddlepaddle.org.cn/documentation/docs/zh/guides/beginner/data_load_cn.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算机视觉（CV）相关数据集： ['DatasetFolder', 'ImageFolder', 'MNIST', 'FashionMNIST', 'Flowers', 'Cifar10', 'Cifar100', 'VOC2012']\n",
      "自然语言处理（NLP）相关数据集： ['Conll05st', 'Imdb', 'Imikolov', 'Movielens', 'UCIHousing', 'WMT14', 'WMT16']\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "print('计算机视觉（CV）相关数据集：', paddle.vision.datasets.__all__)\n",
    "print('自然语言处理（NLP）相关数据集：', paddle.text.__all__)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cache file C:\\Users\\ljc\\.cache\\paddle\\dataset\\mnist\\train-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file C:\\Users\\ljc\\.cache\\paddle\\dataset\\mnist\\train-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/train-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "........\n",
      "Download finished\n",
      "Cache file C:\\Users\\ljc\\.cache\\paddle\\dataset\\mnist\\t10k-images-idx3-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-images-idx3-ubyte.gz \n",
      "Begin to download\n",
      "\n",
      "Download finished\n",
      "Cache file C:\\Users\\ljc\\.cache\\paddle\\dataset\\mnist\\t10k-labels-idx1-ubyte.gz not found, downloading https://dataset.bj.bcebos.com/mnist/t10k-labels-idx1-ubyte.gz \n",
      "Begin to download\n",
      "..\n",
      "Download finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images:  60000 , test images:  10000\n"
     ]
    }
   ],
   "source": [
    "from paddle.vision.transforms import Normalize\n",
    "\n",
    "# 定义图像归一化处理方法，这里的CHW指图像格式需为 [C通道数，H图像高度，W图像宽度]\n",
    "transform = Normalize(mean=[127.5], std=[127.5], data_format='CHW')\n",
    "# 下载数据集并初始化 DataSet\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "print('train images: ',len(train_dataset),', test images: ',len(test_dataset))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image:  (1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for data in train_dataset:\n",
    "    image, label = data\n",
    "    print('shape of image: ',image.shape)\n",
    "    plt.title(str(label))\n",
    "    plt.imshow(image[0])\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 自定义dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mnist/train/label.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-c951edf39da7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     49\u001B[0m \u001B[0mtransform\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mNormalize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmean\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m127.5\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstd\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m127.5\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdata_format\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'CHW'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[1;31m# 打印数据集样本数\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 51\u001B[1;33m \u001B[0mtrain_custom_dataset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMyDataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'mnist/train'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'mnist/train/label.txt'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     52\u001B[0m \u001B[0mtest_custom_dataset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMyDataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'mnist/val'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m'mnist/val/label.txt'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'train_custom_dataset images: '\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_custom_dataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'test_custom_dataset images: '\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_custom_dataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-5-c951edf39da7>\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, data_dir, label_path, transform)\u001B[0m\n\u001B[0;32m     14\u001B[0m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mMyDataset\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata_list\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m         \u001B[1;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlabel_path\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mencoding\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'utf-8'\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mline\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadlines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m                 \u001B[0mimage_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlabel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mline\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'\\t'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'mnist/train/label.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from paddle.io import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    步骤一：继承 paddle.io.Dataset 类\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, label_path, transform=None):\n",
    "        \"\"\"\n",
    "        步骤二：实现 __init__ 函数，初始化数据集，将样本和标签映射到列表中\n",
    "        \"\"\"\n",
    "        super(MyDataset, self).__init__()\n",
    "        self.data_list = []\n",
    "        with open(label_path,encoding='utf-8') as f:\n",
    "            for line in f.readlines():\n",
    "                image_path, label = line.strip().split('\\t')\n",
    "                image_path = os.path.join(data_dir, image_path)\n",
    "                self.data_list.append([image_path, label])\n",
    "        # 传入定义好的数据处理方法，作为自定义数据集类的一个属性\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        步骤三：实现 __getitem__ 函数，定义指定 index 时如何获取数据，并返回单条数据（样本数据、对应的标签）\n",
    "        \"\"\"\n",
    "        # 根据索引，从列表中取出一个图像\n",
    "        image_path, label = self.data_list[index]\n",
    "        # 读取灰度图\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        # 飞桨训练时内部数据格式默认为float32，将图像数据格式转换为 float32\n",
    "        image = image.astype('float32')\n",
    "        # 应用数据处理方法到图像上\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        # CrossEntropyLoss要求label格式为int，将Label格式转换为 int\n",
    "        label = int(label)\n",
    "        # 返回图像和对应标签\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        步骤四：实现 __len__ 函数，返回数据集的样本总数\n",
    "        \"\"\"\n",
    "        return len(self.data_list)\n",
    "\n",
    "# 定义图像归一化处理方法，这里的CHW指图像格式需为 [C通道数，H图像高度，W图像宽度]\n",
    "transform = Normalize(mean=[127.5], std=[127.5], data_format='CHW')\n",
    "# 打印数据集样本数\n",
    "train_custom_dataset = MyDataset('mnist/train','mnist/train/label.txt', transform)\n",
    "test_custom_dataset = MyDataset('mnist/val','mnist/val/label.txt', transform)\n",
    "print('train_custom_dataset images: ',len(train_custom_dataset), 'test_custom_dataset images: ',len(test_custom_dataset))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for data in train_custom_dataset:\n",
    "    image, label = data\n",
    "    print('shape of image: ',image.shape)\n",
    "    plt.title(str(label))\n",
    "    plt.imshow(image[0])\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 使用 paddle.io.DataLoader 定义数据读取器\n",
    "通过前面介绍的直接迭代读取 Dataset 的方式虽然可实现对数据集的访问，但是这种访问方式只能单线程进行并且还需要手动分批次（batch）。在飞桨框架中，推荐使用 paddle.io.DataLoader API 对数据集进行多进程的读取，并且可自动完成划分 batch 的工作"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义并初始化数据读取器\n",
    "train_loader = paddle.io.DataLoader(train_custom_dataset, batch_size=64, shuffle=True, num_workers=1, drop_last=True)\n",
    "\n",
    "# 调用 DataLoader 迭代读取数据\n",
    "for batch_id, data in enumerate(train_loader()):\n",
    "    images, labels = data\n",
    "    print(\"batch_id: {}, 训练数据shape: {}, 标签数据shape: {}\".format(batch_id, images.shape, labels.shape))\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#（可选）自定义采样器\n",
    "采样器定义了从数据集中的采样行为，如顺序采样、批次采样、随机采样、分布式采样等。采样器会根据设定的采样规则，返回数据集中的索引列表，然后数据读取器 Dataloader 即可根据索引列表从数据集中取出对应的样本。\n",
    "\n",
    "飞桨框架在 paddle.io 目录下提供了多种采样器，如批采样器 BatchSampler、分布式批采样器 DistributedBatchSampler、顺序采样器 SequenceSampler、随机采样器 RandomSampler 等。\n",
    "\n",
    "下面通过两段示例代码，介绍采样器的用法。\n",
    "\n",
    "首先，以 BatchSampler 为例，介绍在 DataLoader 中使用 BatchSampler 获取采样数据的方法。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from paddle.io import BatchSampler\n",
    "\n",
    "# 定义一个批采样器，并设置采样的数据集源、采样批大小、是否乱序等\n",
    "bs = BatchSampler(train_custom_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "\n",
    "print(\"BatchSampler 每轮迭代返回一个索引列表\")\n",
    "for batch_indices in bs:\n",
    "    print(batch_indices)\n",
    "    break\n",
    "\n",
    "# 在 DataLoader 中使用 BatchSampler 获取采样数据\n",
    "train_loader = paddle.io.DataLoader(train_custom_dataset, batch_sampler=bs, num_workers=1)\n",
    "\n",
    "print(\"在 DataLoader 中使用 BatchSampler，返回索引对应的一组样本和标签数据 \")\n",
    "for batch_id, data in enumerate(train_loader()):\n",
    "    images, labels = data\n",
    "    print(\"batch_id: {}, 训练数据shape: {}, 标签数据shape: {}\".format(batch_id, images.shape, labels.shape))\n",
    "    break\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "BatchSampler 每轮迭代返回一个索引列表\n",
    "[53486, 39208, 42267, 46762, 33087, 54705, 55986, 20736]\n",
    "在 DataLoader 中使用 BatchSampler，返回索引对应的一组样本和标签数据\n",
    "batch_id: 0, 训练数据shape: [8, 1, 28, 28], 标签数据shape: [8]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------顺序采样----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "[30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "[70, 71, 72, 73, 74, 75, 76, 77, 78, 79]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n",
      "[90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "-----------------随机采样----------------\n",
      "[57, 63, 80, 41, 49, 6, 35, 79, 10, 56]\n",
      "[77, 96, 33, 68, 98, 64, 53, 73, 47, 8]\n",
      "[15, 76, 27, 38, 4, 87, 71, 78, 37, 11]\n",
      "[30, 34, 1, 58, 65, 29, 81, 55, 7, 21]\n",
      "[97, 83, 69, 3, 22, 84, 26, 45, 62, 86]\n",
      "[19, 72, 17, 12, 14, 20, 95, 54, 2, 67]\n",
      "[18, 0, 91, 36, 52, 24, 70, 28, 50, 13]\n",
      "[85, 46, 74, 92, 16, 82, 88, 99, 48, 31]\n",
      "[51, 5, 90, 59, 60, 39, 66, 40, 23, 61]\n",
      "[94, 75, 44, 42, 25, 93, 43, 89, 9, 32]\n",
      "-----------------分布式采样----------------\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "[40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "[60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n",
      "[80, 81, 82, 83, 84, 85, 86, 87, 88, 89]\n"
     ]
    }
   ],
   "source": [
    "from paddle.io import SequenceSampler, RandomSampler, BatchSampler, DistributedBatchSampler\n",
    "\n",
    "class RandomDataset(paddle.io.Dataset):\n",
    "    def __init__(self, num_samples):\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.random.random([784]).astype('float32')\n",
    "        label = np.random.randint(0, 9, (1, )).astype('int64')\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "train_dataset = RandomDataset(100)\n",
    "\n",
    "print('-----------------顺序采样----------------')\n",
    "sampler = SequenceSampler(train_dataset)\n",
    "batch_sampler = BatchSampler(sampler=sampler, batch_size=10)\n",
    "\n",
    "for index in batch_sampler:\n",
    "    print(index)\n",
    "\n",
    "print('-----------------随机采样----------------')\n",
    "sampler = RandomSampler(train_dataset)\n",
    "batch_sampler = BatchSampler(sampler=sampler, batch_size=10)\n",
    "\n",
    "for index in batch_sampler:\n",
    "    print(index)\n",
    "\n",
    "print('-----------------分布式采样----------------')\n",
    "batch_sampler = DistributedBatchSampler(train_dataset, num_replicas=2, batch_size=10)\n",
    "\n",
    "for index in batch_sampler:\n",
    "    print(index)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "从代码输出结果可以看出：\n",
    "\n",
    "顺序采样：按照顺序的方式输出各个样本的索引。\n",
    "\n",
    "随机采样：先将样本顺序打乱，再输出乱序后的样本索引。\n",
    "\n",
    "分布式采样：常用于分布式训练场景，将样本数据切分成多份，分别放到不同卡上训练。示例中设置了 num_replicas=2，样本会被划分到两张卡上，所以这里只输出一半样本的索引。"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
