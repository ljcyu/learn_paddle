{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "经典的线性回归模型主要用来预测一些存在着线性关系的数据集。回归模型可以理解为：存在一个点集，用一条曲线去拟合它分布的过程。如果拟合曲线是一条直线，则称为线性回归。如果是一条二次曲线，则被称为二次回归。线性回归是回归模型中最简单的一种。 本教程使用PaddlePaddle建立起一个鲍鱼年龄预测模型。\n",
    "\n",
    "在线性回归中：\n",
    "\n",
    "（1）假设函数是指，用数学的方法描述自变量和因变量之间的关系，它们之间可以是一个线性函数或非线性函数。 在本次线性回顾模型中，我们的假设函数为 Y’= wX+b ，其中，Y’表示模型的预测结果（预测的鲍鱼年龄），用来和真实的Y区分。模型要学习的参数即：w,b。\n",
    "\n",
    "（2）损失函数是指，用数学的方法衡量假设函数预测结果与真实值之间的误差。这个差距越小预测越准确，而算法的任务就是使这个差距越来越小。 建立模型后，我们需要给模型一个优化目标，使得学到的参数能够让预测值Y’尽可能地接近真实值Y。这个实值通常用来反映模型误差的大小。不同问题场景下采用不同的损失函数。 对于线性模型来讲，最常用的损失函数就是均方误差（Mean Squared Error， MSE）。\n",
    "\n",
    "（3）优化算法：神经网络的训练就是调整权重（参数）使得损失函数值尽可能得小，在训练过程中，将损失函数值逐渐收敛，得到一组使得神经网络拟合真实模型的权重（参数）。所以，优化算法的最终目标是找到损失函数的最小值。而这个寻找过程就是不断地微调变量w和b的值，一步一步地试出这个最小值。 常见的优化算法有随机梯度下降法（SGD）、Adam算法等等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **Step1.数据准备**\n",
    "\n",
    "**认识数据：**\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/bba24e932f7547e38de93fce393fac0f166861451ac24080b69cd3ff2cb4dbf8)\n",
    "\n",
    "数据集共4177行，每行9列\n",
    "\n",
    "前8列用来描述鲍鱼的各种信息，分别是性别、长度、直径、高度、总重量、皮重、内脏重量、克重，最后一列为该鲍鱼的年龄\n",
    "\n",
    "\n",
    "**数据准备：**\n",
    "\n",
    "1.从文件中加载数据\n",
    "\n",
    "2.对数据进行归一化\n",
    "\n",
    "3.构造数据集提供器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4177 entries, 0 to 4176\n",
      "Data columns (total 9 columns):\n",
      "性别      4177 non-null int64\n",
      "长度      4177 non-null float64\n",
      "直径      4177 non-null float64\n",
      "高度      4177 non-null float64\n",
      "总重量     4177 non-null float64\n",
      "皮重      4177 non-null float64\n",
      "内脏重量    4177 non-null float64\n",
      "克重      4177 non-null float64\n",
      "年龄      4177 non-null int64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 293.8 KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# 将性别（M：雄性，F：雌性，I：未成年）映射成数字\r\n",
    "sex_dict = { 'I': 0, 'M': 1, 'F': 2 }\r\n",
    "def sex_map(sex):\r\n",
    "    return sex_dict[sex]\r\n",
    "\r\n",
    "txt_path='data/data361/AbaloneAgePrediction.txt'\r\n",
    "df=pd.read_csv(txt_path,names=['性别','长度','直径','高度','总重量','皮重','内脏重量','克重','年龄'],converters={'性别':sex_map})\r\n",
    "df.head(10)\r\n",
    "df.info()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>性别</th>\n",
       "      <th>长度</th>\n",
       "      <th>直径</th>\n",
       "      <th>高度</th>\n",
       "      <th>总重量</th>\n",
       "      <th>皮重</th>\n",
       "      <th>内脏重量</th>\n",
       "      <th>克重</th>\n",
       "      <th>年龄</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.513514</td>\n",
       "      <td>0.521008</td>\n",
       "      <td>0.084071</td>\n",
       "      <td>0.181335</td>\n",
       "      <td>0.150303</td>\n",
       "      <td>0.132324</td>\n",
       "      <td>0.147982</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.371622</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.079646</td>\n",
       "      <td>0.079157</td>\n",
       "      <td>0.066241</td>\n",
       "      <td>0.063199</td>\n",
       "      <td>0.068261</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.614865</td>\n",
       "      <td>0.613445</td>\n",
       "      <td>0.119469</td>\n",
       "      <td>0.239065</td>\n",
       "      <td>0.171822</td>\n",
       "      <td>0.185648</td>\n",
       "      <td>0.207773</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.493243</td>\n",
       "      <td>0.521008</td>\n",
       "      <td>0.110619</td>\n",
       "      <td>0.182044</td>\n",
       "      <td>0.144250</td>\n",
       "      <td>0.149440</td>\n",
       "      <td>0.152965</td>\n",
       "      <td>0.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344595</td>\n",
       "      <td>0.336134</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.071897</td>\n",
       "      <td>0.059516</td>\n",
       "      <td>0.051350</td>\n",
       "      <td>0.053313</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    性别        长度        直径        高度       总重量        皮重      内脏重量        克重  \\\n",
       "0  0.5  0.513514  0.521008  0.084071  0.181335  0.150303  0.132324  0.147982   \n",
       "1  0.5  0.371622  0.352941  0.079646  0.079157  0.066241  0.063199  0.068261   \n",
       "2  1.0  0.614865  0.613445  0.119469  0.239065  0.171822  0.185648  0.207773   \n",
       "3  0.5  0.493243  0.521008  0.110619  0.182044  0.144250  0.149440  0.152965   \n",
       "4  0.0  0.344595  0.336134  0.070796  0.071897  0.059516  0.051350  0.053313   \n",
       "\n",
       "         年龄  \n",
       "0  0.500000  \n",
       "1  0.214286  \n",
       "2  0.285714  \n",
       "3  0.321429  \n",
       "4  0.214286  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas归一化\r\n",
    "df=(df-df.min())/(df.max()-df.min())\r\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pandas划分测试集和训练集,x_train,y_train,x_test,y_test\r\n",
    "\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import paddle.fluid.dygraph as dygraph\r\n",
    "from paddle.fluid.dygraph import Linear\r\n",
    "\r\n",
    "# 分割训练集、测试集\r\n",
    "x=df.iloc[:,:-1].values\r\n",
    "y=df.iloc[:,-1:].values\r\n",
    "#x.reset_index(drop=True,inplace=True)\r\n",
    "#y.reset_index(drop=True,inplace=True)\r\n",
    "#print(x.shape,y.shape)\r\n",
    "x_train, x_test, y_train,y_test=train_test_split(x,y,test_size=0.1,random_state=42)\r\n",
    "# 自定义reader,每次返回一个样本数据\r\n",
    "def reader_creator(_X, _Y):\r\n",
    "    def reader():\r\n",
    "        for _x, _y in zip(_X, _Y):\r\n",
    "            yield [_x, _y]          #返回Iterable对象\r\n",
    "    return reader\r\n",
    "# 一个minibatch中有16个数据\r\n",
    "BATCH_SIZE = 16\r\n",
    "\r\n",
    "#定义了用于训练与验证的数据提供器。提供器每次读入一个大小为BATCH_SIZE的数据批次。\r\n",
    "#BATCH_SIZE个数据项组成一个mini batch。\r\n",
    "train_reader = paddle.batch(reader_creator(x_train, y_train),\r\n",
    "                            batch_size=BATCH_SIZE)\r\n",
    "test_reader = paddle.batch(reader_creator(x_test, y_test), \r\n",
    "                           batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pandas划分测试集和训练集,train_data,eval_data\r\n",
    "\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import paddle.fluid.dygraph as dygraph\r\n",
    "from paddle.fluid.dygraph import Linear\r\n",
    "train_data,eval_data=train_test_split(df,test_size=0.1,random_state=42)\r\n",
    "BATCH_SIZE = 16\r\n",
    "def reader_creator2(data):\r\n",
    "    def reader():\r\n",
    "        for row in data.values:           \r\n",
    "            yield [row[:-1], row[-1:]]          #返回Iterable对象\r\n",
    "    return reader\r\n",
    "train_reader = paddle.batch(reader_creator2(train_data),\r\n",
    "                            batch_size=BATCH_SIZE)\r\n",
    "test_reader = paddle.batch(reader_creator2(eval_data), \r\n",
    "                           batch_size=BATCH_SIZE)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape (4177, 8) (4177, 1)\n",
      "data_x shape[1] 8\n"
     ]
    }
   ],
   "source": [
    "#原方法读取数据\n",
    "# 读取文件\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_X = []\n",
    "data_Y = []\n",
    "# 将性别（M：雄性，F：雌性，I：未成年）映射成数字\n",
    "sex_map = { 'I': 0, 'M': 1, 'F': 2 }\n",
    "with open ('data/data361/AbaloneAgePrediction.txt') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.split(',')\n",
    "        line[0] = sex_map[line[0]]\n",
    "        data_X.append(line[:-1])\n",
    "        data_Y.append(line[-1:])\n",
    "# 转换为nparray\n",
    "data_X = np.array(data_X, dtype='float32')\n",
    "data_Y = np.array(data_Y, dtype='float32')\n",
    "# 检查大小\n",
    "print('data shape', data_X.shape, data_Y.shape)\n",
    "print('data_x shape[1]', data_X.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 原来归一化\r\n",
    "for i in range(data_X.shape[1]):\r\n",
    "    _min = np.min(data_X[:,i])                            #每一列的最小值\r\n",
    "    _max = np.max(data_X[:,i])                            #每一列的最大值\r\n",
    "    data_X[:, i] = (data_X[:, i] - _min) / (_max - _min)  #归一化到0-1之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#原来划分训练和测试\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import paddle.fluid.dygraph as dygraph\r\n",
    "from paddle.fluid.dygraph import Linear\r\n",
    "\r\n",
    "# 分割训练集、测试集\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_X,          #被划分的样本特征集\r\n",
    "                                                    data_Y,          #被划分的样本标签\r\n",
    "                                                    test_size=0.2,   #测试集占比\r\n",
    "                                                    random_state=1)  #随机数种子，在需要重复试验的时候，保证得到一组一样的随机数\r\n",
    "# 自定义reader,每次返回一个样本数据\r\n",
    "def reader_creator(_X, _Y):\r\n",
    "    def reader():\r\n",
    "        for _x, _y in zip(_X, _Y):\r\n",
    "            yield [_x, _y]          #返回Iterable对象\r\n",
    "    return reader\r\n",
    "    \r\n",
    "# 一个minibatch中有16个数据\r\n",
    "BATCH_SIZE = 16\r\n",
    "\r\n",
    "#定义了用于训练与验证的数据提供器。提供器每次读入一个大小为BATCH_SIZE的数据批次。\r\n",
    "#BATCH_SIZE个数据项组成一个mini batch。\r\n",
    "train_reader = paddle.batch(reader_creator(X_train, y_train),\r\n",
    "                            batch_size=BATCH_SIZE)\r\n",
    "test_reader = paddle.batch(reader_creator(X_test, y_test), \r\n",
    "                           batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **Step2.网络配置**\n",
    "\n",
    "**（1）网络搭建**：对于线性回归来讲，它就是一个从输入到输出的简单的全连接层。\n",
    "\n",
    "对于鲍鱼年龄预测数据集，假设鲍鱼属性和年龄之间的关系可以被属性间的线性组合描述。\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f3f567e7aa7a499fb3abb767aaaa1b943eed373cf4694d87beb382e161ea8edc)\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/f6c44a96e1624828829bbd438c29c17ead9ecc45c68b4310bfbbb0a4dc96c3fe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "# 定义动态图\r\n",
    "class Regressor(fluid.dygraph.Layer):\r\n",
    "    def __init__(self, name_scope):\r\n",
    "        super(Regressor, self).__init__(name_scope)\r\n",
    "        name_scope = self.full_name()\r\n",
    "        # 定义一层全连接层，输出维度是1，激活函数为None，即不使用激活函数\r\n",
    "        self.fc = Linear(input_dim=8, output_dim=1, act=None)\r\n",
    "    \r\n",
    "    # 网络的前向计算函数\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = self.fc(inputs)\r\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **Step3.网络训练 & Step4.网络评估**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "\r\n",
    "\r\n",
    "def draw_train_process(iters,train_costs):\r\n",
    "    title=\"training cost\"\r\n",
    "    plt.title(title, fontsize=24)\r\n",
    "    plt.xlabel(\"iter\", fontsize=14)\r\n",
    "    plt.ylabel(\"cost\", fontsize=14)\r\n",
    "    plt.plot(iters, train_costs,color='red',label='training cost') \r\n",
    "    plt.grid()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iter: 0, loss is: [113.00326]\n",
      "epoch: 0, iter: 50, loss is: [4.8912306]\n",
      "epoch: 0, iter: 100, loss is: [6.56061]\n",
      "epoch: 0, iter: 150, loss is: [16.880997]\n",
      "epoch: 0, iter: 200, loss is: [5.9421334]\n",
      "Test:0, Cost:6.47945\n",
      "epoch: 1, iter: 0, loss is: [12.126436]\n",
      "epoch: 1, iter: 50, loss is: [4.5091505]\n",
      "epoch: 1, iter: 100, loss is: [5.9230776]\n",
      "epoch: 1, iter: 150, loss is: [16.46431]\n",
      "epoch: 1, iter: 200, loss is: [5.5849934]\n",
      "Test:1, Cost:6.19403\n",
      "epoch: 2, iter: 0, loss is: [11.347308]\n",
      "epoch: 2, iter: 50, loss is: [4.312611]\n",
      "epoch: 2, iter: 100, loss is: [5.352735]\n",
      "epoch: 2, iter: 150, loss is: [16.137175]\n",
      "epoch: 2, iter: 200, loss is: [5.2896347]\n",
      "Test:2, Cost:5.96544\n",
      "epoch: 3, iter: 0, loss is: [10.697964]\n",
      "epoch: 3, iter: 50, loss is: [4.144273]\n",
      "epoch: 3, iter: 100, loss is: [4.883069]\n",
      "epoch: 3, iter: 150, loss is: [15.873074]\n",
      "epoch: 3, iter: 200, loss is: [5.0420103]\n",
      "Test:3, Cost:5.78210\n",
      "epoch: 4, iter: 0, loss is: [10.157059]\n",
      "epoch: 4, iter: 50, loss is: [3.9992423]\n",
      "epoch: 4, iter: 100, loss is: [4.496025]\n",
      "epoch: 4, iter: 150, loss is: [15.659627]\n",
      "epoch: 4, iter: 200, loss is: [4.8334236]\n",
      "Test:4, Cost:5.63476\n",
      "epoch: 5, iter: 0, loss is: [9.704483]\n",
      "epoch: 5, iter: 50, loss is: [3.8738751]\n",
      "epoch: 5, iter: 100, loss is: [4.17664]\n",
      "epoch: 5, iter: 150, loss is: [15.486998]\n",
      "epoch: 5, iter: 200, loss is: [4.6569734]\n",
      "Test:5, Cost:5.51611\n",
      "epoch: 6, iter: 0, loss is: [9.324088]\n",
      "epoch: 6, iter: 50, loss is: [3.7651687]\n",
      "epoch: 6, iter: 100, loss is: [3.9127624]\n",
      "epoch: 6, iter: 150, loss is: [15.347321]\n",
      "epoch: 6, iter: 200, loss is: [4.5070977]\n",
      "Test:6, Cost:5.42039\n",
      "epoch: 7, iter: 0, loss is: [9.002896]\n",
      "epoch: 7, iter: 50, loss is: [3.6706343]\n",
      "epoch: 7, iter: 100, loss is: [3.6944928]\n",
      "epoch: 7, iter: 150, loss is: [15.234293]\n",
      "epoch: 7, iter: 200, loss is: [4.379288]\n",
      "Test:7, Cost:5.34302\n",
      "epoch: 8, iter: 0, loss is: [8.73044]\n",
      "epoch: 8, iter: 50, loss is: [3.5882006]\n",
      "epoch: 8, iter: 100, loss is: [3.5137646]\n",
      "epoch: 8, iter: 150, loss is: [15.142847]\n",
      "epoch: 8, iter: 200, loss is: [4.269875]\n",
      "Test:8, Cost:5.28035\n",
      "epoch: 9, iter: 0, loss is: [8.49825]\n",
      "epoch: 9, iter: 50, loss is: [3.5161273]\n",
      "epoch: 9, iter: 100, loss is: [3.3639777]\n",
      "epoch: 9, iter: 150, loss is: [15.068895]\n",
      "epoch: 9, iter: 200, loss is: [4.175851]\n",
      "Test:9, Cost:5.22948\n",
      "epoch: 10, iter: 0, loss is: [8.299452]\n",
      "epoch: 10, iter: 50, loss is: [3.4529529]\n",
      "epoch: 10, iter: 100, loss is: [3.2397242]\n",
      "epoch: 10, iter: 150, loss is: [15.009131]\n",
      "epoch: 10, iter: 200, loss is: [4.0947576]\n",
      "Test:10, Cost:5.18809\n",
      "epoch: 11, iter: 0, loss is: [8.128453]\n",
      "epoch: 11, iter: 50, loss is: [3.3974414]\n",
      "epoch: 11, iter: 100, loss is: [3.136568]\n",
      "epoch: 11, iter: 150, loss is: [14.960884]\n",
      "epoch: 11, iter: 200, loss is: [4.024564]\n",
      "Test:11, Cost:5.15433\n",
      "epoch: 12, iter: 0, loss is: [7.980688]\n",
      "epoch: 12, iter: 50, loss is: [3.3485432]\n",
      "epoch: 12, iter: 100, loss is: [3.0508628]\n",
      "epoch: 12, iter: 150, loss is: [14.92198]\n",
      "epoch: 12, iter: 200, loss is: [3.9635928]\n",
      "Test:12, Cost:5.12670\n",
      "epoch: 13, iter: 0, loss is: [7.8524075]\n",
      "epoch: 13, iter: 50, loss is: [3.3053665]\n",
      "epoch: 13, iter: 100, loss is: [2.9796052]\n",
      "epoch: 13, iter: 150, loss is: [14.890659]\n",
      "epoch: 13, iter: 200, loss is: [3.9104543]\n",
      "Test:13, Cost:5.10402\n",
      "epoch: 14, iter: 0, loss is: [7.7405396]\n",
      "epoch: 14, iter: 50, loss is: [3.2671518]\n",
      "epoch: 14, iter: 100, loss is: [2.9203234]\n",
      "epoch: 14, iter: 150, loss is: [14.865487]\n",
      "epoch: 14, iter: 200, loss is: [3.8639855]\n",
      "Test:14, Cost:5.08532\n",
      "epoch: 15, iter: 0, loss is: [7.642545]\n",
      "epoch: 15, iter: 50, loss is: [3.2332468]\n",
      "epoch: 15, iter: 100, loss is: [2.8709779]\n",
      "epoch: 15, iter: 150, loss is: [14.845291]\n",
      "epoch: 15, iter: 200, loss is: [3.823222]\n",
      "Test:15, Cost:5.06983\n",
      "epoch: 16, iter: 0, loss is: [7.5563216]\n",
      "epoch: 16, iter: 50, loss is: [3.2030928]\n",
      "epoch: 16, iter: 100, loss is: [2.8298826]\n",
      "epoch: 16, iter: 150, loss is: [14.829121]\n",
      "epoch: 16, iter: 200, loss is: [3.7873473]\n",
      "Test:16, Cost:5.05694\n",
      "epoch: 17, iter: 0, loss is: [7.4801283]\n",
      "epoch: 17, iter: 50, loss is: [3.1762114]\n",
      "epoch: 17, iter: 100, loss is: [2.7956467]\n",
      "epoch: 17, iter: 150, loss is: [14.816202]\n",
      "epoch: 17, iter: 200, loss is: [3.7556813]\n",
      "Test:17, Cost:5.04613\n",
      "epoch: 18, iter: 0, loss is: [7.4125175]\n",
      "epoch: 18, iter: 50, loss is: [3.1521873]\n",
      "epoch: 18, iter: 100, loss is: [2.7671175]\n",
      "epoch: 18, iter: 150, loss is: [14.805895]\n",
      "epoch: 18, iter: 200, loss is: [3.7276452]\n",
      "Test:18, Cost:5.03702\n",
      "epoch: 19, iter: 0, loss is: [7.35227]\n",
      "epoch: 19, iter: 50, loss is: [3.1306655]\n",
      "epoch: 19, iter: 100, loss is: [2.7433443]\n",
      "epoch: 19, iter: 150, loss is: [14.79769]\n",
      "epoch: 19, iter: 200, loss is: [3.7027512]\n",
      "Test:19, Cost:5.02926\n",
      "epoch: 20, iter: 0, loss is: [7.2983704]\n",
      "epoch: 20, iter: 50, loss is: [3.111338]\n",
      "epoch: 20, iter: 100, loss is: [2.7235343]\n",
      "epoch: 20, iter: 150, loss is: [14.791162]\n",
      "epoch: 20, iter: 200, loss is: [3.6805851]\n",
      "Test:20, Cost:5.02261\n",
      "epoch: 21, iter: 0, loss is: [7.2499623]\n",
      "epoch: 21, iter: 50, loss is: [3.093938]\n",
      "epoch: 21, iter: 100, loss is: [2.707036]\n",
      "epoch: 21, iter: 150, loss is: [14.785965]\n",
      "epoch: 21, iter: 200, loss is: [3.6607904]\n",
      "Test:21, Cost:5.01684\n",
      "epoch: 22, iter: 0, loss is: [7.206317]\n",
      "epoch: 22, iter: 50, loss is: [3.0782325]\n",
      "epoch: 22, iter: 100, loss is: [2.6933]\n",
      "epoch: 22, iter: 150, loss is: [14.781828]\n",
      "epoch: 22, iter: 200, loss is: [3.6430707]\n",
      "Test:22, Cost:5.01180\n",
      "epoch: 23, iter: 0, loss is: [7.166824]\n",
      "epoch: 23, iter: 50, loss is: [3.0640237]\n",
      "epoch: 23, iter: 100, loss is: [2.6818776]\n",
      "epoch: 23, iter: 150, loss is: [14.778519]\n",
      "epoch: 23, iter: 200, loss is: [3.627162]\n",
      "Test:23, Cost:5.00733\n",
      "epoch: 24, iter: 0, loss is: [7.1309643]\n",
      "epoch: 24, iter: 50, loss is: [3.0511327]\n",
      "epoch: 24, iter: 100, loss is: [2.6723962]\n",
      "epoch: 24, iter: 150, loss is: [14.775856]\n",
      "epoch: 24, iter: 200, loss is: [3.6128418]\n",
      "Test:24, Cost:5.00333\n",
      "epoch: 25, iter: 0, loss is: [7.098291]\n",
      "epoch: 25, iter: 50, loss is: [3.0394092]\n",
      "epoch: 25, iter: 100, loss is: [2.6645403]\n",
      "epoch: 25, iter: 150, loss is: [14.773684]\n",
      "epoch: 25, iter: 200, loss is: [3.5999186]\n",
      "Test:25, Cost:4.99971\n",
      "epoch: 26, iter: 0, loss is: [7.0684175]\n",
      "epoch: 26, iter: 50, loss is: [3.0287175]\n",
      "epoch: 26, iter: 100, loss is: [2.6580515]\n",
      "epoch: 26, iter: 150, loss is: [14.771887]\n",
      "epoch: 26, iter: 200, loss is: [3.5882301]\n",
      "Test:26, Cost:4.99640\n",
      "epoch: 27, iter: 0, loss is: [7.0410194]\n",
      "epoch: 27, iter: 50, loss is: [3.0189424]\n",
      "epoch: 27, iter: 100, loss is: [2.6527088]\n",
      "epoch: 27, iter: 150, loss is: [14.770369]\n",
      "epoch: 27, iter: 200, loss is: [3.5776277]\n",
      "Test:27, Cost:4.99333\n",
      "epoch: 28, iter: 0, loss is: [7.0158124]\n",
      "epoch: 28, iter: 50, loss is: [3.009983]\n",
      "epoch: 28, iter: 100, loss is: [2.6483347]\n",
      "epoch: 28, iter: 150, loss is: [14.769051]\n",
      "epoch: 28, iter: 200, loss is: [3.5679884]\n",
      "Test:28, Cost:4.99047\n",
      "epoch: 29, iter: 0, loss is: [6.9925537]\n",
      "epoch: 29, iter: 50, loss is: [3.0017486]\n",
      "epoch: 29, iter: 100, loss is: [2.6447773]\n",
      "epoch: 29, iter: 150, loss is: [14.76787]\n",
      "epoch: 29, iter: 200, loss is: [3.559199]\n",
      "Test:29, Cost:4.98777\n",
      "epoch: 30, iter: 0, loss is: [6.971031]\n",
      "epoch: 30, iter: 50, loss is: [2.9941611]\n",
      "epoch: 30, iter: 100, loss is: [2.6419098]\n",
      "epoch: 30, iter: 150, loss is: [14.766778]\n",
      "epoch: 30, iter: 200, loss is: [3.55117]\n",
      "Test:30, Cost:4.98521\n",
      "epoch: 31, iter: 0, loss is: [6.9510517]\n",
      "epoch: 31, iter: 50, loss is: [2.9871485]\n",
      "epoch: 31, iter: 100, loss is: [2.6396248]\n",
      "epoch: 31, iter: 150, loss is: [14.765732]\n",
      "epoch: 31, iter: 200, loss is: [3.5438175]\n",
      "Test:31, Cost:4.98277\n",
      "epoch: 32, iter: 0, loss is: [6.9324617]\n",
      "epoch: 32, iter: 50, loss is: [2.9806538]\n",
      "epoch: 32, iter: 100, loss is: [2.6378334]\n",
      "epoch: 32, iter: 150, loss is: [14.764706]\n",
      "epoch: 32, iter: 200, loss is: [3.5370648]\n",
      "Test:32, Cost:4.98041\n",
      "epoch: 33, iter: 0, loss is: [6.915114]\n",
      "epoch: 33, iter: 50, loss is: [2.9746192]\n",
      "epoch: 33, iter: 100, loss is: [2.6364617]\n",
      "epoch: 33, iter: 150, loss is: [14.763677]\n",
      "epoch: 33, iter: 200, loss is: [3.5308511]\n",
      "Test:33, Cost:4.97813\n",
      "epoch: 34, iter: 0, loss is: [6.8988886]\n",
      "epoch: 34, iter: 50, loss is: [2.9689991]\n",
      "epoch: 34, iter: 100, loss is: [2.635446]\n",
      "epoch: 34, iter: 150, loss is: [14.762624]\n",
      "epoch: 34, iter: 200, loss is: [3.5251164]\n",
      "Test:34, Cost:4.97591\n",
      "epoch: 35, iter: 0, loss is: [6.8836727]\n",
      "epoch: 35, iter: 50, loss is: [2.9637523]\n",
      "epoch: 35, iter: 100, loss is: [2.6347332]\n",
      "epoch: 35, iter: 150, loss is: [14.761538]\n",
      "epoch: 35, iter: 200, loss is: [3.5198178]\n",
      "Test:35, Cost:4.97375\n",
      "epoch: 36, iter: 0, loss is: [6.8693705]\n",
      "epoch: 36, iter: 50, loss is: [2.9588401]\n",
      "epoch: 36, iter: 100, loss is: [2.63428]\n",
      "epoch: 36, iter: 150, loss is: [14.760405]\n",
      "epoch: 36, iter: 200, loss is: [3.514903]\n",
      "Test:36, Cost:4.97163\n",
      "epoch: 37, iter: 0, loss is: [6.855893]\n",
      "epoch: 37, iter: 50, loss is: [2.954229]\n",
      "epoch: 37, iter: 100, loss is: [2.634046]\n",
      "epoch: 37, iter: 150, loss is: [14.759224]\n",
      "epoch: 37, iter: 200, loss is: [3.510335]\n",
      "Test:37, Cost:4.96956\n",
      "epoch: 38, iter: 0, loss is: [6.8431644]\n",
      "epoch: 38, iter: 50, loss is: [2.94989]\n",
      "epoch: 38, iter: 100, loss is: [2.6340008]\n",
      "epoch: 38, iter: 150, loss is: [14.757984]\n",
      "epoch: 38, iter: 200, loss is: [3.5060818]\n",
      "Test:38, Cost:4.96752\n",
      "epoch: 39, iter: 0, loss is: [6.8311214]\n",
      "epoch: 39, iter: 50, loss is: [2.9457974]\n",
      "epoch: 39, iter: 100, loss is: [2.6341157]\n",
      "epoch: 39, iter: 150, loss is: [14.756683]\n",
      "epoch: 39, iter: 200, loss is: [3.5021093]\n",
      "Test:39, Cost:4.96552\n",
      "epoch: 40, iter: 0, loss is: [6.8196964]\n",
      "epoch: 40, iter: 50, loss is: [2.941927]\n",
      "epoch: 40, iter: 100, loss is: [2.6343684]\n",
      "epoch: 40, iter: 150, loss is: [14.755329]\n",
      "epoch: 40, iter: 200, loss is: [3.4983928]\n",
      "Test:40, Cost:4.96354\n",
      "epoch: 41, iter: 0, loss is: [6.808839]\n",
      "epoch: 41, iter: 50, loss is: [2.9382575]\n",
      "epoch: 41, iter: 100, loss is: [2.6347394]\n",
      "epoch: 41, iter: 150, loss is: [14.753908]\n",
      "epoch: 41, iter: 200, loss is: [3.4949079]\n",
      "Test:41, Cost:4.96160\n",
      "epoch: 42, iter: 0, loss is: [6.7984986]\n",
      "epoch: 42, iter: 50, loss is: [2.9347725]\n",
      "epoch: 42, iter: 100, loss is: [2.6352122]\n",
      "epoch: 42, iter: 150, loss is: [14.75243]\n",
      "epoch: 42, iter: 200, loss is: [3.4916315]\n",
      "Test:42, Cost:4.95968\n",
      "epoch: 43, iter: 0, loss is: [6.788635]\n",
      "epoch: 43, iter: 50, loss is: [2.9314532]\n",
      "epoch: 43, iter: 100, loss is: [2.6357708]\n",
      "epoch: 43, iter: 150, loss is: [14.750902]\n",
      "epoch: 43, iter: 200, loss is: [3.4885454]\n",
      "Test:43, Cost:4.95778\n",
      "epoch: 44, iter: 0, loss is: [6.7792044]\n",
      "epoch: 44, iter: 50, loss is: [2.9282858]\n",
      "epoch: 44, iter: 100, loss is: [2.6364026]\n",
      "epoch: 44, iter: 150, loss is: [14.749317]\n",
      "epoch: 44, iter: 200, loss is: [3.4856296]\n",
      "Test:44, Cost:4.95591\n",
      "epoch: 45, iter: 0, loss is: [6.770176]\n",
      "epoch: 45, iter: 50, loss is: [2.9252567]\n",
      "epoch: 45, iter: 100, loss is: [2.6370986]\n",
      "epoch: 45, iter: 150, loss is: [14.747677]\n",
      "epoch: 45, iter: 200, loss is: [3.4828706]\n",
      "Test:45, Cost:4.95406\n",
      "epoch: 46, iter: 0, loss is: [6.761513]\n",
      "epoch: 46, iter: 50, loss is: [2.922354]\n",
      "epoch: 46, iter: 100, loss is: [2.6378508]\n",
      "epoch: 46, iter: 150, loss is: [14.745992]\n",
      "epoch: 46, iter: 200, loss is: [3.4802551]\n",
      "Test:46, Cost:4.95223\n",
      "epoch: 47, iter: 0, loss is: [6.753194]\n",
      "epoch: 47, iter: 50, loss is: [2.919568]\n",
      "epoch: 47, iter: 100, loss is: [2.6386461]\n",
      "epoch: 47, iter: 150, loss is: [14.74426]\n",
      "epoch: 47, iter: 200, loss is: [3.4777722]\n",
      "Test:47, Cost:4.95042\n",
      "epoch: 48, iter: 0, loss is: [6.745186]\n",
      "epoch: 48, iter: 50, loss is: [2.916888]\n",
      "epoch: 48, iter: 100, loss is: [2.6394835]\n",
      "epoch: 48, iter: 150, loss is: [14.742483]\n",
      "epoch: 48, iter: 200, loss is: [3.475404]\n",
      "Test:48, Cost:4.94864\n",
      "epoch: 49, iter: 0, loss is: [6.7374673]\n",
      "epoch: 49, iter: 50, loss is: [2.914306]\n",
      "epoch: 49, iter: 100, loss is: [2.6403542]\n",
      "epoch: 49, iter: 150, loss is: [14.740669]\n",
      "epoch: 49, iter: 200, loss is: [3.473146]\n",
      "Test:49, Cost:4.94687\n",
      "epoch: 50, iter: 0, loss is: [6.7300205]\n",
      "epoch: 50, iter: 50, loss is: [2.9118133]\n",
      "epoch: 50, iter: 100, loss is: [2.6412523]\n",
      "epoch: 50, iter: 150, loss is: [14.738813]\n",
      "epoch: 50, iter: 200, loss is: [3.470992]\n",
      "Test:50, Cost:4.94513\n",
      "epoch: 51, iter: 0, loss is: [6.7228227]\n",
      "epoch: 51, iter: 50, loss is: [2.9094048]\n",
      "epoch: 51, iter: 100, loss is: [2.6421754]\n",
      "epoch: 51, iter: 150, loss is: [14.736929]\n",
      "epoch: 51, iter: 200, loss is: [3.4689264]\n",
      "Test:51, Cost:4.94341\n",
      "epoch: 52, iter: 0, loss is: [6.715858]\n",
      "epoch: 52, iter: 50, loss is: [2.9070723]\n",
      "epoch: 52, iter: 100, loss is: [2.6431184]\n",
      "epoch: 52, iter: 150, loss is: [14.735014]\n",
      "epoch: 52, iter: 200, loss is: [3.4669483]\n",
      "Test:52, Cost:4.94171\n",
      "epoch: 53, iter: 0, loss is: [6.7091107]\n",
      "epoch: 53, iter: 50, loss is: [2.9048119]\n",
      "epoch: 53, iter: 100, loss is: [2.6440792]\n",
      "epoch: 53, iter: 150, loss is: [14.733069]\n",
      "epoch: 53, iter: 200, loss is: [3.4650428]\n",
      "Test:53, Cost:4.94003\n",
      "epoch: 54, iter: 0, loss is: [6.7025647]\n",
      "epoch: 54, iter: 50, loss is: [2.902617]\n",
      "epoch: 54, iter: 100, loss is: [2.645053]\n",
      "epoch: 54, iter: 150, loss is: [14.731096]\n",
      "epoch: 54, iter: 200, loss is: [3.463214]\n",
      "Test:54, Cost:4.93837\n",
      "epoch: 55, iter: 0, loss is: [6.696208]\n",
      "epoch: 55, iter: 50, loss is: [2.9004834]\n",
      "epoch: 55, iter: 100, loss is: [2.6460361]\n",
      "epoch: 55, iter: 150, loss is: [14.729103]\n",
      "epoch: 55, iter: 200, loss is: [3.4614527]\n",
      "Test:55, Cost:4.93673\n",
      "epoch: 56, iter: 0, loss is: [6.6900263]\n",
      "epoch: 56, iter: 50, loss is: [2.898407]\n",
      "epoch: 56, iter: 100, loss is: [2.647029]\n",
      "epoch: 56, iter: 150, loss is: [14.727089]\n",
      "epoch: 56, iter: 200, loss is: [3.4597528]\n",
      "Test:56, Cost:4.93511\n",
      "epoch: 57, iter: 0, loss is: [6.6840134]\n",
      "epoch: 57, iter: 50, loss is: [2.8963847]\n",
      "epoch: 57, iter: 100, loss is: [2.64803]\n",
      "epoch: 57, iter: 150, loss is: [14.7250595]\n",
      "epoch: 57, iter: 200, loss is: [3.4581077]\n",
      "Test:57, Cost:4.93351\n",
      "epoch: 58, iter: 0, loss is: [6.678156]\n",
      "epoch: 58, iter: 50, loss is: [2.8944128]\n",
      "epoch: 58, iter: 100, loss is: [2.6490345]\n",
      "epoch: 58, iter: 150, loss is: [14.723013]\n",
      "epoch: 58, iter: 200, loss is: [3.4565187]\n",
      "Test:58, Cost:4.93194\n",
      "epoch: 59, iter: 0, loss is: [6.6724477]\n",
      "epoch: 59, iter: 50, loss is: [2.892488]\n",
      "epoch: 59, iter: 100, loss is: [2.6500435]\n",
      "epoch: 59, iter: 150, loss is: [14.720954]\n",
      "epoch: 59, iter: 200, loss is: [3.454977]\n",
      "Test:59, Cost:4.93038\n",
      "epoch: 60, iter: 0, loss is: [6.666874]\n",
      "epoch: 60, iter: 50, loss is: [2.8906057]\n",
      "epoch: 60, iter: 100, loss is: [2.651054]\n",
      "epoch: 60, iter: 150, loss is: [14.718882]\n",
      "epoch: 60, iter: 200, loss is: [3.453485]\n",
      "Test:60, Cost:4.92884\n",
      "epoch: 61, iter: 0, loss is: [6.6614304]\n",
      "epoch: 61, iter: 50, loss is: [2.8887663]\n",
      "epoch: 61, iter: 100, loss is: [2.6520655]\n",
      "epoch: 61, iter: 150, loss is: [14.716803]\n",
      "epoch: 61, iter: 200, loss is: [3.452035]\n",
      "Test:61, Cost:4.92732\n",
      "epoch: 62, iter: 0, loss is: [6.656112]\n",
      "epoch: 62, iter: 50, loss is: [2.8869672]\n",
      "epoch: 62, iter: 100, loss is: [2.6530776]\n",
      "epoch: 62, iter: 150, loss is: [14.714714]\n",
      "epoch: 62, iter: 200, loss is: [3.450626]\n",
      "Test:62, Cost:4.92583\n",
      "epoch: 63, iter: 0, loss is: [6.6509123]\n",
      "epoch: 63, iter: 50, loss is: [2.8852034]\n",
      "epoch: 63, iter: 100, loss is: [2.6540859]\n",
      "epoch: 63, iter: 150, loss is: [14.712623]\n",
      "epoch: 63, iter: 200, loss is: [3.449256]\n",
      "Test:63, Cost:4.92435\n",
      "epoch: 64, iter: 0, loss is: [6.6458206]\n",
      "epoch: 64, iter: 50, loss is: [2.8834753]\n",
      "epoch: 64, iter: 100, loss is: [2.6550937]\n",
      "epoch: 64, iter: 150, loss is: [14.710525]\n",
      "epoch: 64, iter: 200, loss is: [3.4479208]\n",
      "Test:64, Cost:4.92289\n",
      "epoch: 65, iter: 0, loss is: [6.6408377]\n",
      "epoch: 65, iter: 50, loss is: [2.8817813]\n",
      "epoch: 65, iter: 100, loss is: [2.6560996]\n",
      "epoch: 65, iter: 150, loss is: [14.708421]\n",
      "epoch: 65, iter: 200, loss is: [3.446621]\n",
      "Test:65, Cost:4.92145\n",
      "epoch: 66, iter: 0, loss is: [6.635955]\n",
      "epoch: 66, iter: 50, loss is: [2.8801196]\n",
      "epoch: 66, iter: 100, loss is: [2.6571012]\n",
      "epoch: 66, iter: 150, loss is: [14.706318]\n",
      "epoch: 66, iter: 200, loss is: [3.445355]\n",
      "Test:66, Cost:4.92003\n",
      "epoch: 67, iter: 0, loss is: [6.6311674]\n",
      "epoch: 67, iter: 50, loss is: [2.8784869]\n",
      "epoch: 67, iter: 100, loss is: [2.6580973]\n",
      "epoch: 67, iter: 150, loss is: [14.704214]\n",
      "epoch: 67, iter: 200, loss is: [3.4441166]\n",
      "Test:67, Cost:4.91863\n",
      "epoch: 68, iter: 0, loss is: [6.6264706]\n",
      "epoch: 68, iter: 50, loss is: [2.8768847]\n",
      "epoch: 68, iter: 100, loss is: [2.65909]\n",
      "epoch: 68, iter: 150, loss is: [14.702113]\n",
      "epoch: 68, iter: 200, loss is: [3.4429078]\n",
      "Test:68, Cost:4.91725\n",
      "epoch: 69, iter: 0, loss is: [6.6218643]\n",
      "epoch: 69, iter: 50, loss is: [2.8753097]\n",
      "epoch: 69, iter: 100, loss is: [2.6600776]\n",
      "epoch: 69, iter: 150, loss is: [14.700012]\n",
      "epoch: 69, iter: 200, loss is: [3.4417276]\n",
      "Test:69, Cost:4.91589\n",
      "epoch: 70, iter: 0, loss is: [6.61734]\n",
      "epoch: 70, iter: 50, loss is: [2.8737614]\n",
      "epoch: 70, iter: 100, loss is: [2.66106]\n",
      "epoch: 70, iter: 150, loss is: [14.697912]\n",
      "epoch: 70, iter: 200, loss is: [3.4405756]\n",
      "Test:70, Cost:4.91454\n",
      "epoch: 71, iter: 0, loss is: [6.612897]\n",
      "epoch: 71, iter: 50, loss is: [2.872237]\n",
      "epoch: 71, iter: 100, loss is: [2.6620357]\n",
      "epoch: 71, iter: 150, loss is: [14.695822]\n",
      "epoch: 71, iter: 200, loss is: [3.439446]\n",
      "Test:71, Cost:4.91321\n",
      "epoch: 72, iter: 0, loss is: [6.60853]\n",
      "epoch: 72, iter: 50, loss is: [2.87074]\n",
      "epoch: 72, iter: 100, loss is: [2.6630058]\n",
      "epoch: 72, iter: 150, loss is: [14.693731]\n",
      "epoch: 72, iter: 200, loss is: [3.4383414]\n",
      "Test:72, Cost:4.91191\n",
      "epoch: 73, iter: 0, loss is: [6.6042376]\n",
      "epoch: 73, iter: 50, loss is: [2.869266]\n",
      "epoch: 73, iter: 100, loss is: [2.663969]\n",
      "epoch: 73, iter: 150, loss is: [14.691649]\n",
      "epoch: 73, iter: 200, loss is: [3.4372618]\n",
      "Test:73, Cost:4.91061\n",
      "epoch: 74, iter: 0, loss is: [6.6000204]\n",
      "epoch: 74, iter: 50, loss is: [2.8678145]\n",
      "epoch: 74, iter: 100, loss is: [2.664925]\n",
      "epoch: 74, iter: 150, loss is: [14.689572]\n",
      "epoch: 74, iter: 200, loss is: [3.4362006]\n",
      "Test:74, Cost:4.90934\n",
      "epoch: 75, iter: 0, loss is: [6.595871]\n",
      "epoch: 75, iter: 50, loss is: [2.8663855]\n",
      "epoch: 75, iter: 100, loss is: [2.6658754]\n",
      "epoch: 75, iter: 150, loss is: [14.687504]\n",
      "epoch: 75, iter: 200, loss is: [3.435163]\n",
      "Test:75, Cost:4.90809\n",
      "epoch: 76, iter: 0, loss is: [6.5917873]\n",
      "epoch: 76, iter: 50, loss is: [2.8649774]\n",
      "epoch: 76, iter: 100, loss is: [2.666818]\n",
      "epoch: 76, iter: 150, loss is: [14.68544]\n",
      "epoch: 76, iter: 200, loss is: [3.434145]\n",
      "Test:76, Cost:4.90685\n",
      "epoch: 77, iter: 0, loss is: [6.587766]\n",
      "epoch: 77, iter: 50, loss is: [2.8635914]\n",
      "epoch: 77, iter: 100, loss is: [2.6677525]\n",
      "epoch: 77, iter: 150, loss is: [14.683388]\n",
      "epoch: 77, iter: 200, loss is: [3.433147]\n",
      "Test:77, Cost:4.90563\n",
      "epoch: 78, iter: 0, loss is: [6.583811]\n",
      "epoch: 78, iter: 50, loss is: [2.8622246]\n",
      "epoch: 78, iter: 100, loss is: [2.6686804]\n",
      "epoch: 78, iter: 150, loss is: [14.681345]\n",
      "epoch: 78, iter: 200, loss is: [3.4321673]\n",
      "Test:78, Cost:4.90443\n",
      "epoch: 79, iter: 0, loss is: [6.579916]\n",
      "epoch: 79, iter: 50, loss is: [2.8608775]\n",
      "epoch: 79, iter: 100, loss is: [2.669601]\n",
      "epoch: 79, iter: 150, loss is: [14.67931]\n",
      "epoch: 79, iter: 200, loss is: [3.4312088]\n",
      "Test:79, Cost:4.90324\n",
      "epoch: 80, iter: 0, loss is: [6.576081]\n",
      "epoch: 80, iter: 50, loss is: [2.8595502]\n",
      "epoch: 80, iter: 100, loss is: [2.6705136]\n",
      "epoch: 80, iter: 150, loss is: [14.677285]\n",
      "epoch: 80, iter: 200, loss is: [3.4302645]\n",
      "Test:80, Cost:4.90207\n",
      "epoch: 81, iter: 0, loss is: [6.572299]\n",
      "epoch: 81, iter: 50, loss is: [2.8582401]\n",
      "epoch: 81, iter: 100, loss is: [2.6714182]\n",
      "epoch: 81, iter: 150, loss is: [14.675269]\n",
      "epoch: 81, iter: 200, loss is: [3.4293392]\n",
      "Test:81, Cost:4.90091\n",
      "epoch: 82, iter: 0, loss is: [6.5685754]\n",
      "epoch: 82, iter: 50, loss is: [2.8569498]\n",
      "epoch: 82, iter: 100, loss is: [2.6723146]\n",
      "epoch: 82, iter: 150, loss is: [14.673267]\n",
      "epoch: 82, iter: 200, loss is: [3.428428]\n",
      "Test:82, Cost:4.89977\n",
      "epoch: 83, iter: 0, loss is: [6.5649014]\n",
      "epoch: 83, iter: 50, loss is: [2.8556747]\n",
      "epoch: 83, iter: 100, loss is: [2.673203]\n",
      "epoch: 83, iter: 150, loss is: [14.671278]\n",
      "epoch: 83, iter: 200, loss is: [3.4275367]\n",
      "Test:83, Cost:4.89865\n",
      "epoch: 84, iter: 0, loss is: [6.561285]\n",
      "epoch: 84, iter: 50, loss is: [2.8544183]\n",
      "epoch: 84, iter: 100, loss is: [2.6740837]\n",
      "epoch: 84, iter: 150, loss is: [14.669294]\n",
      "epoch: 84, iter: 200, loss is: [3.4266605]\n",
      "Test:84, Cost:4.89754\n",
      "epoch: 85, iter: 0, loss is: [6.557717]\n",
      "epoch: 85, iter: 50, loss is: [2.8531787]\n",
      "epoch: 85, iter: 100, loss is: [2.6749563]\n",
      "epoch: 85, iter: 150, loss is: [14.667328]\n",
      "epoch: 85, iter: 200, loss is: [3.4257965]\n",
      "Test:85, Cost:4.89645\n",
      "epoch: 86, iter: 0, loss is: [6.5541987]\n",
      "epoch: 86, iter: 50, loss is: [2.851955]\n",
      "epoch: 86, iter: 100, loss is: [2.6758218]\n",
      "epoch: 86, iter: 150, loss is: [14.665372]\n",
      "epoch: 86, iter: 200, loss is: [3.4249492]\n",
      "Test:86, Cost:4.89538\n",
      "epoch: 87, iter: 0, loss is: [6.550731]\n",
      "epoch: 87, iter: 50, loss is: [2.8507476]\n",
      "epoch: 87, iter: 100, loss is: [2.6766777]\n",
      "epoch: 87, iter: 150, loss is: [14.663428]\n",
      "epoch: 87, iter: 200, loss is: [3.4241145]\n",
      "Test:87, Cost:4.89431\n",
      "epoch: 88, iter: 0, loss is: [6.547309]\n",
      "epoch: 88, iter: 50, loss is: [2.8495557]\n",
      "epoch: 88, iter: 100, loss is: [2.6775265]\n",
      "epoch: 88, iter: 150, loss is: [14.661493]\n",
      "epoch: 88, iter: 200, loss is: [3.4232962]\n",
      "Test:88, Cost:4.89327\n",
      "epoch: 89, iter: 0, loss is: [6.5439343]\n",
      "epoch: 89, iter: 50, loss is: [2.8483794]\n",
      "epoch: 89, iter: 100, loss is: [2.6783671]\n",
      "epoch: 89, iter: 150, loss is: [14.659575]\n",
      "epoch: 89, iter: 200, loss is: [3.422492]\n",
      "Test:89, Cost:4.89223\n",
      "epoch: 90, iter: 0, loss is: [6.540602]\n",
      "epoch: 90, iter: 50, loss is: [2.847218]\n",
      "epoch: 90, iter: 100, loss is: [2.6792004]\n",
      "epoch: 90, iter: 150, loss is: [14.657667]\n",
      "epoch: 90, iter: 200, loss is: [3.4217]\n",
      "Test:90, Cost:4.89122\n",
      "epoch: 91, iter: 0, loss is: [6.5373178]\n",
      "epoch: 91, iter: 50, loss is: [2.8460708]\n",
      "epoch: 91, iter: 100, loss is: [2.6800246]\n",
      "epoch: 91, iter: 150, loss is: [14.655777]\n",
      "epoch: 91, iter: 200, loss is: [3.420921]\n",
      "Test:91, Cost:4.89021\n",
      "epoch: 92, iter: 0, loss is: [6.5340724]\n",
      "epoch: 92, iter: 50, loss is: [2.8449395]\n",
      "epoch: 92, iter: 100, loss is: [2.6808412]\n",
      "epoch: 92, iter: 150, loss is: [14.653898]\n",
      "epoch: 92, iter: 200, loss is: [3.4201546]\n",
      "Test:92, Cost:4.88922\n",
      "epoch: 93, iter: 0, loss is: [6.5308704]\n",
      "epoch: 93, iter: 50, loss is: [2.8438206]\n",
      "epoch: 93, iter: 100, loss is: [2.6816494]\n",
      "epoch: 93, iter: 150, loss is: [14.652032]\n",
      "epoch: 93, iter: 200, loss is: [3.419402]\n",
      "Test:93, Cost:4.88825\n",
      "epoch: 94, iter: 0, loss is: [6.5277114]\n",
      "epoch: 94, iter: 50, loss is: [2.8427162]\n",
      "epoch: 94, iter: 100, loss is: [2.6824503]\n",
      "epoch: 94, iter: 150, loss is: [14.650178]\n",
      "epoch: 94, iter: 200, loss is: [3.41866]\n",
      "Test:94, Cost:4.88728\n",
      "epoch: 95, iter: 0, loss is: [6.5245924]\n",
      "epoch: 95, iter: 50, loss is: [2.8416262]\n",
      "epoch: 95, iter: 100, loss is: [2.683242]\n",
      "epoch: 95, iter: 150, loss is: [14.648337]\n",
      "epoch: 95, iter: 200, loss is: [3.4179323]\n",
      "Test:95, Cost:4.88633\n",
      "epoch: 96, iter: 0, loss is: [6.521513]\n",
      "epoch: 96, iter: 50, loss is: [2.8405495]\n",
      "epoch: 96, iter: 100, loss is: [2.6840274]\n",
      "epoch: 96, iter: 150, loss is: [14.646515]\n",
      "epoch: 96, iter: 200, loss is: [3.4172153]\n",
      "Test:96, Cost:4.88540\n",
      "epoch: 97, iter: 0, loss is: [6.5184765]\n",
      "epoch: 97, iter: 50, loss is: [2.839487]\n",
      "epoch: 97, iter: 100, loss is: [2.684804]\n",
      "epoch: 97, iter: 150, loss is: [14.644705]\n",
      "epoch: 97, iter: 200, loss is: [3.4165096]\n",
      "Test:97, Cost:4.88447\n",
      "epoch: 98, iter: 0, loss is: [6.5154734]\n",
      "epoch: 98, iter: 50, loss is: [2.8384364]\n",
      "epoch: 98, iter: 100, loss is: [2.6855745]\n",
      "epoch: 98, iter: 150, loss is: [14.642907]\n",
      "epoch: 98, iter: 200, loss is: [3.4158123]\n",
      "Test:98, Cost:4.88356\n",
      "epoch: 99, iter: 0, loss is: [6.5125127]\n",
      "epoch: 99, iter: 50, loss is: [2.8373985]\n",
      "epoch: 99, iter: 100, loss is: [2.686336]\n",
      "epoch: 99, iter: 150, loss is: [14.641123]\n",
      "epoch: 99, iter: 200, loss is: [3.4151292]\n",
      "Test:99, Cost:4.88266\n",
      "训练模型保存完成！\n",
      "save models to work/fit_a_line_inference\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from visualdl import LogWriter\r\n",
    "\r\n",
    "iter=0\r\n",
    "iters=[]\r\n",
    "train_costs=[]\r\n",
    "#训练轮数：所有训练数据的一个前向传递和一个后向传递为一轮\r\n",
    "EPOCH_NUM=100\r\n",
    "#模型保存路径\r\n",
    "model_save_dir = \"work/fit_a_line_inference\"\r\n",
    "logdir='log/fit'\r\n",
    "train_loss_logger=LogWriter(logdir=logdir)\r\n",
    "eval_loss_logger=LogWriter(logdir=logdir)\r\n",
    "\r\n",
    "# 定义飞桨动态图的工作环境\r\n",
    "with fluid.dygraph.guard(place = fluid.CUDAPlace(0)):\r\n",
    "#with fluid.dygraph.guard():\r\n",
    "    # 声明定义好的线性回归模型\r\n",
    "    model = Regressor(\"Regressor\")\r\n",
    "   \r\n",
    "    \r\n",
    "    # 定义优化算法，这里使用随机梯度下降-SGD\r\n",
    "    opt = fluid.optimizer.SGD(learning_rate=0.1, parameter_list=model.parameters())\r\n",
    "  \r\n",
    "    # 定义外层循环\r\n",
    "    for epoch_id in range(EPOCH_NUM):\r\n",
    "        #if epoch_id>5:break\r\n",
    "        model.train() # 开启模型训练模式   \r\n",
    "        for batch_id, data in enumerate(train_reader()):\r\n",
    "            #if batch_id>2:break\r\n",
    "            test_x = np.array([x[0] for x in data],np.float32)\r\n",
    "            test_y = np.array([x[1] for x in data],np.float32)\r\n",
    "            #print('test_x {} test_y {}'.format(test_x,test_y))\r\n",
    "            # 将numpy数据转为飞桨动态图variable形式\r\n",
    "            features = dygraph.to_variable(test_x)\r\n",
    "            ages= dygraph.to_variable(test_y)\r\n",
    "            \r\n",
    "            # 前向计算\r\n",
    "            predicts = model(features)\r\n",
    "            # 计算损失\r\n",
    "            loss = fluid.layers.square_error_cost(predicts, label=ages)\r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "\r\n",
    "            iter=iter+1\r\n",
    "            iters.append(iter)\r\n",
    "            train_costs.append(avg_loss.numpy())\r\n",
    "            \r\n",
    "            if batch_id%50==0:\r\n",
    "                print(\"epoch: {}, iter: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\r\n",
    "                train_loss_logger.add_scalar('train_loss',step=iter,value=avg_loss.numpy())\r\n",
    "            \r\n",
    "            # 反向传播\r\n",
    "            avg_loss.backward()\r\n",
    "            # 最小化loss,更新参数\r\n",
    "            opt.minimize(avg_loss)\r\n",
    "            # 清除梯度\r\n",
    "            model.clear_gradients()\r\n",
    "\r\n",
    "        test_costs = []\r\n",
    "        model.eval()\r\n",
    "        for batch_id,data in enumerate(test_reader()):\r\n",
    "            test_x = np.array([x[0] for x in data],np.float32)\r\n",
    "            test_y = np.array([x[1] for x in data],np.float32)\r\n",
    "            features = dygraph.to_variable(test_x)\r\n",
    "            ages = dygraph.to_variable(test_y)\r\n",
    "            # 前向计算\r\n",
    "            predicts = model(features)\r\n",
    "            # 计算损失\r\n",
    "            loss = fluid.layers.square_error_cost(predicts, label=ages)\r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "               \r\n",
    "            test_costs.append(avg_loss.numpy())\r\n",
    "           \r\n",
    "        test_cost = (sum(test_costs) / len(test_costs)) \r\n",
    "        print('Test:%d, Cost:%0.5f' % (epoch_id, test_cost))\r\n",
    "\r\n",
    "\r\n",
    "print('训练模型保存完成！')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "print ('save models to %s' % (model_save_dir))\r\n",
    "# 保存模型\r\n",
    "fluid.save_dygraph(model.state_dict(), model_save_dir)\r\n",
    "\r\n",
    "draw_train_process(iters,train_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **Step5.模型预测**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**可视化真实值与预测值方法定义**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\r\n",
    "def draw_infer_result(groud_truths,infer_results):\r\n",
    "    title='abalone'\r\n",
    "    plt.title(title, fontsize=24)\r\n",
    "    x = np.arange(1,20) \r\n",
    "    y = x\r\n",
    "    plt.plot(x, y)\r\n",
    "    plt.xlabel('ground truth', fontsize=14)\r\n",
    "    plt.ylabel('infer result', fontsize=14)\r\n",
    "    plt.scatter(groud_truths, infer_results,color='green',label='training cost') \r\n",
    "    plt.grid()\r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**开始预测**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0: infer result is 9.16,ground truth is 10.00\n",
      "No.1: infer result is 7.17,ground truth is 8.00\n",
      "No.2: infer result is 8.01,ground truth is 9.00\n",
      "No.3: infer result is 9.16,ground truth is 10.00\n",
      "No.4: infer result is 11.02,ground truth is 16.00\n",
      "No.5: infer result is 6.14,ground truth is 6.00\n",
      "No.6: infer result is 11.87,ground truth is 9.00\n",
      "No.7: infer result is 10.58,ground truth is 10.00\n",
      "No.8: infer result is 10.08,ground truth is 12.00\n",
      "No.9: infer result is 9.10,ground truth is 9.00\n",
      "平均误差为: [4.0149097]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "add_pr_curve() missing 1 required positional argument: 'step'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9aeb295a1270>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdraw_infer_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroud_truths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfer_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mtest_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pr_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroud_truths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfer_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: add_pr_curve() missing 1 required positional argument: 'step'"
     ]
    }
   ],
   "source": [
    "with dygraph.guard():\r\n",
    "    # 参数为保存模型参数的文件地址\r\n",
    "    model = Regressor(\"Regressor\")\r\n",
    "    model_dict, _ = fluid.load_dygraph(model_save_dir)\r\n",
    "    model.load_dict(model_dict)\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    INFER_BATCH_SIZE=10\r\n",
    "    infer_reader = paddle.batch(reader_creator(X_test, y_test), batch_size=INFER_BATCH_SIZE)\r\n",
    "    #从infer_reader中分割x\r\n",
    "    infer_data = next(infer_reader())\r\n",
    "    infer_x = np.array([data[0] for data in infer_data]).astype(\"float32\")\r\n",
    "    infer_y= np.array([data[1] for data in infer_data]).astype(\"float32\")\r\n",
    "\r\n",
    "    infer_x = dygraph.to_variable(infer_x)\r\n",
    "\r\n",
    "    results = model(infer_x)\r\n",
    "\r\n",
    "    infer_results=[]    #预测值\r\n",
    "    groud_truths=[]     #真实值\r\n",
    "    sum_cost=0\r\n",
    "    for i in range(INFER_BATCH_SIZE):\r\n",
    "        infer_result=results[i]      #经过预测后的值\r\n",
    "\r\n",
    "        ground_truth=infer_y[i]          #真实值\r\n",
    "        \r\n",
    "        infer_results.append(infer_result.numpy())\r\n",
    "        groud_truths.append(ground_truth)\r\n",
    "\r\n",
    "\r\n",
    "        print(\"No.%d: infer result is %.2f,ground truth is %.2f\" % (i, infer_result.numpy(),ground_truth))\r\n",
    "        cost=np.power(infer_result.numpy()-ground_truth,2)\r\n",
    "        sum_cost+=cost\r\n",
    "        \r\n",
    "\r\n",
    "    print(\"平均误差为:\",sum_cost/INFER_BATCH_SIZE)\r\n",
    "       \r\n",
    "    draw_infer_result(groud_truths,infer_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.8.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
