{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "from paddle.vision.transforms import Normalize\n",
    "\n",
    "transform = Normalize(mean=[127.5], std=[127.5], data_format='CHW')\n",
    "# 加载 MNIST 训练集和测试集\n",
    "train_dataset = paddle.vision.datasets.MNIST(mode='train', transform=transform)\n",
    "test_dataset = paddle.vision.datasets.MNIST(mode='test', transform=transform)\n",
    "\n",
    "# 模型组网，构建并初始化一个模型 mnist\n",
    "mnist = paddle.nn.Sequential(\n",
    "    paddle.nn.Flatten(1, -1),\n",
    "    paddle.nn.Linear(784, 512),\n",
    "    paddle.nn.ReLU(),\n",
    "    paddle.nn.Dropout(0.2),\n",
    "    paddle.nn.Linear(512, 10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class MyDataset(paddle.io.Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        super(MyDataset,self).__init__()\n",
    "        self.dataset=dataset\n",
    "    def __getitem__(self, index):\n",
    "        return self.dataset[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)//5\n",
    "\n",
    "self_train_dataset=MyDataset(train_dataset)\n",
    "self_test_dataset=MyDataset(test_dataset)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 封装模型为一个 model 实例，便于进行后续的训练、评估和推理\n",
    "model = paddle.Model(mnist)\n",
    "# 为模型训练做准备，设置优化器及其学习率，并将网络的参数传入优化器，设置损失函数和精度计算方式\n",
    "model.prepare(optimizer=paddle.optimizer.Adam(learning_rate=0.001, parameters=model.parameters()),\n",
    "              loss=paddle.nn.CrossEntropyLoss(),\n",
    "              metrics=paddle.metric.Accuracy())\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous step.\n",
      "Epoch 1/5\n",
      "step 188/188 [==============================] - loss: 0.3066 - acc: 0.8209 - 10ms/step          \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 32/32 [==============================] - loss: 0.2979 - acc: 0.8610 - 8ms/step          \n",
      "Eval samples: 2000\n",
      "Epoch 2/5\n",
      "step 188/188 [==============================] - loss: 0.2239 - acc: 0.9100 - 9ms/step           \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 32/32 [==============================] - loss: 0.2277 - acc: 0.9005 - 7ms/step          \n",
      "Eval samples: 2000\n",
      "Epoch 3/5\n",
      "step 188/188 [==============================] - loss: 0.1078 - acc: 0.9326 - 7ms/step          \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 32/32 [==============================] - loss: 0.1217 - acc: 0.9160 - 6ms/step          \n",
      "Eval samples: 2000\n",
      "Epoch 4/5\n",
      "step 188/188 [==============================] - loss: 0.0602 - acc: 0.9459 - 8ms/step          \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 32/32 [==============================] - loss: 0.2935 - acc: 0.9240 - 7ms/step          \n",
      "Eval samples: 2000\n",
      "Epoch 5/5\n",
      "step 188/188 [==============================] - loss: 0.0811 - acc: 0.9539 - 9ms/step          \n",
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 32/32 [==============================] - loss: 0.3350 - acc: 0.9190 - 8ms/step          \n",
      "Eval samples: 2000\n"
     ]
    }
   ],
   "source": [
    "# 启动模型训练，指定训练数据集，设置训练轮次，设置每次数据集计算的批次大小，设置日志格式\n",
    "model.fit(self_train_dataset,eval_data=self_test_dataset,\n",
    "          epochs=5,\n",
    "          batch_size=64,\n",
    "          verbose=1)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval begin...\n",
      "The loss value printed in the log is the current batch, and the metric is the average value of previous step.\n",
      "step 10000/10000 [==============================] - loss: 6.6757e-06 - acc: 0.9398 - 3ms/step          \n",
      "Eval samples: 10000\n",
      "{'loss': [6.675698e-06], 'acc': 0.9398}\n"
     ]
    }
   ],
   "source": [
    "# 用 evaluate 在测试集上对模型进行验证\n",
    "eval_result = model.evaluate(self_test_dataset, verbose=1)\n",
    "print(eval_result)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# predict输出\n",
    "模型是单一输出：结果为[1,n批，m种类数],[(numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n)]，\n",
    "模型是多输出：结果为[m,n],[(numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n), (numpy_ndarray_1, numpy_ndarray_2, …, numpy_ndarray_n), …]\n",
    "\n",
    "如果模型是单一输出，则输出的形状为 [1, n]，n 表示数据集的样本数。其中每个 numpy_ndarray_n 是对应原始数据经过模型计算后得到的预测结果，类型为 numpy 数组，例如 mnist 分类任务中，每个 numpy_ndarray_n 是长度为 10 的 numpy 数组。\n",
    "\n",
    "如果模型是多输出，则输出的形状为[m, n]，m 表示标签的种类数，在多标签分类任务中，m 会根据标签的数目而定。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 2000/2000 [==============================] - 3ms/step          \n",
      "Predict samples: 2000\n",
      "1\n",
      "2000\n",
      "[[-2.6724722 -3.3764327  1.6130106  4.3637486 -6.9111414 -0.8649532\n",
      "  -8.738144  10.380799  -0.8362608  1.0366589]]\n"
     ]
    }
   ],
   "source": [
    "test_result=model.predict(self_test_dataset)\n",
    "print(len(test_result)) #1\n",
    "print(len(test_result[0]))#2000\n",
    "print(test_result[0][0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_label:9 true_label：[9]\n"
     ]
    }
   ],
   "source": [
    "pred_label=test_result[0][20].argmax()\n",
    "img,true_label=self_test_dataset[20]\n",
    "print(f'pred_label:{pred_label} true_label：{true_label}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x29814824c50>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(img.shape)\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(img[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# fit拆解\n",
    "飞桨框架通过基础 API 对模型进行训练，对应高层 API 的 Model.prepare 与 Model.fit ，一般包括如下几个步骤：\n",
    "\n",
    "加载训练数据集、声明模型、设置模型实例为 train 模式\n",
    "\n",
    "设置优化器、损失函数与各个超参数\n",
    "\n",
    "设置模型训练的二层循环嵌套，并在内层循环嵌套中设置如下内容\n",
    "\n",
    "3.1 从数据读取器 DataLoader 获取一批次训练数据\n",
    "\n",
    "3.2 执行一次预测，即经过模型计算获得输入数据的预测值\n",
    "\n",
    "3.3 计算预测值与数据集标签的损失\n",
    "\n",
    "3.4 计算预测值与数据集标签的准确率\n",
    "\n",
    "3.5 将损失进行反向传播\n",
    "\n",
    "3.6 打印模型的轮数、批次、损失值、准确率等信息\n",
    "\n",
    "3.7 执行一次优化器步骤，即按照选择的优化算法，根据当前批次数据的梯度更新传入优化器的参数\n",
    "\n",
    "3.8 将优化器的梯度进行清零"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 50, loss is: [0.04622211], acc is: [0.96875]\n",
      "epoch: 0, batch_id: 100, loss is: [0.04025707], acc is: [0.984375]\n",
      "epoch: 0, batch_id: 150, loss is: [0.01878752], acc is: [1.]\n",
      "epoch: 1, batch_id: 50, loss is: [0.04404696], acc is: [0.984375]\n",
      "epoch: 1, batch_id: 100, loss is: [0.00445972], acc is: [1.]\n",
      "epoch: 1, batch_id: 150, loss is: [0.0383167], acc is: [0.96875]\n",
      "epoch: 2, batch_id: 50, loss is: [0.00124187], acc is: [1.]\n",
      "epoch: 2, batch_id: 100, loss is: [0.00665052], acc is: [1.]\n",
      "epoch: 2, batch_id: 150, loss is: [0.01051711], acc is: [1.]\n",
      "epoch: 3, batch_id: 50, loss is: [0.00524316], acc is: [1.]\n",
      "epoch: 3, batch_id: 100, loss is: [0.06856215], acc is: [0.96875]\n",
      "epoch: 3, batch_id: 150, loss is: [0.03784144], acc is: [0.984375]\n",
      "epoch: 4, batch_id: 50, loss is: [0.04834902], acc is: [0.96875]\n",
      "epoch: 4, batch_id: 100, loss is: [0.02801925], acc is: [0.984375]\n",
      "epoch: 4, batch_id: 150, loss is: [0.00773724], acc is: [1.]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
