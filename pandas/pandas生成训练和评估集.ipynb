{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#导入需要的包\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph import Linear\n",
    "import matplotlib.pyplot as plt\n",
    "from argparse import Namespace as args\n",
    "from pathlib import Path,PosixPath\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1、函数准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def unzip_data(src_path,target_path):\n",
    "\n",
    "    '''\n",
    "    解压原始数据集，将src_path路径下的zip包解压至data/dataset目录下\n",
    "    '''\n",
    "\n",
    "    if(not os.path.isdir(target_path)):    \n",
    "        print(f\"源文件地址：{src_path}\",f\"解压目标目录：{target_path}\")\n",
    "        z = zipfile.ZipFile(src_path, 'r')\n",
    "        z.extractall(path=target_path)\n",
    "        z.close()\n",
    "    else:\n",
    "        print(\"文件已解压\")\n",
    "    __MACOSX = Path(target_path) / '__MACOSX'\n",
    "    if __MACOSX.is_dir():\n",
    "        shutil.rmtree(__MACOSX)   \n",
    "        \n",
    "def data_reader(df):\n",
    "    '''\n",
    "    自定义data_reader\n",
    "    '''\n",
    "    def reader():\n",
    "        for img_path,_,lbl in df.itertuples(index=False):\n",
    "            img = Image.open(img_path)\n",
    "            if img.mode != 'RGB': \n",
    "                img = img.convert('RGB') \n",
    "            img = img.resize((64, 64), Image.BILINEAR)\n",
    "            img = np.array(img).astype('float32') \n",
    "            img = img.transpose((2, 0, 1))  # HWC to CHW \n",
    "            img = img/255                   # 像素值归一化 \n",
    "            yield img, int(lbl)     \n",
    "    return reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2、参数初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "dataset_prefix='test' #数据集名\n",
    "train_params_path='work/'+dataset_prefix+'_params.json' #保存train_params\n",
    "train_params={\n",
    " 'input_size': [3, 64, 64],\n",
    " 'class_dim': 25,\n",
    " 'augment_path': 'augment/',\n",
    " 'src_path': 'data/data55032/archive_train.zip',\n",
    " 'target_path': 'work/dataset/'+dataset_prefix+'/',\n",
    " 'train_txt': 'work/'+dataset_prefix+'_train.txt',\n",
    " 'eval_txt': 'work/'+dataset_prefix+'_eval.txt',\n",
    " 'label_dict': {},\n",
    " 'num_epochs': 10,\n",
    " 'batch_size': 8,\n",
    " 'learning_strategy': {'lr': 0.001},\n",
    " 'gen_img_count': 30,\n",
    " }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "源文件地址：data/data55032/archive_train.zip 解压目标目录：work/dataset/test/\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "解压原始数据到指定路径\n",
    "'''\n",
    "unzip_data( train_params['src_path'], train_params['target_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练集测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#训练数据文件夹\n",
    "targetPath = Path(train_params['target_path'])\n",
    "class_dirs = sorted(targetPath.glob(\"*\"))\n",
    "print(class_dirs)\n",
    "train_params['class_dim']=len(class_dirs)\n",
    "#获取数据 metadata\n",
    "lst_data = []\n",
    "for i, class_dir in enumerate(class_dirs):\n",
    "    lst_path = list(class_dir.glob(\"*.jpg\"))\n",
    "    lst_gemName = [p.parent.name for p in lst_path]\n",
    "    #zip当前路径、名称以及该路径下的宝石类别,\n",
    "    #lst_path、lst_genName都是一个list，所以类别也需要是一个list\n",
    "    lst_data.extend( zip(map(str,lst_path),lst_gemName,[i]*len(lst_path)) )\n",
    "    #print([i]*len(lst_path))\n",
    "#print(lst_data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': [3, 64, 64],\n",
       " 'class_dim': 25,\n",
       " 'augment_path': 'augment/',\n",
       " 'src_path': 'data/data55032/archive_train.zip',\n",
       " 'target_path': 'work/dataset/test/',\n",
       " 'train_txt': 'work/test_train.txt',\n",
       " 'eval_txt': 'work/test_eval.txt',\n",
       " 'label_dict': {},\n",
       " 'num_epochs': 10,\n",
       " 'batch_size': 8,\n",
       " 'learning_strategy': {'lr': 0.001},\n",
       " 'gen_img_count': 30}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gem_path</th>\n",
       "      <th>gem_name</th>\n",
       "      <th>lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>work\\dataset\\test\\Benitoite\\benitoite_21.jpg</td>\n",
       "      <td>Benitoite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>work\\dataset\\test\\Tanzanite\\tanzanite_25.jpg</td>\n",
       "      <td>Tanzanite</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>work\\dataset\\test\\Carnelian\\carnelian_4.jpg</td>\n",
       "      <td>Carnelian</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>work\\dataset\\test\\Emerald\\emerald_34.jpg</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>work\\dataset\\test\\Carnelian\\carnelian_33.jpg</td>\n",
       "      <td>Carnelian</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         gem_path   gem_name  lbl\n",
       "78   work\\dataset\\test\\Benitoite\\benitoite_21.jpg  Benitoite    2\n",
       "730  work\\dataset\\test\\Tanzanite\\tanzanite_25.jpg  Tanzanite   22\n",
       "160   work\\dataset\\test\\Carnelian\\carnelian_4.jpg  Carnelian    4\n",
       "285      work\\dataset\\test\\Emerald\\emerald_34.jpg    Emerald    8\n",
       "156  work\\dataset\\test\\Carnelian\\carnelian_33.jpg  Carnelian    4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建数据 dataframe 并且打乱    \n",
    "df_data = pd.DataFrame(lst_data,columns=['gem_path','gem_name','lbl']).sample(frac=1,replace=False,random_state=SEED)\n",
    "df_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "DataFrame.sample(n=None, frac=None, replace=False, weights=None, random_state=None, axis=None)\n",
    "其中：n和frac不能同时出现，n抽样几个，frac抽样比例，可以大于1，replace表示是否允许重复抽样，frac大于1的时候必须为True，\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到标签字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lbl</th>\n",
       "      <th>gem_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2</td>\n",
       "      <td>Benitoite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>22</td>\n",
       "      <td>Tanzanite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>4</td>\n",
       "      <td>Carnelian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>8</td>\n",
       "      <td>Emerald</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>6</td>\n",
       "      <td>Danburite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lbl   gem_name\n",
       "78     2  Benitoite\n",
       "730   22  Tanzanite\n",
       "160    4  Carnelian\n",
       "285    8    Emerald\n",
       "201    6  Danburite"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#得到标签字典，无重复\n",
    "dic = df_data[['lbl','gem_name']].drop_duplicates()\n",
    "dic.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_size': [3, 64, 64],\n",
       " 'class_dim': 25,\n",
       " 'augment_path': 'augment/',\n",
       " 'src_path': 'data/data55032/archive_train.zip',\n",
       " 'target_path': 'work/dataset/test/',\n",
       " 'train_txt': 'work/test_train.txt',\n",
       " 'eval_txt': 'work/test_eval.txt',\n",
       " 'label_dict': {'Benitoite': 2,\n",
       "  'Tanzanite': 22,\n",
       "  'Carnelian': 4,\n",
       "  'Emerald': 8,\n",
       "  'Danburite': 6,\n",
       "  'Malachite': 16,\n",
       "  'Hessonite': 11,\n",
       "  'Garnet Red': 10,\n",
       "  'Beryl Golden': 3,\n",
       "  'Onyx Black': 17,\n",
       "  'Variscite': 23,\n",
       "  'Jade': 13,\n",
       "  'Almandine': 1,\n",
       "  'Cats Eye': 5,\n",
       "  'Iolite': 12,\n",
       "  'Fluorite': 9,\n",
       "  'Zircon': 24,\n",
       "  'Rhodochrosite': 20,\n",
       "  'Labradorite': 15,\n",
       "  'Pearl': 18,\n",
       "  'Diamond': 7,\n",
       "  'Alexandrite': 0,\n",
       "  'Quartz Beer': 19,\n",
       "  'Sapphire Blue': 21,\n",
       "  'Kunzite': 14},\n",
       " 'num_epochs': 10,\n",
       " 'batch_size': 8,\n",
       " 'learning_strategy': {'lr': 0.001},\n",
       " 'gen_img_count': 30}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_params['label_dict'] = {v:int(k) for k,v in dic.to_records(index=False)}\n",
    "train_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gem_path</th>\n",
       "      <th>gem_name</th>\n",
       "      <th>lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>work\\dataset\\test\\Tanzanite\\tanzanite_32.jpg</td>\n",
       "      <td>Tanzanite</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>work\\dataset\\test\\Benitoite\\benitoite_26.jpg</td>\n",
       "      <td>Benitoite</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>work\\dataset\\test\\Labradorite\\labradorite_25.jpg</td>\n",
       "      <td>Labradorite</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>work\\dataset\\test\\Emerald\\emerald_29.jpg</td>\n",
       "      <td>Emerald</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>work\\dataset\\test\\Beryl Golden\\beryl golden_14...</td>\n",
       "      <td>Beryl Golden</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              gem_path      gem_name  lbl\n",
       "737       work\\dataset\\test\\Tanzanite\\tanzanite_32.jpg     Tanzanite   22\n",
       "83        work\\dataset\\test\\Benitoite\\benitoite_26.jpg     Benitoite    2\n",
       "503   work\\dataset\\test\\Labradorite\\labradorite_25.jpg   Labradorite   15\n",
       "280           work\\dataset\\test\\Emerald\\emerald_29.jpg       Emerald    8\n",
       "102  work\\dataset\\test\\Beryl Golden\\beryl golden_14...  Beryl Golden    3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#分割 traing,validation 数据集\n",
    "train_data, eval_data = train_test_split(df_data, test_size=0.1, random_state=42)\n",
    "train_data.__class__\n",
    "train_data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拷贝评估集文件到另一个目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gem_path</th>\n",
       "      <th>gem_name</th>\n",
       "      <th>lbl</th>\n",
       "      <th>dest_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>work\\dataset\\test\\Alexandrite\\alexandrite_9.jpg</td>\n",
       "      <td>Alexandrite</td>\n",
       "      <td>0</td>\n",
       "      <td>work\\dataset_eval\\test\\Alexandrite\\alexandrite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>work\\dataset\\test\\Cats Eye\\cats eye_6.jpg</td>\n",
       "      <td>Cats Eye</td>\n",
       "      <td>5</td>\n",
       "      <td>work\\dataset_eval\\test\\Cats Eye\\cats eye_6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>work\\dataset\\test\\Tanzanite\\tanzanite_23.jpg</td>\n",
       "      <td>Tanzanite</td>\n",
       "      <td>22</td>\n",
       "      <td>work\\dataset_eval\\test\\Tanzanite\\tanzanite_23.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>work\\dataset\\test\\Cats Eye\\cats eye_11.jpg</td>\n",
       "      <td>Cats Eye</td>\n",
       "      <td>5</td>\n",
       "      <td>work\\dataset_eval\\test\\Cats Eye\\cats eye_11.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>work\\dataset\\test\\Iolite\\iolite_24.jpg</td>\n",
       "      <td>Iolite</td>\n",
       "      <td>12</td>\n",
       "      <td>work\\dataset_eval\\test\\Iolite\\iolite_24.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            gem_path     gem_name  lbl  \\\n",
       "33   work\\dataset\\test\\Alexandrite\\alexandrite_9.jpg  Alexandrite    0   \n",
       "193        work\\dataset\\test\\Cats Eye\\cats eye_6.jpg     Cats Eye    5   \n",
       "728     work\\dataset\\test\\Tanzanite\\tanzanite_23.jpg    Tanzanite   22   \n",
       "168       work\\dataset\\test\\Cats Eye\\cats eye_11.jpg     Cats Eye    5   \n",
       "409           work\\dataset\\test\\Iolite\\iolite_24.jpg       Iolite   12   \n",
       "\n",
       "                                             dest_path  \n",
       "33   work\\dataset_eval\\test\\Alexandrite\\alexandrite...  \n",
       "193     work\\dataset_eval\\test\\Cats Eye\\cats eye_6.jpg  \n",
       "728  work\\dataset_eval\\test\\Tanzanite\\tanzanite_23.jpg  \n",
       "168    work\\dataset_eval\\test\\Cats Eye\\cats eye_11.jpg  \n",
       "409        work\\dataset_eval\\test\\Iolite\\iolite_24.jpg  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#apply\n",
    "eval_data.loc[:,'dest_path']=eval_data.loc[:,'gem_path'].apply(lambda x:str(x).replace('dataset','dataset_eval'))\n",
    "eval_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_data中的图片移动到另一个目录，然后可以对剩下图片进行增强\n",
    "# 就不用担心eval中数据被增强的问题\n",
    "#eval.txt文件移动到另一个目录，然后对train.txt中文件进行数据增强\n",
    "def move_eval_imgs():\n",
    "    for row in eval_data[['gem_path','dest_path']].itertuples():        \n",
    "        src_path=row[1]\n",
    "        dest_path=row[2] \n",
    "        tmp_=Path(dest_path)    \n",
    "        if not tmp_.exists(): tmp_.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.move(src_path,dest_path)\n",
    "\n",
    "def gen_eval_txt(eval_txt_path):\n",
    "    with open(eval_txt_path,'w') as f:\n",
    "        for row in eval_data[['dest_path','lbl']].itertuples():\n",
    "            dest_path=str(row[1])\n",
    "            label=str(row[2]) \n",
    "            f.write('{}\\t{}\\n'.format(dest_path,label))            \n",
    "            \n",
    "move_eval_imgs()            \n",
    "gen_eval_txt(train_params['eval_txt'])            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reset_index()参数说明：\n",
    "```\n",
    "dropbool, default False\n",
    "Do not try to insert index into dataframe columns. This resets the index to the default integer index.\n",
    "\n",
    "inplacebool, default False\n",
    "Modify the DataFrame in place (do not create a new object).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_index(drop=True,inplace=True)\n",
    "eval_data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gem_path</th>\n",
       "      <th>gem_name</th>\n",
       "      <th>lbl</th>\n",
       "      <th>dest_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>work\\dataset\\test\\Alexandrite\\alexandrite_9.jpg</td>\n",
       "      <td>Alexandrite</td>\n",
       "      <td>0</td>\n",
       "      <td>work\\dataset_eval\\test\\Alexandrite\\alexandrite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>work\\dataset\\test\\Cats Eye\\cats eye_6.jpg</td>\n",
       "      <td>Cats Eye</td>\n",
       "      <td>5</td>\n",
       "      <td>work\\dataset_eval\\test\\Cats Eye\\cats eye_6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work\\dataset\\test\\Tanzanite\\tanzanite_23.jpg</td>\n",
       "      <td>Tanzanite</td>\n",
       "      <td>22</td>\n",
       "      <td>work\\dataset_eval\\test\\Tanzanite\\tanzanite_23.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>work\\dataset\\test\\Cats Eye\\cats eye_11.jpg</td>\n",
       "      <td>Cats Eye</td>\n",
       "      <td>5</td>\n",
       "      <td>work\\dataset_eval\\test\\Cats Eye\\cats eye_11.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>work\\dataset\\test\\Iolite\\iolite_24.jpg</td>\n",
       "      <td>Iolite</td>\n",
       "      <td>12</td>\n",
       "      <td>work\\dataset_eval\\test\\Iolite\\iolite_24.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>work\\dataset\\test\\Carnelian\\carnelian_35.jpg</td>\n",
       "      <td>Carnelian</td>\n",
       "      <td>4</td>\n",
       "      <td>work\\dataset_eval\\test\\Carnelian\\carnelian_35.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>work\\dataset\\test\\Jade\\jade_5.jpg</td>\n",
       "      <td>Jade</td>\n",
       "      <td>13</td>\n",
       "      <td>work\\dataset_eval\\test\\Jade\\jade_5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>work\\dataset\\test\\Rhodochrosite\\rhodochrosite_...</td>\n",
       "      <td>Rhodochrosite</td>\n",
       "      <td>20</td>\n",
       "      <td>work\\dataset_eval\\test\\Rhodochrosite\\rhodochro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>work\\dataset\\test\\Fluorite\\fluorite_21.jpg</td>\n",
       "      <td>Fluorite</td>\n",
       "      <td>9</td>\n",
       "      <td>work\\dataset_eval\\test\\Fluorite\\fluorite_21.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>work\\dataset\\test\\Labradorite\\labradorite_17.jpg</td>\n",
       "      <td>Labradorite</td>\n",
       "      <td>15</td>\n",
       "      <td>work\\dataset_eval\\test\\Labradorite\\labradorite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            gem_path       gem_name  lbl  \\\n",
       "0    work\\dataset\\test\\Alexandrite\\alexandrite_9.jpg    Alexandrite    0   \n",
       "1          work\\dataset\\test\\Cats Eye\\cats eye_6.jpg       Cats Eye    5   \n",
       "2       work\\dataset\\test\\Tanzanite\\tanzanite_23.jpg      Tanzanite   22   \n",
       "3         work\\dataset\\test\\Cats Eye\\cats eye_11.jpg       Cats Eye    5   \n",
       "4             work\\dataset\\test\\Iolite\\iolite_24.jpg         Iolite   12   \n",
       "5       work\\dataset\\test\\Carnelian\\carnelian_35.jpg      Carnelian    4   \n",
       "6                  work\\dataset\\test\\Jade\\jade_5.jpg           Jade   13   \n",
       "7  work\\dataset\\test\\Rhodochrosite\\rhodochrosite_...  Rhodochrosite   20   \n",
       "8         work\\dataset\\test\\Fluorite\\fluorite_21.jpg       Fluorite    9   \n",
       "9   work\\dataset\\test\\Labradorite\\labradorite_17.jpg    Labradorite   15   \n",
       "\n",
       "                                           dest_path  \n",
       "0  work\\dataset_eval\\test\\Alexandrite\\alexandrite...  \n",
       "1     work\\dataset_eval\\test\\Cats Eye\\cats eye_6.jpg  \n",
       "2  work\\dataset_eval\\test\\Tanzanite\\tanzanite_23.jpg  \n",
       "3    work\\dataset_eval\\test\\Cats Eye\\cats eye_11.jpg  \n",
       "4        work\\dataset_eval\\test\\Iolite\\iolite_24.jpg  \n",
       "5  work\\dataset_eval\\test\\Carnelian\\carnelian_35.jpg  \n",
       "6             work\\dataset_eval\\test\\Jade\\jade_5.jpg  \n",
       "7  work\\dataset_eval\\test\\Rhodochrosite\\rhodochro...  \n",
       "8    work\\dataset_eval\\test\\Fluorite\\fluorite_21.jpg  \n",
       "9  work\\dataset_eval\\test\\Labradorite\\labradorite...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.head(10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 此处代码主要是消除原始 4 通道图片的影响\n",
    "def proc_img(src):\n",
    "    for root, dirs, files in os.walk(src):\n",
    "        for file in files:            \n",
    "            src=os.path.join(root,file)\n",
    "            #print(src)\n",
    "            img=Image.open(src)\n",
    "            if img.mode != 'RGB': \n",
    "                    img = img.convert('RGB') \n",
    "                    img.save(src)            \n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    proc_img(train_params['target_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, Augmentor\n",
    "import shutil, glob\n",
    "\n",
    "augment_path = train_params['augment_path']\n",
    "gen_img_count=train_params['gen_img_count']\n",
    "img_root=train_params['target_path']\n",
    "def aug():\n",
    "    if not os.path.exists(augment_path): # 控制不重复增强数据\n",
    "        for root, dirs, files in os.walk(img_root, topdown=False):\n",
    "            for name in dirs:\n",
    "                path_ = os.path.join(root, name)\n",
    "                if '__MACOSX' in path_:continue\n",
    "                print('数据增强：',os.path.join(root, name))\n",
    "                print('image：',os.path.join(root, name))\n",
    "                \n",
    "                p = Augmentor.Pipeline(os.path.join(root, name),output_directory='output')\n",
    "                p.rotate(probability=0.6, max_left_rotation=2, max_right_rotation=2)\n",
    "                p.zoom(probability=0.6, min_factor=0.9, max_factor=1.1)\n",
    "                p.random_distortion(probability=0.4, grid_height=2, grid_width=2, magnitude=1)\n",
    "                p.flip_left_right(probability=0.3)\n",
    "                p.flip_top_bottom(probability=0.3)\n",
    "                p.crop_random(probability=0.3,percentage_area=0.8)\n",
    "                p.greyscale(probability=0.2)\n",
    "                p.random_brightness(probability=0.2,min_factor=0.8,max_factor=1.2)\n",
    "                \n",
    "                count = gen_img_count - len(glob.glob(pathname=path_+'/*.jpg'))\n",
    "                p.sample(count, multi_threaded=False)\n",
    "                p.process()\n",
    "\n",
    "        print('将生成的图片拷贝到正确的目录')\n",
    "        tmp_dirs=Path(img_root).iterdir()\n",
    "        #print(tmp_dirs)\n",
    "        for dir_ in tmp_dirs:\n",
    "            src_path=dir_/'output'\n",
    "            dest_path=augment_path+\"/\"+dir_.name\n",
    "            #print(src_path,dest_path)\n",
    "            shutil.move(str(src_path),dest_path)\n",
    "        print('完成数据增强')\n",
    "aug()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到增强后的训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WindowsPath('augment/0'),\n",
       " WindowsPath('augment/1'),\n",
       " WindowsPath('augment/10'),\n",
       " WindowsPath('augment/11'),\n",
       " WindowsPath('augment/12'),\n",
       " WindowsPath('augment/13'),\n",
       " WindowsPath('augment/14'),\n",
       " WindowsPath('augment/15'),\n",
       " WindowsPath('augment/16'),\n",
       " WindowsPath('augment/17')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetPath_aug = Path(train_params['augment_path'])\n",
    "class_dirs_aug = sorted(targetPath_aug.glob(\"*\"))\n",
    "class_dirs_aug[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('augment\\\\0\\\\0_original_img_10.jpg_8b847718-a221-4182-b5c5-615e8a6a62f3.jpg',\n",
       " '0_original_img_10.jpg_8b847718-a221-4182-b5c5-615e8a6a62f3.jpg',\n",
       " '0',\n",
       " 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst_data = []\n",
    "for i, class_dir in enumerate(class_dirs_aug):# 遍历增强后的数据\n",
    "    lst_path = list(class_dir.glob(\"*.jpg\"))  \n",
    "    img = [p.name for p in lst_path ]\n",
    "    lst_gemName = [p.parent.name for p in lst_path]  \n",
    "    lst_data.extend( zip(map(str,lst_path), img, lst_gemName, [i]*len(lst_path)) )\n",
    "\n",
    "lst_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gem_path</th>\n",
       "      <th>img</th>\n",
       "      <th>gem_name</th>\n",
       "      <th>lbl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6876</th>\n",
       "      <td>augment\\23\\23_original_img_11327.jpg_09b5c54a-...</td>\n",
       "      <td>23_original_img_11327.jpg_09b5c54a-8770-4e14-b...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9379</th>\n",
       "      <td>augment\\29\\29_original_img_14543.jpg_a504702e-...</td>\n",
       "      <td>29_original_img_14543.jpg_a504702e-838f-4fae-9...</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6133</th>\n",
       "      <td>augment\\21\\21_original_img_10449.jpg_7b258511-...</td>\n",
       "      <td>21_original_img_10449.jpg_7b258511-5a76-43d6-9...</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>augment\\10\\10_original_img_4562.jpg_5ecc752f-9...</td>\n",
       "      <td>10_original_img_4562.jpg_5ecc752f-9ec1-4fc7-aa...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10627</th>\n",
       "      <td>augment\\31\\31_original_img_15609.jpg_4cd04177-...</td>\n",
       "      <td>31_original_img_15609.jpg_4cd04177-66f8-42e0-b...</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>augment\\14\\14_original_img_7102.jpg_93b01d26-7...</td>\n",
       "      <td>14_original_img_7102.jpg_93b01d26-766e-4282-a5...</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6931</th>\n",
       "      <td>augment\\23\\23_original_img_11386.jpg_4dcfc25e-...</td>\n",
       "      <td>23_original_img_11386.jpg_4dcfc25e-1c8a-4201-8...</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>augment\\20\\20_original_img_9606.jpg_5b346e52-2...</td>\n",
       "      <td>20_original_img_9606.jpg_5b346e52-2d74-46bc-91...</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10579</th>\n",
       "      <td>augment\\31\\31_original_img_15530.jpg_5862fb9e-...</td>\n",
       "      <td>31_original_img_15530.jpg_5862fb9e-2a50-4fc0-a...</td>\n",
       "      <td>31</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>augment\\29\\29_original_img_14513.jpg_f8077b73-...</td>\n",
       "      <td>29_original_img_14513.jpg_f8077b73-4673-46df-b...</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                gem_path  \\\n",
       "6876   augment\\23\\23_original_img_11327.jpg_09b5c54a-...   \n",
       "9379   augment\\29\\29_original_img_14543.jpg_a504702e-...   \n",
       "6133   augment\\21\\21_original_img_10449.jpg_7b258511-...   \n",
       "1051   augment\\10\\10_original_img_4562.jpg_5ecc752f-9...   \n",
       "10627  augment\\31\\31_original_img_15609.jpg_4cd04177-...   \n",
       "2946   augment\\14\\14_original_img_7102.jpg_93b01d26-7...   \n",
       "6931   augment\\23\\23_original_img_11386.jpg_4dcfc25e-...   \n",
       "5460   augment\\20\\20_original_img_9606.jpg_5b346e52-2...   \n",
       "10579  augment\\31\\31_original_img_15530.jpg_5862fb9e-...   \n",
       "9356   augment\\29\\29_original_img_14513.jpg_f8077b73-...   \n",
       "\n",
       "                                                     img gem_name  lbl  \n",
       "6876   23_original_img_11327.jpg_09b5c54a-8770-4e14-b...       23   16  \n",
       "9379   29_original_img_14543.jpg_a504702e-838f-4fae-9...       29   22  \n",
       "6133   21_original_img_10449.jpg_7b258511-5a76-43d6-9...       21   14  \n",
       "1051   10_original_img_4562.jpg_5ecc752f-9ec1-4fc7-aa...       10    2  \n",
       "10627  31_original_img_15609.jpg_4cd04177-66f8-42e0-b...       31   25  \n",
       "2946   14_original_img_7102.jpg_93b01d26-766e-4282-a5...       14    6  \n",
       "6931   23_original_img_11386.jpg_4dcfc25e-1c8a-4201-8...       23   16  \n",
       "5460   20_original_img_9606.jpg_5b346e52-2d74-46bc-91...       20   13  \n",
       "10579  31_original_img_15530.jpg_5862fb9e-2a50-4fc0-a...       31   25  \n",
       "9356   29_original_img_14513.jpg_f8077b73-4673-46df-b...       29   22  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建数据 dataframe 并且打乱    \n",
    "train_data = pd.DataFrame(lst_data,columns=['gem_path','img','gem_name','lbl']).sample(frac=1,replace=False,random_state=SEED)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重新生成train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#重新产生train.txt\n",
    "#生成标签\n",
    "def gen_train_txt(train_txt_path):\n",
    "    with open(train_txt_path,'w') as f:\n",
    "        for row in train_data[['gem_path','lbl']].itertuples():\n",
    "            dest_path=str(row[1])\n",
    "            label=str(row[2]) \n",
    "            f.write('{}\\t{}\\n'.format(dest_path,label))\n",
    "gen_train_txt(train_params['train_txt'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_json('pandas_train.json')\n",
    "eval_data.to_json('pandas_eval.json')\n",
    "with open(train_params_path,'w') as f:\n",
    "    tmp_=json.dumps(train_params)\n",
    "    f.write(tmp_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_size': [3, 64, 64], 'class_dim': 25, 'augment_path': 'augment/', 'src_path': 'data/data55032/archive_train.zip', 'target_path': 'work/dataset/test', 'train_txt': 'work/test_train.txt', 'eval_txt': 'work/test_eval.txt', 'label_dict': {'Benitoite': 2, 'Tanzanite': 22, 'Carnelian': 4, 'Emerald': 8, 'Danburite': 6, 'Malachite': 16, 'Hessonite': 11, 'Garnet Red': 10, 'Beryl Golden': 3, 'Onyx Black': 17, 'Variscite': 23, 'Jade': 13, 'Almandine': 1, 'Cats Eye': 5, 'Iolite': 12, 'Fluorite': 9, 'Zircon': 24, 'Rhodochrosite': 20, 'Labradorite': 15, 'Pearl': 18, 'Diamond': 7, 'Alexandrite': 0, 'Quartz Beer': 19, 'Sapphire Blue': 21, 'Kunzite': 14}, 'num_epochs': 10, 'batch_size': 8, 'learning_strategy': {'lr': 0.001}, 'gen_img_count': 30}\n"
     ]
    }
   ],
   "source": [
    "train_data=pd.read_json('pandas_train.json')\n",
    "eval_data=pd.read_json('pandas_eval.json')\n",
    "with open(train_params_path,'r') as f:\n",
    "    tmp_str=f.read()\n",
    "train_params=json.loads(tmp_str)    \n",
    "print(train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== 数据集总体情况:总类别数 40\n",
      "== 训练集不同类别的样本数：\n",
      "11    635\n",
      "21    566\n",
      "25    472\n",
      "27    460\n",
      "6     400\n",
      "26    400\n",
      "13    400\n",
      "38    400\n",
      "36    400\n",
      "8     400\n",
      "7     400\n",
      "31    400\n",
      "4     400\n",
      "35    400\n",
      "22    400\n",
      "28    400\n",
      "39    400\n",
      "20    400\n",
      "10    400\n",
      "16    400\n",
      "29    400\n",
      "30    400\n",
      "2     400\n",
      "3     400\n",
      "37    400\n",
      "14    400\n",
      "32    400\n",
      "15    400\n",
      "24    400\n",
      "5     400\n",
      "34    400\n",
      "19    400\n",
      "1     400\n",
      "18    400\n",
      "23    400\n",
      "17    400\n",
      "0     400\n",
      "33    400\n",
      "9     400\n",
      "12    400\n",
      "Name: gem_name, dtype: int64\n",
      "== 训练集样本数：16533 验证集样本数：82\n"
     ]
    }
   ],
   "source": [
    "print(\"== 数据集总体情况:总类别数\",train_data.lbl.max() + 1)\n",
    "print(\"== 训练集不同类别的样本数：\")\n",
    "print(train_data.gem_name.value_counts())\n",
    "print(f\"== 训练集样本数：{len(train_data)}\", f\"验证集样本数：{len(eval_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "构造数据提供器\n",
    "'''\n",
    "train_reader = paddle.batch(data_reader(train_data),batch_size=train_params['batch_size'],drop_last=True)\n",
    "\n",
    "eval_reader = paddle.batch(data_reader(eval_data),batch_size=train_params['batch_size'],drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# df用作训练接\n",
    "下边代码不是完整代码"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_parameters = {\n",
    "    \"input_size\": [3, 416, 416],  # 输入图片的尺寸\n",
    "    \"class_dim\": -1,  # 分类数，用 -1 占位\n",
    "    \"data_path\": \"/home/aistudio/data/data101839/data.zip\",  # 原始数据集的路径\n",
    "    \"target_path\": \"/home/aistudio/data\",  # 保存文件的路径\n",
    "    \"train_list_path\": \"/home/aistudio/data/train.txt\",  # train.txt 路径\n",
    "    \"val_list_path\": \"/home/aistudio/data/val.txt\",  # val.txt 路径\n",
    "    \"test_list_path\": \"/home/aistudio/data/test.txt\",  # test.txt 路径\n",
    "    \"readme_path\": \"/home/aistudio/data/readme.json\",  # readme.json 路径\n",
    "    \"label_dict\":{},  # 标签字典\n",
    "    \"num_epochs\": 5,  # 训练轮数\n",
    "    \"batch_size\": 16,  # 训练时每个批次的大小\n",
    "    \"learning_strategy\": {  # 优化函数相关的配置\n",
    "        \"lr\": 0.0005  # 学习率\n",
    "    },\n",
    "    \"skip_steps\": 5,  # 每N个批次打印一次结果\n",
    "    \"save_steps\": 100,  # 每N个批次保存一次模型参数\n",
    "    \"checkpoints\": \"/home/aistudio/work/logs\"  # 保存的路径\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "root=Path(target_path,'data')\n",
    "img_data=[]\n",
    "for id,_dir in enumerate(sorted(root.glob('*'))):\n",
    "    print(_dir)\n",
    "    lst_path=list(_dir.glob(\"*.jpg\"))\n",
    "    img_data.extend(zip(map(str,lst_path),[_dir.name]*len(lst_path),[id]*len(lst_path)))\n",
    "\n",
    "np.random.shuffle(img_data)\n",
    "\n",
    "df=pd.DataFrame(img_data,columns=['img','dir','label']).sample(frac=1)\n",
    "print(df.head())\n",
    "dic=df[['label','dir']].drop_duplicates()\n",
    "print(f'dic===:\\n{dic}')\n",
    "print(dic.describe())\n",
    "train_parameters['label_dict']={v:k for k,v in dic.to_records(index=False)}\n",
    "print(train_parameters['label_dict'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_imgs=len(df)\n",
    "num_train=int(0.8*num_imgs)\n",
    "num_eval=int(0.1*num_imgs)\n",
    "num_test=num_imgs-num_train-num_eval\n",
    "train_data=df[:num_train]\n",
    "eval_data=df[num_train:num_train+num_eval]\n",
    "test_data=df[-num_test:]\n",
    "\n",
    "train_data.reset_index(drop=True,inplace=True)\n",
    "eval_data.reset_index(drop=True,inplace=True)\n",
    "test_data.reset_index(drop=True,inplace=True)\n",
    "print(f'{num_train} {num_eval} {num_test}')\n",
    "train_data.to_json('train.json')\n",
    "eval_data.to_json('eval.json')\n",
    "test_data.to_json('test.json')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(train_data.iloc[0]['img'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DatasetTask(Dataset):\n",
    "    def __init__(self, train_parameters, _df):\n",
    "        \"\"\"\n",
    "        读取数据\n",
    "        params:\n",
    "                train_parameters: 参数字典\n",
    "                mode: train or val or test\n",
    "        \"\"\"\n",
    "        super(DatasetTask, self).__init__()\n",
    "        self.target_path = train_parameters['target_path']\n",
    "        self.input_size = train_parameters['input_size']\n",
    "        self._df=_df\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        获取一组数据\n",
    "        params:\n",
    "                index: 文件索引号\n",
    "        \"\"\"\n",
    "        # 第一步打开图像文件并获取label值\n",
    "        img_path = self._df.iloc[index]['img']\n",
    "        img = Image.open(img_path)\n",
    "        # 将数据集的图片大小统一缩放到指定大小\n",
    "        img = img.resize((self.input_size[1], self.input_size[2]), Image.ANTIALIAS)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        img = np.array(img).astype('float32')\n",
    "        img = img.transpose((2, 0, 1)) / 255\n",
    "        label = self._df.iloc[index]['label']\n",
    "        label = np.array([label], dtype=\"int64\")\n",
    "        return img, label\n",
    "\n",
    "    def print_sample(self, index: int = 0):\n",
    "        \"\"\" 打印示例 \"\"\"\n",
    "        print(\"文件名\", self._df.iloc[index]['img'], \"\\t标签值\", self._df.iloc[index]['label'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._df)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
