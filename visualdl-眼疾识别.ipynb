{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aistudio上[here](https://aistudio.baidu.com/aistudio/projectdetail/5056816?contributionType=1)\n",
    "# VisualDL2.0应用案例--眼疾识别训练可视化\n",
    "\n",
    "本项目将基于眼疾分类数据集[iChallenge-PM](https://ai.baidu.com/broad/introduction)，介绍如何运用飞桨可视化分析工具--VisualDL对模型训练过程进行可视化分析。\n",
    "\n",
    "VisualDL是深度学习模型可视化分析工具，以丰富的图表呈现训练参数变化趋势、模型结构、数据样本、高维数据分布等。帮助用户清晰直观地理解模型训练过程及模型结构，进而实现高效的模型调优。VisualDL的具体介绍请参考：[GitHub](https://github.com/PaddlePaddle/VisualDL)、[VisualDL使用指南](https://github.com/PaddlePaddle/VisualDL/blob/develop/docs/components/README.md)。\n",
    "\n",
    "iChallenge-PM是百度大脑和中山大学中山眼科中心联合举办的iChallenge比赛中，提供的关于病理性近视（Pathologic Myopia，PM）的医疗类数据集，包含1200个受试者的眼底视网膜图片，训练、验证和测试数据集各400张。下面我们将详细介绍如何使用VisualDL进行：\n",
    "\n",
    "- 创建日志文件\n",
    "- 实时训练参数可视化\n",
    "- 展示多组实验训练参数对比\n",
    "- 训练数据中间状态可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VisualDL2.0使用步骤\n",
    "\n",
    "- 创建日志文件`LogWriter`，设置实验结果存放路径，以'./log'为例\n",
    "- 训练过程中插入数据打点语句，将结果储存至日志文件中\n",
    "- 复制项目网址，并将网址中'notebooks'后的内容替换为'visualdl'（包含'notebook'），例如：\n",
    "\t* 将'https://aistudio.baidu.com/bdvgpu/user/220109/502834/notebooks/502834.ipynb?redirects=1'更改为'https://aistudio.baidu.com/bdvgpu/user/220109/502834/visualdl'\n",
    "- 打开浏览器输入网址即可启动VisualDL实现可视化\n",
    "\n",
    "\n",
    "***注意：使用VisualDL2.0需要Paddle版本1.8及以上**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集准备\n",
    "/home/aistudio/data/data19065 目录包括如下三个文件，解压缩后存放在/home/aistudio/work/palm目录下。\n",
    "- training.zip：包含训练中的图片和标签\n",
    "- validation.zip：包含验证集的图片\n",
    "- valid_gt.zip：包含验证集的标签\n",
    "\n",
    "\n",
    "------\n",
    "**注意**：\n",
    "\n",
    "valid_gt.zip文件解压缩之后，需要将/home/aistudio/work/palm/PALM-Validation-GT/目录下的PM_Label_and_Fovea_Location.xlsx文件转存成csv格式，本节代码示例中已经提前转成文件labels.csv。\n",
    "\n",
    "------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-30T12:54:32.696451Z",
     "iopub.status.busy": "2022-11-30T12:54:32.695681Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n",
      "/home/aistudio/work/palm/PALM-Training400\r\n"
     ]
    }
   ],
   "source": [
    "# 初次运行时将注释取消，以便解压文件\n",
    "# 如果已经解压过了，则不需要运行此段代码，否则文件已经存在解压会报错\n",
    "!unzip -o -q -d /home/aistudio/work/palm /home/aistudio/data/data19469//training.zip\n",
    "%cd /home/aistudio/work/palm/PALM-Training400/\n",
    "!unzip -o -q PALM-Training400.zip\n",
    "!unzip -o -q -d /home/aistudio/work/palm /home/aistudio/data/data19469/validation.zip\n",
    "!unzip -o -q -d /home/aistudio/work/palm /home/aistudio/data/data19469/valid_gt.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用VisualDL查看数据集\n",
    "\n",
    "iChallenge-PM中既有病理性近视患者的眼底图片，也有非病理性近视患者的图片，命名规则如下：\n",
    "\n",
    "- 病理性近视（PM）：文件名以P开头\n",
    "\n",
    "- 非病理性近视（non-PM）：\n",
    "\n",
    "  * 高度近似（high myopia）：文件名以H开头\n",
    "  \n",
    "  * 正常眼睛（normal）：文件名以N开头\n",
    "\n",
    "我们将病理性患者的图片作为正样本，标签为1； 非病理性患者的图片作为负样本，标签为0。从数据集中选取两张图片，通过LeNet提取特征，构建分类器，对正负样本进行分类，并将图片在VisualDL中显示出来。代码如下所示：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pillow==9.1.0  -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade visualdl  -i https://mirror.baidu.com/pypi/simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-30T12:56:12.661221Z",
     "iopub.status.busy": "2022-11-30T12:56:12.660391Z",
     "iopub.status.idle": "2022-11-30T12:56:14.649003Z",
     "shell.execute_reply": "2022-11-30T12:56:14.647653Z",
     "shell.execute_reply.started": "2022-11-30T12:56:12.661179Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Pillow\r\n",
      "Version: 9.1.0\r\n",
      "Summary: Python Imaging Library (Fork)\r\n",
      "Home-page: https://python-pillow.org\r\n",
      "Author: Alex Clark (PIL Fork Author)\r\n",
      "Author-email: aclark@python-pillow.org\r\n",
      "License: HPND\r\n",
      "Location: /home/aistudio/.data/webide/pip/lib/python3.7/site-packages\r\n",
      "Requires: \r\n",
      "Required-by: imageio, paddlehub, paddlepaddle-gpu, sahi, streamlit, tb-paddle, visualdl\r\n"
     ]
    }
   ],
   "source": [
    "!pip show pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:42:21.623479Z",
     "iopub.status.busy": "2022-12-01T14:42:21.623029Z",
     "iopub.status.idle": "2022-12-01T14:42:22.153371Z",
     "shell.execute_reply": "2022-12-01T14:42:22.152536Z",
     "shell.execute_reply.started": "2022-12-01T14:42:21.623404Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from visualdl import LogWriter\n",
    "\n",
    "\n",
    "def random_crop(img):\n",
    "    \"\"\"获取图片的随机 100x100 分片\n",
    "    \"\"\"\n",
    "    img = Image.open(img)\n",
    "    w, h = img.size\n",
    "    random_w = np.random.randint(0, w - 100)\n",
    "    random_h = np.random.randint(0, h - 100)\n",
    "    # 生成HWC格式的图片\n",
    "    r = img.crop((random_w, random_h, random_w + 100, random_h + 100))\n",
    "    return np.asarray(r)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 初始化一个记录器\n",
    "    with LogWriter(logdir=\"./log/image_test/train\") as writer:\n",
    "        for step in range(6):\n",
    "            # 添加一个图片数据\n",
    "            writer.add_image(tag=\"eye\",\n",
    "                             img=random_crop(\"/home/aistudio/work/palm/PALM-Training400/PALM-Training400/H0001.jpg\"),\n",
    "                             step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T14:42:23.175306Z",
     "iopub.status.busy": "2022-12-01T14:42:23.174590Z",
     "iopub.status.idle": "2022-12-01T14:42:23.770758Z",
     "shell.execute_reply": "2022-12-01T14:42:23.769790Z",
     "shell.execute_reply.started": "2022-12-01T14:42:23.175270Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from visualdl import LogWriter\n",
    "import os\n",
    "\n",
    "#确保路径为'/home/aistudio'\n",
    "os.chdir('/home/aistudio')\n",
    "\n",
    "#创建 LogWriter 对象，将图像数据存放在 `./log/train`路径下\n",
    "from visualdl import LogWriter\n",
    "log_writer = LogWriter(\"./log/train\")\n",
    "\n",
    "#导入所需展示的图片\n",
    "img1 = Image.open('work/palm/PALM-Training400/PALM-Training400/N0012.jpg')\n",
    "img2 = Image.open('work/palm/PALM-Training400/PALM-Training400/P0095.jpg')\n",
    "\n",
    "#将图片转化成array格式\n",
    "img_n1=np.asarray(img1)\n",
    "img_n2=np.asarray(img2)\n",
    "\n",
    "#将图片数据打点至日志文件\n",
    "log_writer.add_image(tag='图像样本/正样本',img=img_n2, step=5)\n",
    "log_writer.add_image(tag='图像样本/负样本',img=img_n1, step=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "启动VisualDL面板，查看图像数据：\n",
    "\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/5275ceb8083d4b2aa8e3f2bdc510a1625d6613da1c40412e81a62d0c7fca41e4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义数据读取器\n",
    "\n",
    "使用OpenCV从磁盘读入图片，将每张图缩放到$224\\times224$大小，并且将像素值调整到$[-1, 1]$之间，代码如下所示：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:42:26.798216Z",
     "iopub.status.busy": "2022-12-01T14:42:26.797841Z",
     "iopub.status.idle": "2022-12-01T14:42:26.812723Z",
     "shell.execute_reply": "2022-12-01T14:42:26.812056Z",
     "shell.execute_reply.started": "2022-12-01T14:42:26.798188Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 对读入的图像数据进行预处理\n",
    "def transform_img(img):\n",
    "    # 将图片尺寸缩放道 224x224\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    # 读入的图像数据格式是[H, W, C]\n",
    "    # 使用转置操作将其变成[C, H, W]\n",
    "    img = np.transpose(img, (2,0,1))\n",
    "    img = img.astype('float32')\n",
    "    # 将数据范围调整到[-1.0, 1.0]之间\n",
    "    img = img / 255.\n",
    "    img = img * 2.0 - 1.0\n",
    "    return img\n",
    "\n",
    "# 定义训练集数据读取器\n",
    "def data_loader(datadir, batch_size=10, mode = 'train'):\n",
    "    # 将datadir目录下的文件列出来，每条文件都要读入\n",
    "    filenames = os.listdir(datadir)\n",
    "    def reader():\n",
    "        if mode == 'train':\n",
    "            # 训练时随机打乱数据顺序\n",
    "            random.shuffle(filenames)\n",
    "        batch_imgs = []\n",
    "        batch_labels = []\n",
    "        for name in filenames:\n",
    "            filepath = os.path.join(datadir, name)\n",
    "            img = cv2.imread(filepath)\n",
    "            img = transform_img(img)\n",
    "            if name[0] == 'H' or name[0] == 'N':\n",
    "                # H开头的文件名表示高度近似，N开头的文件名表示正常视力\n",
    "                # 高度近视和正常视力的样本，都不是病理性的，属于负样本，标签为0\n",
    "                label = 0\n",
    "            elif name[0] == 'P':\n",
    "                # P开头的是病理性近视，属于正样本，标签为1\n",
    "                label = 1\n",
    "            else:\n",
    "                raise('Not excepted file name')\n",
    "            # 每读取一个样本的数据，就将其放入数据列表中\n",
    "            batch_imgs.append(img)\n",
    "            batch_labels.append(label)\n",
    "            if len(batch_imgs) == batch_size:\n",
    "                # 当数据列表的长度等于batch_size的时候，\n",
    "                # 把这些数据当作一个mini-batch，并作为数据生成器的一个输出\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "                yield imgs_array, labels_array\n",
    "                batch_imgs = []\n",
    "                batch_labels = []\n",
    "\n",
    "        if len(batch_imgs) > 0:\n",
    "            # 剩余样本数目不足一个batch_size的数据，一起打包成一个mini-batch\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "            yield imgs_array, labels_array\n",
    "\n",
    "    return reader\n",
    "\n",
    "# 定义验证集数据读取器\n",
    "def valid_data_loader(datadir, csvfile, batch_size=10, mode='valid'):\n",
    "    # 训练集读取时通过文件名来确定样本标签，验证集则通过csvfile来读取每个图片对应的标签\n",
    "    # 请查看解压后的验证集标签数据，观察csvfile文件里面所包含的内容\n",
    "    # csvfile文件所包含的内容格式如下，每一行代表一个样本，\n",
    "    # 其中第一列是图片id，第二列是文件名，第三列是图片标签，\n",
    "    # 第四列和第五列是Fovea的坐标，与分类任务无关\n",
    "    # ID,imgName,Label,Fovea_X,Fovea_Y\n",
    "    # 1,V0001.jpg,0,1157.74,1019.87\n",
    "    # 2,V0002.jpg,1,1285.82,1080.47\n",
    "    # 打开包含验证集标签的csvfile，并读入其中的内容\n",
    "    filelists = open(csvfile).readlines()\n",
    "    def reader():\n",
    "        batch_imgs = []\n",
    "        batch_labels = []\n",
    "        for line in filelists[1:]:\n",
    "            # print('valid_data_loader:',line)\n",
    "            line = line.strip().split(',')\n",
    "            name = line[1]\n",
    "            label = int(line[2])\n",
    "            # 根据图片文件名加载图片，并对图像数据作预处理\n",
    "            filepath = os.path.join(datadir, name)\n",
    "            img = cv2.imread(filepath)\n",
    "            img = transform_img(img)\n",
    "            # 每读取一个样本的数据，就将其放入数据列表中\n",
    "            batch_imgs.append(img)\n",
    "            batch_labels.append(label)\n",
    "            if len(batch_imgs) == batch_size:\n",
    "                # 当数据列表的长度等于batch_size的时候，\n",
    "                # 把这些数据当作一个mini-batch，并作为数据生成器的一个输出\n",
    "                imgs_array = np.array(batch_imgs).astype('float32')\n",
    "                labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "                yield imgs_array, labels_array\n",
    "                batch_imgs = []\n",
    "                batch_labels = []\n",
    "\n",
    "        if len(batch_imgs) > 0:\n",
    "            # 剩余样本数目不足一个batch_size的数据，一起打包成一个mini-batch\n",
    "            imgs_array = np.array(batch_imgs).astype('float32')\n",
    "            labels_array = np.array(batch_labels).astype('float32').reshape(-1, 1)\n",
    "            yield imgs_array, labels_array\n",
    "\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化第一组实验--使用LeNet网络进行眼疾分类\n",
    "\n",
    "- LeNet网络实现代码如下：\n",
    "\n",
    "***注意：需要在`forward`函数中导出每一层输出图片并储存于一个'list'中，后续才能将每一层输出写入日志文件进行可视化**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:42:31.369907Z",
     "iopub.status.busy": "2022-12-01T14:42:31.369113Z",
     "iopub.status.idle": "2022-12-01T14:42:32.732690Z",
     "shell.execute_reply": "2022-12-01T14:42:32.731602Z",
     "shell.execute_reply.started": "2022-12-01T14:42:31.369876Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导入需要的包\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "\n",
    "# 定义 LeNet 网络结构\n",
    "class LeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        self.conv1 = Conv2D(num_channels=3, num_filters=6, filter_size=5, act='sigmoid')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=6, num_filters=16, filter_size=5, act='sigmoid')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        # 创建第3个卷积层\n",
    "        self.conv3 = Conv2D(num_channels=16, num_filters=120, filter_size=4, act='sigmoid')\n",
    "        # 创建全连接层，第一个全连接层的输出神经元个数为64， 第二个全连接层输出神经元个数为分类标签的类别数\n",
    "        self.fc1 = Linear(input_dim=300000, output_dim=64, act='sigmoid')\n",
    "        self.fc2 = Linear(input_dim=64, output_dim=num_classes)\n",
    "    # 网络的前向计算过程，定义输出每一层的结果，后续将结果写入VisualDL日志文件，实现每一层输出图片的可视化\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.pool1(x1)\n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.pool2(x3)\n",
    "        x5 = self.conv3(x4)\n",
    "        x6 = fluid.layers.reshape(x5, [x5.shape[0], -1])\n",
    "        x7 = self.fc1(x6)\n",
    "        x8 = self.fc2(x7)\n",
    "        conv=[x,x1,x2,x3,x4,x5,x6,x7,x8]\n",
    "        return x8,conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-11-30T12:56:46.947933Z",
     "iopub.status.busy": "2022-11-30T12:56:46.947269Z",
     "iopub.status.idle": "2022-11-30T12:56:47.594165Z",
     "shell.execute_reply": "2022-11-30T12:56:47.593352Z",
     "shell.execute_reply.started": "2022-11-30T12:56:46.947886Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 3, 224, 224), (10, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看数据形状\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\n",
    "train_loader = data_loader(DATADIR, \n",
    "                           batch_size=10, mode='train')\n",
    "data_reader = train_loader()\n",
    "data = next(data_reader)\n",
    "data[0].shape, data[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型并使用VisualDL可视化训练参数及数据样本\n",
    "- 创建LeNet日志文件，以便对比其他模型训练参数，代码如下：\n",
    "\n",
    "log_writer = LogWriter(\"./log/lenet\")\n",
    "\n",
    "- 训练过程中插入作图语句，展示accuracy和loss的变化趋势：\n",
    "\n",
    "log_writer.add_scalar(tag='acc', step=iter, value=acc.numpy())\n",
    "\n",
    "log_writer.add_scalar(tag='loss', step=iter, value=avg_loss.numpy())\n",
    "\n",
    "- 设计网络向前计算过程时，将每一层的输出储存于名为'conv'的list中，方便后续写入日志文件\n",
    "\n",
    "- 训练过程中插入作图语句，展示输入图片在每一层网络的输出\n",
    "\n",
    "log_writer.add_image(tag='input_lenet/conv_1', img=conv[0].numpy(), step=batch_id)\n",
    "\n",
    "***注意使用相同tag才能实现多组模型实验对比**\n",
    "\n",
    "#### 完整训练及可视化代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T14:42:40.638420Z",
     "iopub.status.busy": "2022-12-01T14:42:40.637440Z",
     "iopub.status.idle": "2022-12-01T14:42:40.642453Z",
     "shell.execute_reply": "2022-12-01T14:42:40.641681Z",
     "shell.execute_reply.started": "2022-12-01T14:42:40.638387Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def convert_out_img(_img):\n",
    "    # print(_img.shape)    \n",
    "    _img=_img.numpy()+1    \n",
    "    if len(_img.shape)==3:_img=np.transpose(_img,(1,2,0))\n",
    "    _img=_img*127.5\n",
    "    return _img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T14:42:42.698800Z",
     "iopub.status.busy": "2022-12-01T14:42:42.698421Z",
     "iopub.status.idle": "2022-12-01T14:45:14.086402Z",
     "shell.execute_reply": "2022-12-01T14:45:14.085427Z",
     "shell.execute_reply.started": "2022-12-01T14:42:42.698770Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 22:42:42,865-INFO: font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\r\n",
      "2022-12-01 22:42:43,208-INFO: generated new fontManager\r\n",
      "W1201 22:42:43.293185   222 device_context.cc:252] Please NOTE: device: 0, CUDA Capability: 70, Driver API Version: 11.2, Runtime API Version: 9.0\r\n",
      "W1201 22:42:43.296937   222 device_context.cc:260] device: 0, cuDNN Version: 7.6.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\r\n",
      "train model\r\n",
      "start training ... \r\n",
      "epoch: 0, batch_id: 0, loss is: [0.69579124] acc [0.5]\r\n",
      "epoch: 0, batch_id: 10, loss is: [0.8092405] acc [0.5]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 20, loss is: [0.6578455] acc [0.7]\r\n",
      "epoch: 0, batch_id: 30, loss is: [0.6947677] acc [0.4]\r\n",
      "pred [[0.5126238 ]\r\n",
      " [0.51271063]\r\n",
      " [0.51269174]\r\n",
      " [0.5125851 ]\r\n",
      " [0.51254845]\r\n",
      " [0.5125189 ]\r\n",
      " [0.5125436 ]\r\n",
      " [0.5127212 ]\r\n",
      " [0.5126487 ]\r\n",
      " [0.51259047]]\r\n",
      "pred2 [[0.4873762 ]\r\n",
      " [0.48728937]\r\n",
      " [0.48730826]\r\n",
      " [0.4874149 ]\r\n",
      " [0.48745155]\r\n",
      " [0.48748112]\r\n",
      " [0.48745638]\r\n",
      " [0.48727882]\r\n",
      " [0.4873513 ]\r\n",
      " [0.48740953]]\r\n",
      "concat后，pred [[0.4873762  0.5126238 ]\r\n",
      " [0.48728937 0.51271063]\r\n",
      " [0.48730826 0.51269174]\r\n",
      " [0.4874149  0.5125851 ]\r\n",
      " [0.48745155 0.51254845]\r\n",
      " [0.48748112 0.5125189 ]\r\n",
      " [0.48745638 0.5125436 ]\r\n",
      " [0.48727882 0.5127212 ]\r\n",
      " [0.4873513  0.5126487 ]\r\n",
      " [0.48740953 0.51259047]]\r\n",
      "[validation] accuracy/loss: 0.30000001192092896/0.703454852104187\r\n",
      "epoch: 1, batch_id: 0, loss is: [0.67821574] acc [0.8]\r\n",
      "epoch: 1, batch_id: 10, loss is: [0.720326] acc [0.3]\r\n",
      "epoch: 1, batch_id: 20, loss is: [0.6815664] acc [0.8]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, batch_id: 30, loss is: [0.6856409] acc [0.6]\r\n",
      "pred [[0.521613  ]\r\n",
      " [0.5216748 ]\r\n",
      " [0.52166367]\r\n",
      " [0.5215772 ]\r\n",
      " [0.5215587 ]\r\n",
      " [0.52154374]\r\n",
      " [0.52156126]\r\n",
      " [0.521678  ]\r\n",
      " [0.5216254 ]\r\n",
      " [0.5215876 ]]\r\n",
      "pred2 [[0.478387  ]\r\n",
      " [0.4783252 ]\r\n",
      " [0.47833633]\r\n",
      " [0.47842282]\r\n",
      " [0.4784413 ]\r\n",
      " [0.47845626]\r\n",
      " [0.47843874]\r\n",
      " [0.47832203]\r\n",
      " [0.4783746 ]\r\n",
      " [0.4784124 ]]\r\n",
      "concat后，pred [[0.478387   0.521613  ]\r\n",
      " [0.4783252  0.5216748 ]\r\n",
      " [0.47833633 0.52166367]\r\n",
      " [0.47842282 0.5215772 ]\r\n",
      " [0.4784413  0.5215587 ]\r\n",
      " [0.47845626 0.52154374]\r\n",
      " [0.47843874 0.52156126]\r\n",
      " [0.47832203 0.521678  ]\r\n",
      " [0.4783746  0.5216254 ]\r\n",
      " [0.4784124  0.5215876 ]]\r\n",
      "[validation] accuracy/loss: 0.30000001192092896/0.711302638053894\r\n",
      "epoch: 2, batch_id: 0, loss is: [0.6853463] acc [0.6]\r\n",
      "epoch: 2, batch_id: 10, loss is: [0.6862491] acc [0.7]\r\n",
      "epoch: 2, batch_id: 20, loss is: [0.6953396] acc [0.4]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, batch_id: 30, loss is: [0.68917084] acc [0.6]\r\n",
      "pred [[0.5495572 ]\r\n",
      " [0.5496324 ]\r\n",
      " [0.5496178 ]\r\n",
      " [0.5495182 ]\r\n",
      " [0.5494985 ]\r\n",
      " [0.5494904 ]\r\n",
      " [0.54950666]\r\n",
      " [0.5496312 ]\r\n",
      " [0.54956865]\r\n",
      " [0.5495304 ]]\r\n",
      "pred2 [[0.4504428 ]\r\n",
      " [0.45036763]\r\n",
      " [0.45038217]\r\n",
      " [0.45048177]\r\n",
      " [0.4505015 ]\r\n",
      " [0.4505096 ]\r\n",
      " [0.45049334]\r\n",
      " [0.45036882]\r\n",
      " [0.45043135]\r\n",
      " [0.4504696 ]]\r\n",
      "concat后，pred [[0.4504428  0.5495572 ]\r\n",
      " [0.45036763 0.5496324 ]\r\n",
      " [0.45038217 0.5496178 ]\r\n",
      " [0.45048177 0.5495182 ]\r\n",
      " [0.4505015  0.5494985 ]\r\n",
      " [0.4505096  0.5494904 ]\r\n",
      " [0.45049334 0.54950666]\r\n",
      " [0.45036882 0.5496312 ]\r\n",
      " [0.45043135 0.54956865]\r\n",
      " [0.4504696  0.5495304 ]]\r\n",
      "[validation] accuracy/loss: 0.30000001192092896/0.7377703785896301\r\n",
      "epoch: 3, batch_id: 0, loss is: [0.6383264] acc [0.8]\r\n",
      "epoch: 3, batch_id: 10, loss is: [0.6733761] acc [0.6]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, batch_id: 20, loss is: [0.75188196] acc [0.2]\r\n",
      "epoch: 3, batch_id: 30, loss is: [0.70675117] acc [0.4]\r\n",
      "pred [[0.52727354]\r\n",
      " [0.5273216 ]\r\n",
      " [0.5273153 ]\r\n",
      " [0.52725005]\r\n",
      " [0.5272394 ]\r\n",
      " [0.5272305 ]\r\n",
      " [0.52724147]\r\n",
      " [0.52731997]\r\n",
      " [0.52728534]\r\n",
      " [0.52725583]]\r\n",
      "pred2 [[0.47272646]\r\n",
      " [0.47267842]\r\n",
      " [0.47268468]\r\n",
      " [0.47274995]\r\n",
      " [0.47276062]\r\n",
      " [0.4727695 ]\r\n",
      " [0.47275853]\r\n",
      " [0.47268003]\r\n",
      " [0.47271466]\r\n",
      " [0.47274417]]\r\n",
      "concat后，pred [[0.47272646 0.52727354]\r\n",
      " [0.47267842 0.5273216 ]\r\n",
      " [0.47268468 0.5273153 ]\r\n",
      " [0.47274995 0.52725005]\r\n",
      " [0.47276062 0.5272394 ]\r\n",
      " [0.4727695  0.5272305 ]\r\n",
      " [0.47275853 0.52724147]\r\n",
      " [0.47268003 0.52731997]\r\n",
      " [0.47271466 0.52728534]\r\n",
      " [0.47274417 0.52725583]]\r\n",
      "[validation] accuracy/loss: 0.30000001192092896/0.716422438621521\r\n",
      "epoch: 4, batch_id: 0, loss is: [0.66182554] acc [0.8]\r\n",
      "epoch: 4, batch_id: 10, loss is: [0.70763093] acc [0.3]\r\n",
      "epoch: 4, batch_id: 20, loss is: [0.6931961] acc [0.5]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, batch_id: 30, loss is: [0.69379306] acc [0.5]\r\n",
      "pred [[0.5465    ]\r\n",
      " [0.54655546]\r\n",
      " [0.5465472 ]\r\n",
      " [0.546474  ]\r\n",
      " [0.5464621 ]\r\n",
      " [0.54645467]\r\n",
      " [0.54646605]\r\n",
      " [0.5465523 ]\r\n",
      " [0.5465122 ]\r\n",
      " [0.5464808 ]]\r\n",
      "pred2 [[0.45349997]\r\n",
      " [0.45344454]\r\n",
      " [0.45345283]\r\n",
      " [0.45352602]\r\n",
      " [0.45353788]\r\n",
      " [0.45354533]\r\n",
      " [0.45353395]\r\n",
      " [0.4534477 ]\r\n",
      " [0.4534878 ]\r\n",
      " [0.45351923]]\r\n",
      "concat后，pred [[0.45349997 0.5465    ]\r\n",
      " [0.45344454 0.54655546]\r\n",
      " [0.45345283 0.5465472 ]\r\n",
      " [0.45352602 0.546474  ]\r\n",
      " [0.45353788 0.5464621 ]\r\n",
      " [0.45354533 0.54645467]\r\n",
      " [0.45353395 0.54646605]\r\n",
      " [0.4534477  0.5465523 ]\r\n",
      " [0.4534878  0.5465122 ]\r\n",
      " [0.45351923 0.5464808 ]]\r\n",
      "[validation] accuracy/loss: 0.30000001192092896/0.7347368001937866\r\n"
     ]
    }
   ],
   "source": [
    "# LeNet 识别眼疾图片\n",
    "\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "#创建日志文件，储存lenet训练结果\n",
    "date_str=datetime.datetime.strftime(datetime.datetime.now(),'%Y%m%d_%H%M%S')\n",
    "log_dir=os.path.join('./log/lenet')\n",
    "log_writer = LogWriter(log_dir)\n",
    "\n",
    "#定义文件路径\n",
    "DATADIR = '/home/aistudio/work/palm/PALM-Training400/PALM-Training400'\n",
    "DATADIR2 = '/home/aistudio/work/palm/PALM-Validation400'\n",
    "CSVFILE = '/home/aistudio/labels.csv'\n",
    "from matplotlib import pyplot as plt\n",
    "# 定义训练过程\n",
    "def train(model):\n",
    "    print('train model')\n",
    "    with fluid.dygraph.guard():\n",
    "        print('start training ... ')\n",
    "        model.train()\n",
    "        epoch_num = 5\n",
    "        iter=0\n",
    "        # 定义优化器\n",
    "        opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\n",
    "        # 定义数据读取器，训练数据读取器和验证数据读取器\n",
    "        train_loader = data_loader(DATADIR, batch_size=10, mode='train')\n",
    "        valid_loader = valid_data_loader(DATADIR2, CSVFILE)\n",
    "        for epoch in range(epoch_num):\n",
    "            # if epoch>0:break\n",
    "            for batch_id, data in enumerate(train_loader()):\n",
    "                # if batch_id>0:break\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)               \n",
    "                log_writer.add_image(tag='input_lenet/original', img=convert_out_img(conv[0]),dataformats=\"NCHW\", step=batch_id)             \n",
    "                log_writer.add_image(tag='input_lenet/pool_1', img=convert_out_img(conv[1][:,:4]),dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_lenet/conv_2', img=convert_out_img(conv[2][:,:4]),dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_lenet/pool_2', img=convert_out_img(conv[3][:,:4]),dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_lenet/conv_3', img=convert_out_img(conv[5][:,:4]),dataformats=\"NCHW\", step=batch_id)\n",
    "                # log_writer.add_image(tag='input_lenet/reshape', img=conv[6].numpy(), step=batch_id)\n",
    "                # log_writer.add_image(tag='input_lenet/fc1', img=conv[7].numpy(), step=batch_id)\n",
    "                # log_writer.add_image(tag='input_lenet/fc2', img=conv[8].numpy(), step=batch_id)\n",
    "                #计算accuracy\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                # 进行loss计算\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                #训练过程中插入作图语句，当每10个batch训练完成后，将当前损失、准确率作为一个新增的数据点储存到记录器中。\n",
    "                if batch_id % 10 == 0:\n",
    "                    log_writer.add_scalar(tag='train/acc', step=iter, value=acc.numpy())\n",
    "                    log_writer.add_scalar(tag='train/loss', step=iter, value=avg_loss.numpy())\n",
    "\n",
    "                    iter+=10\n",
    "                    print(\"epoch: {}, batch_id: {}, loss is: {} acc {}\".format(epoch, batch_id, avg_loss.numpy(),acc.numpy()))\n",
    "                # 反向传播，更新权重，清除梯度\n",
    "                avg_loss.backward()\n",
    "                opt.minimize(avg_loss)\n",
    "                model.clear_gradients()\n",
    "\n",
    "            model.eval()\n",
    "            accuracies = []\n",
    "            losses = []\n",
    "            for batch_id, data in enumerate(valid_loader()):\n",
    "                if batch_id>0:break\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "                # 计算sigmoid后的预测概率，进行loss计算\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                # 计算预测概率小于0.5的类别\n",
    "                print('pred',pred.numpy())\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                print('pred2',pred2.numpy())\n",
    "                # 得到两个类别的预测概率，并沿第一个维度级联\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                print('concat后，pred',pred.numpy())\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                accuracies.append(acc.numpy())\n",
    "                losses.append(loss.numpy())\n",
    "            print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "            model.train()\n",
    "\n",
    "        # save params of model\n",
    "        fluid.save_dygraph(model.state_dict(), 'mnist')\n",
    "        # save optimizer state\n",
    "        fluid.save_dygraph(opt.state_dict(), 'mnist')\n",
    "\n",
    "\n",
    "# 定义评估过程\n",
    "def evaluation(model, params_file_path):\n",
    "    with fluid.dygraph.guard():\n",
    "        print('start evaluation .......')\n",
    "        #加载模型参数\n",
    "        model_state_dict, _ = fluid.load_dygraph(params_file_path)\n",
    "        model.load_dict(model_state_dict)\n",
    "\n",
    "        model.eval()\n",
    "        eval_loader = load_data('eval')\n",
    "\n",
    "        acc_set = []\n",
    "        avg_loss_set = []\n",
    "        for batch_id, data in enumerate(eval_loader()):\n",
    "            x_data, y_data = data\n",
    "            img = fluid.dygraph.to_variable(x_data)\n",
    "            label = fluid.dygraph.to_variable(y_data)\n",
    "            # 计算预测和精度\n",
    "            prediction, acc = model(img, label)\n",
    "            # 计算损失函数值\n",
    "            loss = fluid.layers.cross_entropy(input=prediction, label=label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            acc_set.append(float(acc.numpy()))\n",
    "            avg_loss_set.append(float(avg_loss.numpy()))\n",
    "        # 求平均精度\n",
    "        acc_val_mean = np.array(acc_set).mean()\n",
    "        avg_loss_val_mean = np.array(avg_loss_set).mean()\n",
    "\n",
    "        print('loss={}, acc={}'.format(avg_loss_val_mean, acc_val_mean))\n",
    "\n",
    "# 定义 LeNet 网络结构\n",
    "class LeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(LeNet, self).__init__()\n",
    "\n",
    "        # 创建卷积和池化层块，每个卷积层使用Sigmoid激活函数，后面跟着一个2x2的池化\n",
    "        self.conv1 = Conv2D(num_channels=3, num_filters=6, filter_size=5, act='sigmoid')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=6, num_filters=16, filter_size=5, act='sigmoid')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        # 创建第3个卷积层\n",
    "        self.conv3 = Conv2D(num_channels=16, num_filters=120, filter_size=4, act='sigmoid')\n",
    "        # 创建全连接层，第一个全连接层的输出神经元个数为64， 第二个全连接层输出神经元个数为分类标签的类别数\n",
    "        self.fc1 = Linear(input_dim=300000, output_dim=64, act='sigmoid')\n",
    "        self.fc2 = Linear(input_dim=64, output_dim=num_classes)\n",
    "    # 网络的前向计算过程，定义输出每一层的结果，后续将结果写入VisualDL日志文件，实现每一层输出图片的可视化\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        #print(x1.shape)\n",
    "        x2 = self.pool1(x1)\n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.pool2(x3)\n",
    "        x5 = self.conv3(x4)\n",
    "        x6 = fluid.layers.reshape(x5, [x5.shape[0], -1])\n",
    "        x7 = self.fc1(x6)\n",
    "        x8 = self.fc2(x7)\n",
    "        conv=[x,x1,x2,x3,x4,x5,x6,x7,x8]\n",
    "        return x8,conv\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     # 创建模型\n",
    "with fluid.dygraph.guard():\n",
    "    model = LeNet(num_classes=1)\n",
    "print('model')\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**运行结束后，有两种选择**\n",
    "- 可选择直接启动VisualDL面板查看LeNet模型效果\n",
    "- 继续训练以下模型，所有模型训练完成后再启动VisualDL查看不同模型的训练效果对比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化第二组实验--使用AlexNet网络进行眼疾分类\n",
    "\n",
    "- AlexNet网络实现代码如下：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T14:45:17.869012Z",
     "iopub.status.busy": "2022-12-01T14:45:17.868517Z",
     "iopub.status.idle": "2022-12-01T14:45:17.880503Z",
     "shell.execute_reply": "2022-12-01T14:45:17.879851Z",
     "shell.execute_reply.started": "2022-12-01T14:45:17.868986Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# 导入需要的包\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import numpy as np\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "\n",
    "\n",
    "# 定义 AlexNet 网络结构\n",
    "class AlexNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(AlexNet, self).__init__()\n",
    "        \n",
    "        # AlexNet与LeNet一样也会同时使用卷积和池化层提取图像特征\n",
    "        # 与LeNet不同的是激活函数换成了‘relu’\n",
    "        self.conv1 = Conv2D(num_channels=3, num_filters=96, filter_size=11, stride=4, padding=5, act='relu')\n",
    "        self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv2 = Conv2D(num_channels=96, num_filters=256, filter_size=5, stride=1, padding=2, act='relu')\n",
    "        self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "        self.conv3 = Conv2D(num_channels=256, num_filters=384, filter_size=3, stride=1, padding=1, act='relu')\n",
    "        self.conv4 = Conv2D(num_channels=384, num_filters=384, filter_size=3, stride=1, padding=1, act='relu')\n",
    "        self.conv5 = Conv2D(num_channels=384, num_filters=256, filter_size=3, stride=1, padding=1, act='relu')\n",
    "        self.pool5 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "\n",
    "        self.fc1 = Linear(input_dim=12544, output_dim=4096, act='relu')\n",
    "        self.drop_ratio1 = 0.5\n",
    "        self.fc2 = Linear(input_dim=4096, output_dim=4096, act='relu')\n",
    "        self.drop_ratio2 = 0.5\n",
    "        self.fc3 = Linear(input_dim=4096, output_dim=num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.pool1(x1)\n",
    "        x3 = self.conv2(x2)\n",
    "        x4 = self.pool2(x3)\n",
    "        x5 = self.conv3(x4)\n",
    "        x6 = self.conv4(x5)\n",
    "        x7 = self.conv5(x6)\n",
    "        x8 = self.pool5(x7)\n",
    "        x9 = fluid.layers.reshape(x8, [x8.shape[0], -1])\n",
    "        x10 = self.fc1(x9)\n",
    "        # 在全连接之后使用dropout抑制过拟合\n",
    "        x10= fluid.layers.dropout(x10, self.drop_ratio1)\n",
    "        x10 = self.fc2(x10)\n",
    "        # 在全连接之后使用dropout抑制过拟合\n",
    "        x10 = fluid.layers.dropout(x10, self.drop_ratio2)\n",
    "        x10 = self.fc3(x10)\n",
    "        conv=[x,x1,x2,x3,x4,x5,x6,x7,x8,x9,x10]\n",
    "        return x10, conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型并使用VisualDL可视化训练参数及数据样本\n",
    "- 创建AlexNet日志文件，以便对比其他模型训练参数，代码如下：\n",
    "\n",
    "log_writer = LogWriter(\"./log/alexnet\")\n",
    "\n",
    "- 训练过程中插入作图语句，展示accuracy和loss的变化趋势：\n",
    "\n",
    "log_writer.add_scalar(tag='acc', step=iter, value=acc.numpy())\n",
    "\n",
    "log_writer.add_scalar(tag='loss', step=iter, value=avg_loss.numpy())\n",
    "\n",
    "- 设计网络向前计算过程时，将每一层的输出储存于名为'conv'的list中，方便后续写入日志文件\n",
    "\n",
    "- 训练过程中插入作图语句，展示输入图片在每一层网络的输出\n",
    "\n",
    "log_writer.add_image(tag='input_alexnet/conv_1', img=conv[0].numpy(), step=batch_id)\n",
    "\n",
    "***注意使用相同tag才能实现多组模型实验对比**\n",
    "\n",
    "#### 完整训练及可视化代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T14:45:24.346633Z",
     "iopub.status.busy": "2022-12-01T14:45:24.346063Z",
     "iopub.status.idle": "2022-12-01T14:49:45.020278Z",
     "shell.execute_reply": "2022-12-01T14:49:45.019179Z",
     "shell.execute_reply.started": "2022-12-01T14:45:24.346602Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \r\n",
      "epoch: 0, batch_id: 0, loss is: [0.7688733]\r\n",
      "epoch: 0, batch_id: 10, loss is: [0.86218554]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 20, loss is: [0.4846797]\r\n",
      "epoch: 0, batch_id: 30, loss is: [0.7140993]\r\n",
      "[validation] accuracy/loss: 0.7425000071525574/0.613825798034668\r\n",
      "epoch: 1, batch_id: 0, loss is: [0.6335093]\r\n",
      "epoch: 1, batch_id: 10, loss is: [0.48883742]\r\n",
      "epoch: 1, batch_id: 20, loss is: [0.5731732]\r\n",
      "epoch: 1, batch_id: 30, loss is: [0.42922032]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[validation] accuracy/loss: 0.9125000238418579/0.3493860363960266\r\n",
      "epoch: 2, batch_id: 0, loss is: [0.4302479]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, batch_id: 10, loss is: [0.21872629]\r\n",
      "epoch: 2, batch_id: 20, loss is: [0.48957294]\r\n",
      "epoch: 2, batch_id: 30, loss is: [0.17584175]\r\n",
      "[validation] accuracy/loss: 0.9100000262260437/0.2691851854324341\r\n",
      "epoch: 3, batch_id: 0, loss is: [0.6128808]\r\n",
      "epoch: 3, batch_id: 10, loss is: [0.20954657]\r\n",
      "epoch: 3, batch_id: 20, loss is: [0.28138608]\r\n",
      "epoch: 3, batch_id: 30, loss is: [0.12840594]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[validation] accuracy/loss: 0.925000011920929/0.22186213731765747\r\n",
      "epoch: 4, batch_id: 0, loss is: [0.23191528]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, batch_id: 10, loss is: [0.35504922]\r\n",
      "epoch: 4, batch_id: 20, loss is: [0.0974201]\r\n",
      "epoch: 4, batch_id: 30, loss is: [0.4901902]\r\n",
      "[validation] accuracy/loss: 0.9274999499320984/0.18138444423675537\r\n"
     ]
    }
   ],
   "source": [
    "#创建储存alexnet结果的日志文件夹\n",
    "log_writer = LogWriter(\"./log/alexnet\")\n",
    "# 定义训练过程\n",
    "def train(model):\n",
    "    with fluid.dygraph.guard():\n",
    "        print('start training ... ')\n",
    "        model.train()\n",
    "        epoch_num = 5\n",
    "        iter=0\n",
    "        # 定义优化器\n",
    "        opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\n",
    "        # 定义数据读取器，训练数据读取器和验证数据读取器\n",
    "        train_loader = data_loader(DATADIR, batch_size=10, mode='train')\n",
    "        valid_loader = valid_data_loader(DATADIR2, CSVFILE)\n",
    "        for epoch in range(epoch_num):\n",
    "            for batch_id, data in enumerate(train_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                #将每一层输出的图片数据转成numpy array格式并写入日志文件\n",
    "                log_writer.add_image(tag='input_alexnet/original', img=convert_out_img(conv[0]), dataformats=\"NCHW\",step=batch_id)\n",
    "                log_writer.add_image(tag='input_alexnet/conv_1', img=convert_out_img(conv[1][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_alexnet/pool_1', img=convert_out_img(conv[2][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_alexnet/conv_2', img=convert_out_img(conv[3][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_alexnet/pool_2', img=convert_out_img(conv[4][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_alexnet/conv_3', img=convert_out_img(conv[5][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_alexnet/conv_4', img=convert_out_img(conv[6][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_alexnet/conv_5', img=convert_out_img(conv[7][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                # log_writer.add_image(tag='input_alexnet/pool_5', img=conv[8].numpy(), step=batch_id)\n",
    "                # log_writer.add_image(tag='input_alexnet/reshape', img=conv[9].numpy(), step=batch_id)\n",
    "                # log_writer.add_image(tag='input_alexnet/fc', img=conv[10].numpy(), step=batch_id)\n",
    "                # #计算accuracy\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                # 进行loss计算\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                #训练过程中插入作图语句，当每10个batch训练完成后，将当前损失、准确率作为一个新增的数据点储存到记录器中。\n",
    "                if batch_id % 10 == 0:\n",
    "                    log_writer.add_scalar(tag='train/acc', step=iter, value=acc.numpy())\n",
    "                    log_writer.add_scalar(tag='train/loss', step=iter, value=avg_loss.numpy())\n",
    "                    iter+=10\n",
    "                    print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "                # 反向传播，更新权重，清除梯度\n",
    "                avg_loss.backward()\n",
    "                opt.minimize(avg_loss)\n",
    "                model.clear_gradients()\n",
    "\n",
    "            model.eval()\n",
    "            accuracies = []\n",
    "            losses = []\n",
    "            for batch_id, data in enumerate(valid_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "                # 计算sigmoid后的预测概率，进行loss计算\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                # 计算预测概率小于0.5的类别\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                # 得到两个类别的预测概率，并沿第一个维度级联\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                accuracies.append(acc.numpy())\n",
    "                losses.append(loss.numpy())\n",
    "            print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "            model.train()\n",
    "\n",
    "        # save params of model\n",
    "        fluid.save_dygraph(model.state_dict(), 'mnist')\n",
    "        # save optimizer state\n",
    "        fluid.save_dygraph(opt.state_dict(), 'mnist')\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    model = AlexNet()\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**运行结束后，有两种选择**\n",
    "- 可选择直接启动VisualDL面板查看AlexNet和LeNet的accuracy和loss对比\n",
    "- 继续训练以下模型，所有模型训练完成后再启动VisualDL查看不同模型的训练效果对比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化第三组实验--使用VGG网络进行眼疾分类\n",
    "\n",
    "- VGG网络实现代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T14:55:02.744451Z",
     "iopub.status.busy": "2022-12-01T14:55:02.743914Z",
     "iopub.status.idle": "2022-12-01T14:55:02.756546Z",
     "shell.execute_reply": "2022-12-01T14:55:02.755926Z",
     "shell.execute_reply.started": "2022-12-01T14:55:02.744422Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# VGG模型代码\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.layer_helper import LayerHelper\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "\n",
    "# 定义vgg块，包含多层卷积和1层2x2的最大池化层\n",
    "class vgg_block(fluid.dygraph.Layer):\n",
    "    def __init__(self, num_convs, in_channels, out_channels):\n",
    "        \"\"\"\n",
    "        num_convs, 卷积层的数目\n",
    "        num_channels, 卷积层的输出通道数，在同一个Incepition块内，卷积层输出通道数是一样的\n",
    "        \"\"\"\n",
    "        super(vgg_block, self).__init__()\n",
    "        self.conv_list = []\n",
    "        for i in range(num_convs):\n",
    "            conv_layer = self.add_sublayer('conv_' + str(i), Conv2D(num_channels=in_channels, \n",
    "                                        num_filters=out_channels, filter_size=3, padding=1, act='relu'))\n",
    "            self.conv_list.append(conv_layer)\n",
    "            in_channels = out_channels\n",
    "        self.pool = Pool2D(pool_stride=2, pool_size = 2, pool_type='max')\n",
    "    def forward(self, x):\n",
    "        for item in self.conv_list:\n",
    "            x = item(x)\n",
    "        return self.pool(x)\n",
    "\n",
    "class VGG(fluid.dygraph.Layer):\n",
    "    def __init__(self, conv_arch=((2, 64), \n",
    "                                (2, 128), (3, 256), (3, 512), (3, 512))):\n",
    "        super(VGG, self).__init__()\n",
    "        self.vgg_blocks=[]\n",
    "        iter_id = 0\n",
    "        # 添加vgg_block\n",
    "        # 这里一共5个vgg_block，每个block里面的卷积层数目和输出通道数由conv_arch指定\n",
    "        in_channels = [3, 64, 128, 256, 512, 512]\n",
    "        for (num_convs, num_channels) in conv_arch:\n",
    "            block = self.add_sublayer('block_' + str(iter_id), \n",
    "                    vgg_block(num_convs, in_channels=in_channels[iter_id], \n",
    "                              out_channels=num_channels))\n",
    "            self.vgg_blocks.append(block)\n",
    "            iter_id += 1\n",
    "        self.fc1 = Linear(input_dim=512*7*7, output_dim=4096,\n",
    "                      act='relu')\n",
    "        self.drop1_ratio = 0.5\n",
    "        self.fc2= Linear(input_dim=4096, output_dim=4096,\n",
    "                      act='relu')\n",
    "        self.drop2_ratio = 0.5\n",
    "        self.fc3 = Linear(input_dim=4096, output_dim=1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x=input\n",
    "        for item in self.vgg_blocks:\n",
    "            x = item(x)\n",
    "        x1 = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "        x2 = fluid.layers.dropout(self.fc1(x1), self.drop1_ratio)\n",
    "        x3 = fluid.layers.dropout(self.fc2(x2), self.drop2_ratio)\n",
    "        x4 = self.fc3(x3)\n",
    "        conv=[input,x,x1,x2,x3,x4]\n",
    "        return x4,conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型并使用VisualDL可视化训练参数及数据样本\n",
    "- 创建vgg日志文件，以便对比其他模型训练参数，代码如下：\n",
    "\n",
    "log_writer = LogWriter(\"./log/vgg\")\n",
    "\n",
    "- 训练过程中插入作图语句，展示accuracy和loss的变化趋势：\n",
    "\n",
    "log_writer.add_scalar(tag='acc', step=iter, value=acc.numpy())\n",
    "\n",
    "log_writer.add_scalar(tag='loss', step=iter, value=avg_loss.numpy())\n",
    "\n",
    "- 设计网络向前计算过程时，将每一层的输出储存于名为'conv'的list中，方便后续写入日志文件\n",
    "\n",
    "- 训练过程中插入作图语句，展示输入图片在每一层网络的输出\n",
    "\n",
    "log_writer.add_image(tag='input_vgg/conv_1', img=conv[0].numpy(), step=batch_id)\n",
    "\n",
    "***注意使用相同tag才能实现多组模型实验对比**\n",
    "\n",
    "#### 完整训练及可视化代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T14:55:36.791496Z",
     "iopub.status.busy": "2022-12-01T14:55:36.790813Z",
     "iopub.status.idle": "2022-12-01T15:00:14.494108Z",
     "shell.execute_reply": "2022-12-01T15:00:14.492676Z",
     "shell.execute_reply.started": "2022-12-01T14:55:36.791469Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \r\n",
      "epoch: 0, batch_id: 0, loss is: [0.752526]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 10, loss is: [0.82166547]\r\n",
      "epoch: 0, batch_id: 20, loss is: [0.7532598]\r\n",
      "epoch: 0, batch_id: 30, loss is: [0.5577036]\r\n",
      "[validation] accuracy/loss: 0.5275000333786011/0.66121506690979\r\n",
      "epoch: 1, batch_id: 0, loss is: [0.72483516]\r\n",
      "epoch: 1, batch_id: 10, loss is: [0.64986324]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, batch_id: 20, loss is: [0.61736953]\r\n",
      "epoch: 1, batch_id: 30, loss is: [0.62518173]\r\n",
      "[validation] accuracy/loss: 0.9200000762939453/0.40356606245040894\r\n",
      "epoch: 2, batch_id: 0, loss is: [0.47684214]\r\n",
      "epoch: 2, batch_id: 10, loss is: [0.5038073]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, batch_id: 20, loss is: [0.35800314]\r\n",
      "epoch: 2, batch_id: 30, loss is: [0.33573705]\r\n",
      "[validation] accuracy/loss: 0.9200000762939453/0.25573059916496277\r\n",
      "epoch: 3, batch_id: 0, loss is: [0.31720468]\r\n",
      "epoch: 3, batch_id: 10, loss is: [0.1300174]\r\n",
      "epoch: 3, batch_id: 20, loss is: [0.37148193]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, batch_id: 30, loss is: [0.29787353]\r\n",
      "[validation] accuracy/loss: 0.9275000691413879/0.21195261180400848\r\n",
      "epoch: 4, batch_id: 0, loss is: [0.17336412]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, batch_id: 10, loss is: [0.2628278]\r\n",
      "epoch: 4, batch_id: 20, loss is: [0.30194184]\r\n",
      "epoch: 4, batch_id: 30, loss is: [0.63926095]\r\n",
      "[validation] accuracy/loss: 0.9125000238418579/0.2694101631641388\r\n"
     ]
    }
   ],
   "source": [
    "#创建储存vgg结果的日志文件夹\n",
    "log_writer = LogWriter(\"./log/vgg\")\n",
    "# 定义训练过程\n",
    "def train(model):\n",
    "    with fluid.dygraph.guard():\n",
    "        print('start training ... ')\n",
    "        model.train()\n",
    "        epoch_num = 5\n",
    "        iter=0\n",
    "        # 定义优化器\n",
    "        opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\n",
    "        # 定义数据读取器，训练数据读取器和验证数据读取器\n",
    "        train_loader = data_loader(DATADIR, batch_size=10, mode='train')\n",
    "        valid_loader = valid_data_loader(DATADIR2, CSVFILE)\n",
    "        for epoch in range(epoch_num):\n",
    "            for batch_id, data in enumerate(train_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                #将每一层输出的图片数据转成numpy array格式并写入日志文件\n",
    "                log_writer.add_image(tag='input_vgg/original', img=convert_out_img(conv[0][:,:4]), dataformats=\"NCHW\",step=batch_id)\n",
    "                log_writer.add_image(tag='input_vgg/vgg_blocks', img=convert_out_img(conv[1][:,:4]), dataformats=\"NCHW\",step=batch_id)\n",
    "                # log_writer.add_image(tag='input_vgg/fc1', img=convert_out_img(conv[2][:,:4]), dataformats=\"NCHW\",step=batch_id)\n",
    "                # log_writer.add_image(tag='input_vgg/fc2', img=convert_out_img(conv[3][:,:4]), dataformats=\"NCHW\",step=batch_id)\n",
    "                # log_writer.add_image(tag='input_vgg/fc3', img=convert_out_img(conv[4][:,:4]), dataformats=\"NCHW\",step=batch_id)\n",
    "                #计算accuracy\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                # 进行loss计算\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                #训练过程中插入作图语句，当每10个batch训练完成后，将当前损失、准确率作为一个新增的数据点储存到记录器中。\n",
    "                if batch_id % 10 == 0:\n",
    "                    log_writer.add_scalar(tag='train/acc', step=iter, value=acc.numpy())\n",
    "                    log_writer.add_scalar(tag='train/loss', step=iter, value=avg_loss.numpy())\n",
    "                    iter+=10\n",
    "                    print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "                # 反向传播，更新权重，清除梯度\n",
    "                avg_loss.backward()\n",
    "                opt.minimize(avg_loss)\n",
    "                model.clear_gradients()\n",
    "\n",
    "            model.eval()\n",
    "            accuracies = []\n",
    "            losses = []\n",
    "            for batch_id, data in enumerate(valid_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "                # 计算sigmoid后的预测概率，进行loss计算\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                # 计算预测概率小于0.5的类别\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                # 得到两个类别的预测概率，并沿第一个维度级联\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                accuracies.append(acc.numpy())\n",
    "                losses.append(loss.numpy())\n",
    "            print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "            model.train()\n",
    "\n",
    "        # save params of model\n",
    "        fluid.save_dygraph(model.state_dict(), 'mnist')\n",
    "        # save optimizer state\n",
    "        fluid.save_dygraph(opt.state_dict(), 'mnist')\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    model = VGG()\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**运行结束后，有两种选择**\n",
    "- 可选择直接启动VisualDL面板查看AlexNet、LeNet和VGG的accuracy和loss对比\n",
    "- 继续训练以下模型，所有模型训练完成后再启动VisualDL查看不同模型的训练效果对比。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化第三组实验--使用GoogleNet网络进行眼疾分类\n",
    "\n",
    "- Inception模块的具体实现如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T15:01:04.866414Z",
     "iopub.status.busy": "2022-12-01T15:01:04.865635Z",
     "iopub.status.idle": "2022-12-01T15:01:04.875042Z",
     "shell.execute_reply": "2022-12-01T15:01:04.874367Z",
     "shell.execute_reply.started": "2022-12-01T15:01:04.866378Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Inception(fluid.dygraph.Layer):\n",
    "    def __init__(self, c1, c2, c3, c4, **kwargs):\n",
    "        '''\n",
    "        Inception模块的实现代码，\n",
    "        \n",
    "        c1,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        c2，图(b)中第二条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c2[0]是1x1卷积的输出通道数，c2[1]是3x3\n",
    "        c3，图(b)中第三条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c3[0]是1x1卷积的输出通道数，c3[1]是3x3\n",
    "        c4,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        '''\n",
    "        super(Inception, self).__init__()\n",
    "        # 依次创建Inception块每条支路上使用到的操作\n",
    "        self.p1_1 = Conv2D(num_filters=c1, \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_1 = Conv2D(num_filters=c2[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_2 = Conv2D(num_filters=c2[1], \n",
    "                           filter_size=3, padding=1, act='relu')\n",
    "        self.p3_1 = Conv2D(num_filters=c3[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p3_2 = Conv2D(num_filters=c3[1], \n",
    "                           filter_size=5, padding=2, act='relu')\n",
    "        self.p4_1 = Pool2D(pool_size=3, \n",
    "                           pool_stride=1,  pool_padding=1, \n",
    "                           pool_type='max')\n",
    "        self.p4_2 = Conv2D(num_filters=c4, \n",
    "                           filter_size=1, act='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 支路1只包含一个1x1卷积\n",
    "        p1 = self.p1_1(x)\n",
    "        # 支路2包含 1x1卷积 + 3x3卷积\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        # 支路3包含 1x1卷积 + 5x5卷积\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        # 支路4包含 最大池化和1x1卷积\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # 将每个支路的输出特征图拼接在一起作为最终的输出结果\n",
    "        return fluid.layers.concat([p1, p2, p3, p4], axis=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GoogLeNet的具体实现如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T15:01:08.252087Z",
     "iopub.status.busy": "2022-12-01T15:01:08.251740Z",
     "iopub.status.idle": "2022-12-01T15:01:08.270733Z",
     "shell.execute_reply": "2022-12-01T15:01:08.270097Z",
     "shell.execute_reply.started": "2022-12-01T15:01:08.252062Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# GoogLeNet模型代码\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.layer_helper import LayerHelper\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "\n",
    "# 定义Inception块\n",
    "class Inception(fluid.dygraph.Layer):\n",
    "    def __init__(self, c0,c1, c2, c3, c4, **kwargs):\n",
    "        '''\n",
    "        Inception模块的实现代码，\n",
    "        \n",
    "        c1,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        c2，图(b)中第二条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c2[0]是1x1卷积的输出通道数，c2[1]是3x3\n",
    "        c3，图(b)中第三条支路卷积的输出通道数，数据类型是tuple或list, \n",
    "               其中c3[0]是1x1卷积的输出通道数，c3[1]是3x3\n",
    "        c4,  图(b)中第一条支路1x1卷积的输出通道数，数据类型是整数\n",
    "        '''\n",
    "        super(Inception, self).__init__()\n",
    "        # 依次创建Inception块每条支路上使用到的操作\n",
    "        self.p1_1 = Conv2D(num_channels=c0, num_filters=c1, \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_1 = Conv2D(num_channels=c0, num_filters=c2[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p2_2 = Conv2D(num_channels=c2[0], num_filters=c2[1], \n",
    "                           filter_size=3, padding=1, act='relu')\n",
    "        self.p3_1 = Conv2D(num_channels=c0, num_filters=c3[0], \n",
    "                           filter_size=1, act='relu')\n",
    "        self.p3_2 = Conv2D(num_channels=c3[0], num_filters=c3[1], \n",
    "                           filter_size=5, padding=2, act='relu')\n",
    "        self.p4_1 = Pool2D(pool_size=3, \n",
    "                           pool_stride=1,  pool_padding=1, \n",
    "                           pool_type='max')\n",
    "        self.p4_2 = Conv2D(num_channels=c0, num_filters=c4, \n",
    "                           filter_size=1, act='relu')\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 支路1只包含一个1x1卷积\n",
    "        p1 = self.p1_1(x)\n",
    "        # 支路2包含 1x1卷积 + 3x3卷积\n",
    "        p2 = self.p2_2(self.p2_1(x))\n",
    "        # 支路3包含 1x1卷积 + 5x5卷积\n",
    "        p3 = self.p3_2(self.p3_1(x))\n",
    "        # 支路4包含 最大池化和1x1卷积\n",
    "        p4 = self.p4_2(self.p4_1(x))\n",
    "        # 将每个支路的输出特征图拼接在一起作为最终的输出结果\n",
    "        return fluid.layers.concat([p1, p2, p3, p4], axis=1)  \n",
    "    \n",
    "class GoogLeNet(fluid.dygraph.Layer):\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        # GoogLeNet包含五个模块，每个模块后面紧跟一个池化层\n",
    "        # 第一个模块包含1个卷积层\n",
    "        self.conv1 = Conv2D(num_channels=3, num_filters=64, filter_size=7, \n",
    "                            padding=3, act='relu')\n",
    "        # 3x3最大池化\n",
    "        self.pool1 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                            pool_padding=1, pool_type='max')\n",
    "        # 第二个模块包含2个卷积层\n",
    "        self.conv2_1 = Conv2D(num_channels=64, num_filters=64, \n",
    "                              filter_size=1, act='relu')\n",
    "        self.conv2_2 = Conv2D(num_channels=64, num_filters=192, \n",
    "                              filter_size=3, padding=1, act='relu')\n",
    "        # 3x3最大池化\n",
    "        self.pool2 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                            pool_padding=1, pool_type='max')\n",
    "        # 第三个模块包含2个Inception块\n",
    "        self.block3_1 = Inception(192, 64, (96, 128), (16, 32), 32)\n",
    "        self.block3_2 = Inception(256, 128, (128, 192), (32, 96), 64)\n",
    "        # 3x3最大池化\n",
    "        self.pool3 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                               pool_padding=1, pool_type='max')\n",
    "        # 第四个模块包含5个Inception块\n",
    "        self.block4_1 = Inception(480, 192, (96, 208), (16, 48), 64)\n",
    "        self.block4_2 = Inception(512, 160, (112, 224), (24, 64), 64)\n",
    "        self.block4_3 = Inception(512, 128, (128, 256), (24, 64), 64)\n",
    "        self.block4_4 = Inception(512, 112, (144, 288), (32, 64), 64)\n",
    "        self.block4_5 = Inception(528, 256, (160, 320), (32, 128), 128)\n",
    "        # 3x3最大池化\n",
    "        self.pool4 = Pool2D(pool_size=3, pool_stride=2,  \n",
    "                               pool_padding=1, pool_type='max')\n",
    "        # 第五个模块包含2个Inception块\n",
    "        self.block5_1 = Inception(832, 256, (160, 320), (32, 128), 128)\n",
    "        self.block5_2 = Inception(832, 384, (192, 384), (48, 128), 128)\n",
    "        # 全局池化，尺寸用的是global_pooling，pool_stride不起作用\n",
    "        self.pool5 = Pool2D(pool_stride=1, \n",
    "                               global_pooling=True, pool_type='avg')\n",
    "        self.fc = Linear(input_dim=1024, output_dim=1, act=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.pool1(self.conv1(x))\n",
    "        x2 = self.pool2(self.conv2_2(self.conv2_1(x1)))\n",
    "        x3 = self.pool3(self.block3_2(self.block3_1(x2)))\n",
    "        x4 = self.block4_3(self.block4_2(self.block4_1(x3)))\n",
    "        x5 = self.pool4(self.block4_5(self.block4_4(x4)))\n",
    "        x6 = self.pool5(self.block5_2(self.block5_1(x5)))\n",
    "        x7 = fluid.layers.reshape(x6, [x6.shape[0], -1])\n",
    "        x8 = self.fc(x7)\n",
    "        conv=[x,x1,x2,x3,x4,x5,x6,x7,x8]\n",
    "        return x8,conv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型并使用VisualDL可视化训练参数及数据样本\n",
    "- 创建GoogleNet日志文件，以便对比其他模型训练参数，代码如下：\n",
    "\n",
    "log_writer = LogWriter(\"./log/googlenet\")\n",
    "\n",
    "- 训练过程中插入作图语句，展示accuracy和loss的变化趋势：\n",
    "\n",
    "log_writer.add_scalar(tag='acc', step=iter, value=acc.numpy())\n",
    "\n",
    "log_writer.add_scalar(tag='loss', step=iter, value=avg_loss.numpy())\n",
    "\n",
    "- 设计网络向前计算过程时，将每一层的输出储存于名为'conv'的list中，方便后续写入日志文件\n",
    "\n",
    "- 训练过程中插入作图语句，展示输入图片在每一层网络的输出\n",
    "\n",
    "log_writer.add_image(tag='input_googlenet/pool_1', img=conv[0].numpy(), step=batch_id)\n",
    "\n",
    "***注意使用相同tag才能实现多组模型实验对比**\n",
    "\n",
    "#### 完整训练及可视化代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T15:01:45.697388Z",
     "iopub.status.busy": "2022-12-01T15:01:45.696661Z",
     "iopub.status.idle": "2022-12-01T15:06:06.810148Z",
     "shell.execute_reply": "2022-12-01T15:06:06.809059Z",
     "shell.execute_reply.started": "2022-12-01T15:01:45.697356Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \r\n",
      "epoch: 0, batch_id: 0, loss is: [0.75418067]\r\n",
      "epoch: 0, batch_id: 10, loss is: [0.7037188]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 20, loss is: [0.6713807]\r\n",
      "epoch: 0, batch_id: 30, loss is: [0.65968716]\r\n",
      "[validation] accuracy/loss: 0.550000011920929/0.6173955798149109\r\n",
      "epoch: 1, batch_id: 0, loss is: [0.5912618]\r\n",
      "epoch: 1, batch_id: 10, loss is: [0.63442963]\r\n",
      "epoch: 1, batch_id: 20, loss is: [0.884045]\r\n",
      "epoch: 1, batch_id: 30, loss is: [0.6811533]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[validation] accuracy/loss: 0.8575000762939453/0.43541648983955383\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, batch_id: 0, loss is: [0.45489442]\r\n",
      "epoch: 2, batch_id: 10, loss is: [0.38237202]\r\n",
      "epoch: 2, batch_id: 20, loss is: [0.53658324]\r\n",
      "epoch: 2, batch_id: 30, loss is: [1.0337268]\r\n",
      "[validation] accuracy/loss: 0.8700000047683716/0.5773341655731201\r\n",
      "epoch: 3, batch_id: 0, loss is: [0.5977422]\r\n",
      "epoch: 3, batch_id: 10, loss is: [0.7324745]\r\n",
      "epoch: 3, batch_id: 20, loss is: [0.592078]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, batch_id: 30, loss is: [0.33997554]\r\n",
      "[validation] accuracy/loss: 0.9125000238418579/0.3259984850883484\r\n",
      "epoch: 4, batch_id: 0, loss is: [0.17838205]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, batch_id: 10, loss is: [0.21453923]\r\n",
      "epoch: 4, batch_id: 20, loss is: [0.24832763]\r\n",
      "epoch: 4, batch_id: 30, loss is: [0.6171415]\r\n",
      "[validation] accuracy/loss: 0.8324999809265137/0.41865235567092896\r\n"
     ]
    }
   ],
   "source": [
    "#创建储存googlenet结果的日志文件夹\n",
    "log_writer = LogWriter(\"./log/googlenet\")\n",
    "# 定义训练过程\n",
    "def train(model):\n",
    "    with fluid.dygraph.guard():\n",
    "        print('start training ... ')\n",
    "        model.train()\n",
    "        epoch_num = 5\n",
    "        iter=0\n",
    "        # 定义优化器\n",
    "        opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\n",
    "        # 定义数据读取器，训练数据读取器和验证数据读取器\n",
    "        train_loader = data_loader(DATADIR, batch_size=10, mode='train')\n",
    "        valid_loader = valid_data_loader(DATADIR2, CSVFILE)\n",
    "        for epoch in range(epoch_num):\n",
    "            for batch_id, data in enumerate(train_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                #将每一层输出的图片数据转成numpy array格式并写入日志文件\n",
    "                log_writer.add_image(tag='input_googlenet/original', img=convert_out_img(conv[0]), dataformats=\"NCHW\",step=batch_id)\n",
    "                log_writer.add_image(tag='input_googlenet/pool_1', img=convert_out_img(conv[1][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_googlenet/pool_2', img=convert_out_img(conv[2][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_googlenet/pool_3', img=convert_out_img(conv[3][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_googlenet/block4_3', img=convert_out_img(conv[4][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_googlenet/pool_4', img=convert_out_img(conv[5][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                log_writer.add_image(tag='input_googlenet/pool_5', img=convert_out_img(conv[6][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                # log_writer.add_image(tag='input_googlenet/reshape', img=convert_out_img(conv[7][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                # log_writer.add_image(tag='input_googlenet/fc', img=convert_out_img(conv[8][:,:4]), dataformats=\"NCHW\", step=batch_id)\n",
    "                #计算accuracy\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                # 进行loss计算\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                #训练过程中插入作图语句，当每10个batch训练完成后，将当前损失、准确率作为一个新增的数据点储存到记录器中。\n",
    "                if batch_id % 10 == 0:\n",
    "                    log_writer.add_scalar(tag='train/acc', step=iter, value=acc.numpy())\n",
    "                    log_writer.add_scalar(tag='train/loss', step=iter, value=avg_loss.numpy())\n",
    "                    iter+=10\n",
    "                    print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "                # 反向传播，更新权重，清除梯度\n",
    "                avg_loss.backward()\n",
    "                opt.minimize(avg_loss)\n",
    "                model.clear_gradients()\n",
    "\n",
    "            model.eval()\n",
    "            accuracies = []\n",
    "            losses = []\n",
    "            for batch_id, data in enumerate(valid_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "                # 计算sigmoid后的预测概率，进行loss计算\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                # 计算预测概率小于0.5的类别\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                # 得到两个类别的预测概率，并沿第一个维度级联\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                accuracies.append(acc.numpy())\n",
    "                losses.append(loss.numpy())\n",
    "            print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "            model.train()\n",
    "\n",
    "        # save params of model\n",
    "        fluid.save_dygraph(model.state_dict(), 'mnist')\n",
    "        # save optimizer state\n",
    "        fluid.save_dygraph(opt.state_dict(), 'mnist')\n",
    "\n",
    "\n",
    "with fluid.dygraph.guard():\n",
    "    model = GoogLeNet()\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**运行结束后，有两种选择**\n",
    "- 可选择直接启动VisualDL面板查看AlexNet、LeNet、VGG和GoogleNet的accuracy和loss对比\n",
    "- 继续训练以下模型，所有模型训练完成后再启动VisualDL查看不同模型的训练效果对比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化第三组实验--使用ResNet网络进行眼疾分类\n",
    "\n",
    "- ResNet-50的具体实现如下代码所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T15:08:48.226542Z",
     "iopub.status.busy": "2022-12-01T15:08:48.226194Z",
     "iopub.status.idle": "2022-12-01T15:08:48.246548Z",
     "shell.execute_reply": "2022-12-01T15:08:48.245909Z",
     "shell.execute_reply.started": "2022-12-01T15:08:48.226519Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "# ResNet模型代码\n",
    "import numpy as np\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.layer_helper import LayerHelper\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, BatchNorm, Linear\n",
    "from paddle.fluid.dygraph.base import to_variable\n",
    "\n",
    "# ResNet中使用了BatchNorm层，在卷积层的后面加上BatchNorm以提升数值稳定性\n",
    "# 定义卷积批归一化块\n",
    "class ConvBNLayer(fluid.dygraph.Layer):\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 num_filters,\n",
    "                 filter_size,\n",
    "                 stride=1,\n",
    "                 groups=1,\n",
    "                 act=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        num_channels, 卷积层的输入通道数\n",
    "        num_filters, 卷积层的输出通道数\n",
    "        stride, 卷积层的步幅\n",
    "        groups, 分组卷积的组数，默认groups=1不使用分组卷积\n",
    "        act, 激活函数类型，默认act=None不使用激活函数\n",
    "        \"\"\"\n",
    "        super(ConvBNLayer, self).__init__()\n",
    "\n",
    "        # 创建卷积层\n",
    "        self._conv = Conv2D(\n",
    "            num_channels=num_channels,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=filter_size,\n",
    "            stride=stride,\n",
    "            padding=(filter_size - 1) // 2,\n",
    "            groups=groups,\n",
    "            act=None,\n",
    "            bias_attr=False)\n",
    "\n",
    "        # 创建BatchNorm层\n",
    "        self._batch_norm = BatchNorm(num_filters, act=act)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self._conv(inputs)\n",
    "        y = self._batch_norm(y)\n",
    "        return y\n",
    "\n",
    "# 定义残差块\n",
    "# 每个残差块会对输入图片做三次卷积，然后跟输入图片进行短接\n",
    "# 如果残差块中第三次卷积输出特征图的形状与输入不一致，则对输入图片做1x1卷积，将其输出形状调整成一致\n",
    "class BottleneckBlock(fluid.dygraph.Layer):\n",
    "    def __init__(self,\n",
    "                 num_channels,\n",
    "                 num_filters,\n",
    "                 stride,\n",
    "                 shortcut=True):\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        # 创建第一个卷积层 1x1\n",
    "        self.conv0 = ConvBNLayer(\n",
    "            num_channels=num_channels,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=1,\n",
    "            act='relu')\n",
    "        # 创建第二个卷积层 3x3\n",
    "        self.conv1 = ConvBNLayer(\n",
    "            num_channels=num_filters,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=3,\n",
    "            stride=stride,\n",
    "            act='relu')\n",
    "        # 创建第三个卷积 1x1，但输出通道数乘以4\n",
    "        self.conv2 = ConvBNLayer(\n",
    "            num_channels=num_filters,\n",
    "            num_filters=num_filters * 4,\n",
    "            filter_size=1,\n",
    "            act=None)\n",
    "\n",
    "        # 如果conv2的输出跟此残差块的输入数据形状一致，则shortcut=True\n",
    "        # 否则shortcut = False，添加1个1x1的卷积作用在输入数据上，使其形状变成跟conv2一致\n",
    "        if not shortcut:\n",
    "            self.short = ConvBNLayer(\n",
    "                num_channels=num_channels,\n",
    "                num_filters=num_filters * 4,\n",
    "                filter_size=1,\n",
    "                stride=stride)\n",
    "\n",
    "        self.shortcut = shortcut\n",
    "\n",
    "        self._num_channels_out = num_filters * 4\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        y = self.conv0(inputs)\n",
    "        conv1 = self.conv1(y)\n",
    "        conv2 = self.conv2(conv1)\n",
    "\n",
    "        # 如果shortcut=True，直接将inputs跟conv2的输出相加\n",
    "        # 否则需要对inputs进行一次卷积，将形状调整成跟conv2输出一致\n",
    "        if self.shortcut:\n",
    "            short = inputs\n",
    "        else:\n",
    "            short = self.short(inputs)\n",
    "\n",
    "        y = fluid.layers.elementwise_add(x=short, y=conv2)\n",
    "        layer_helper = LayerHelper(self.full_name(), act='relu')\n",
    "        return layer_helper.append_activation(y)\n",
    "\n",
    "# 定义ResNet模型\n",
    "class ResNet(fluid.dygraph.Layer):\n",
    "    def __init__(self, layers=50, class_dim=1):\n",
    "        \"\"\"\n",
    "        \n",
    "        layers, 网络层数，可以是50, 101或者152\n",
    "        class_dim，分类标签的类别数\n",
    "        \"\"\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.layers = layers\n",
    "        supported_layers = [50, 101, 152]\n",
    "        assert layers in supported_layers, \\\n",
    "            \"supported layers are {} but input layer is {}\".format(supported_layers, layers)\n",
    "\n",
    "        if layers == 50:\n",
    "            #ResNet50包含多个模块，其中第2到第5个模块分别包含3、4、6、3个残差块\n",
    "            depth = [3, 4, 6, 3]\n",
    "        elif layers == 101:\n",
    "            #ResNet101包含多个模块，其中第2到第5个模块分别包含3、4、23、3个残差块\n",
    "            depth = [3, 4, 23, 3]\n",
    "        elif layers == 152:\n",
    "            #ResNet50包含多个模块，其中第2到第5个模块分别包含3、8、36、3个残差块\n",
    "            depth = [3, 8, 36, 3]\n",
    "        \n",
    "        # 残差块中使用到的卷积的输出通道数\n",
    "        num_filters = [64, 128, 256, 512]\n",
    "\n",
    "        # ResNet的第一个模块，包含1个7x7卷积，后面跟着1个最大池化层\n",
    "        self.conv = ConvBNLayer(\n",
    "            num_channels=3,\n",
    "            num_filters=64,\n",
    "            filter_size=7,\n",
    "            stride=2,\n",
    "            act='relu')\n",
    "        self.pool2d_max = Pool2D(\n",
    "            pool_size=3,\n",
    "            pool_stride=2,\n",
    "            pool_padding=1,\n",
    "            pool_type='max')\n",
    "\n",
    "        # ResNet的第二到第五个模块c2、c3、c4、c5\n",
    "        self.bottleneck_block_list = []\n",
    "        num_channels = 64\n",
    "        for block in range(len(depth)):\n",
    "            shortcut = False\n",
    "            for i in range(depth[block]):\n",
    "                bottleneck_block = self.add_sublayer(\n",
    "                    'bb_%d_%d' % (block, i),\n",
    "                    BottleneckBlock(\n",
    "                        num_channels=num_channels,\n",
    "                        num_filters=num_filters[block],\n",
    "                        stride=2 if i == 0 and block != 0 else 1, # c3、c4、c5将会在第一个残差块使用stride=2；其余所有残差块stride=1\n",
    "                        shortcut=shortcut))\n",
    "                num_channels = bottleneck_block._num_channels_out\n",
    "                self.bottleneck_block_list.append(bottleneck_block)\n",
    "                shortcut = True\n",
    "\n",
    "        # 在c5的输出特征图上使用全局池化\n",
    "        self.pool2d_avg = Pool2D(pool_size=7, pool_type='avg', global_pooling=True)\n",
    "\n",
    "        # stdv用来作为全连接层随机初始化参数的方差\n",
    "        import math\n",
    "        stdv = 1.0 / math.sqrt(2048 * 1.0)\n",
    "        \n",
    "        # 创建全连接层，输出大小为类别数目\n",
    "        self.out = Linear(input_dim=2048, output_dim=class_dim,\n",
    "                      param_attr=fluid.param_attr.ParamAttr(\n",
    "                          initializer=fluid.initializer.Uniform(-stdv, stdv)))\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        y = self.conv(inputs)\n",
    "        y = self.pool2d_max(y)\n",
    "        for bottleneck_block in self.bottleneck_block_list:\n",
    "            y = bottleneck_block(y)\n",
    "        y1 = self.pool2d_avg(y)\n",
    "        y2 = fluid.layers.reshape(y1, [y1.shape[0], -1])\n",
    "        y3 = self.out(y2)\n",
    "        conv=[inputs,y,y1,y2,y3]\n",
    "        return y3,conv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型并使用VisualDL可视化训练参数及数据样本\n",
    "- 创建ResNet日志文件，以便对比其他模型训练参数，代码如下：\n",
    "\n",
    "log_writer = LogWriter(\"./log/resenet\")\n",
    "\n",
    "- 训练过程中插入作图语句，展示accuracy和loss的变化趋势：\n",
    "\n",
    "log_writer.add_scalar(tag='acc', step=iter, value=acc.numpy())\n",
    "\n",
    "log_writer.add_scalar(tag='loss', step=iter, value=avg_loss.numpy())\n",
    "\n",
    "- 设计网络向前计算过程时，将每一层的输出储存于名为'conv'的list中，方便后续写入日志文件\n",
    "\n",
    "- 训练过程中插入作图语句，展示输入图片在每一层网络的输出\n",
    "\n",
    "log_writer.add_image(tag='input_resnet/pool2d_avg', img=conv[0].numpy(), step=batch_id)\n",
    "\n",
    "***注意使用相同tag才能实现多组模型实验对比**\n",
    "\n",
    "#### 完整训练及可视化代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2022-12-01T15:10:54.827199Z",
     "iopub.status.busy": "2022-12-01T15:10:54.826675Z",
     "iopub.status.idle": "2022-12-01T15:15:13.863792Z",
     "shell.execute_reply": "2022-12-01T15:15:13.862757Z",
     "shell.execute_reply.started": "2022-12-01T15:10:54.827161Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training ... \r\n",
      "epoch: 0, batch_id: 0, loss is: [0.6848939]\r\n",
      "epoch: 0, batch_id: 10, loss is: [0.722348]\r\n",
      "epoch: 0, batch_id: 20, loss is: [0.69279873]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch_id: 30, loss is: [0.6632378]\r\n",
      "[validation] accuracy/loss: 0.7400000095367432/0.5463799834251404\r\n",
      "epoch: 1, batch_id: 0, loss is: [0.6896794]\r\n",
      "epoch: 1, batch_id: 10, loss is: [0.5407681]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, batch_id: 20, loss is: [0.41758567]\r\n",
      "epoch: 1, batch_id: 30, loss is: [0.4623827]\r\n",
      "[validation] accuracy/loss: 0.875/0.3386470675468445\r\n",
      "epoch: 2, batch_id: 0, loss is: [0.2210343]\r\n",
      "epoch: 2, batch_id: 10, loss is: [0.304076]\r\n",
      "epoch: 2, batch_id: 20, loss is: [0.2317107]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, batch_id: 30, loss is: [0.24433315]\r\n",
      "[validation] accuracy/loss: 0.9475000500679016/0.19909973442554474\r\n",
      "epoch: 3, batch_id: 0, loss is: [0.26255694]\r\n",
      "epoch: 3, batch_id: 10, loss is: [0.7900493]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, batch_id: 20, loss is: [0.1531486]\r\n",
      "epoch: 3, batch_id: 30, loss is: [0.25372422]\r\n",
      "[validation] accuracy/loss: 0.9225000143051147/0.23160284757614136\r\n",
      "epoch: 4, batch_id: 0, loss is: [0.21286654]\r\n",
      "epoch: 4, batch_id: 10, loss is: [0.25417072]\r\n",
      "epoch: 4, batch_id: 20, loss is: [0.24430172]\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Premature end of JPEG file\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, batch_id: 30, loss is: [0.358006]\r\n",
      "[validation] accuracy/loss: 0.8899999856948853/0.2840989828109741\r\n"
     ]
    }
   ],
   "source": [
    "#创建储存resnet结果的日志文件夹\n",
    "log_writer = LogWriter(\"./log/resnet\")\n",
    "# 定义训练过程\n",
    "def train(model):\n",
    "    with fluid.dygraph.guard():\n",
    "        print('start training ... ')\n",
    "        model.train()\n",
    "        epoch_num = 5\n",
    "        iter=0\n",
    "        # 定义优化器\n",
    "        opt = fluid.optimizer.Momentum(learning_rate=0.001, momentum=0.9, parameter_list=model.parameters())\n",
    "        # 定义数据读取器，训练数据读取器和验证数据读取器\n",
    "        train_loader = data_loader(DATADIR, batch_size=10, mode='train')\n",
    "        valid_loader = valid_data_loader(DATADIR2, CSVFILE)\n",
    "        for epoch in range(epoch_num):\n",
    "            for batch_id, data in enumerate(train_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                #将每一层输出的图片数据转成numpy array格式并写入日志文件\n",
    "                log_writer.add_image(tag='input_resnet/original', img=convert_out_img(conv[0]),dataformats=\"NCHW\",step=batch_id)\n",
    "                log_writer.add_image(tag='input_resnet/pool2d_avg', img=convert_out_img(conv[1][:,:4]),dataformats=\"NCHW\",step=batch_id)\n",
    "                # log_writer.add_image(tag='input_resnet/reshape', img=convert_out_img(conv[2][:,:4]),dataformats=\"NCHW\", step=batch_id)\n",
    "                # log_writer.add_image(tag='input_resnet/output', img=convert_out_img(conv[3][:,:4]),dataformats=\"NCHW\", step=batch_id)\n",
    "                #计算accuracy\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                # 进行loss计算\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                #训练过程中插入作图语句，当每10个batch训练完成后，将当前损失、准确率作为一个新增的数据点储存到记录器中。\n",
    "                if batch_id % 10 == 0:\n",
    "                    log_writer.add_scalar(tag='train/acc', step=iter, value=acc.numpy())\n",
    "                    log_writer.add_scalar(tag='train/loss', step=iter, value=avg_loss.numpy())\n",
    "                    iter+=10\n",
    "                    print(\"epoch: {}, batch_id: {}, loss is: {}\".format(epoch, batch_id, avg_loss.numpy()))\n",
    "                # 反向传播，更新权重，清除梯度\n",
    "                avg_loss.backward()\n",
    "                opt.minimize(avg_loss)\n",
    "                model.clear_gradients()\n",
    "\n",
    "            model.eval()\n",
    "            accuracies = []\n",
    "            losses = []\n",
    "            for batch_id, data in enumerate(valid_loader()):\n",
    "                x_data, y_data = data\n",
    "                img = fluid.dygraph.to_variable(x_data)\n",
    "                label = fluid.dygraph.to_variable(y_data)\n",
    "                # 运行模型前向计算，得到预测值\n",
    "                logits,conv = model(img)\n",
    "                # 二分类，sigmoid计算后的结果以0.5为阈值分两个类别\n",
    "                # 计算sigmoid后的预测概率，进行loss计算\n",
    "                pred = fluid.layers.sigmoid(logits)\n",
    "                loss = fluid.layers.sigmoid_cross_entropy_with_logits(logits, label)\n",
    "                avg_loss = fluid.layers.mean(loss)\n",
    "                # 计算预测概率小于0.5的类别\n",
    "                pred2 = pred * (-1.0) + 1.0\n",
    "                # 得到两个类别的预测概率，并沿第一个维度级联\n",
    "                pred = fluid.layers.concat([pred2, pred], axis=1)\n",
    "                acc = fluid.layers.accuracy(pred, fluid.layers.cast(label, dtype='int64'))\n",
    "                accuracies.append(acc.numpy())\n",
    "                losses.append(loss.numpy())\n",
    "            print(\"[validation] accuracy/loss: {}/{}\".format(np.mean(accuracies), np.mean(losses)))\n",
    "            model.train()\n",
    "\n",
    "        # save params of model\n",
    "        fluid.save_dygraph(model.state_dict(), 'mnist')\n",
    "        # save optimizer state\n",
    "        fluid.save_dygraph(opt.state_dict(), 'mnist')\n",
    "with fluid.dygraph.guard():\n",
    "    model = ResNet()\n",
    "\n",
    "train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**至此，所有模型训练完毕，启动VisuaDL查看模型训练参数对比**\n",
    "\n",
    "对比五个模型的Accuracy和Loss：\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/671fac7e91e84d8a947db56ed70f9e7d78e5c248d4a4467e839975f1b74c99f2)\n",
    "\n",
    "\n",
    "通过对比，我们可以发现：\n",
    "\n",
    "- LeNet的loss很难下降，模型没有收敛。\n",
    "- AlexNet的loss能有效下降，经过5个epoch的训练，在训练集上的准确率可以达到92%左右。\n",
    "- VGG的loss能有效下降，经过5个epoch的训练，在训练集上的准确率可以达到94%左右\n",
    "- GoogleNet的loss能有效下降，经过5个epoch的训练，在训练集上的准确率可以达到96%左右\n",
    "- ResNet的loss能有效下降，经过5个epoch的训练，在训练集上的准确率可以达到98%左右\n",
    "\n",
    "除了LeNet不适合大尺寸的图像分类问题之外，其它几个模型在此数据集上损失函数都能显著下降，如果读者有兴趣的话，可以进一步调整学习率和训练轮数等超参数，使用VisualDL记录这些参数，观察其对模型精度的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**启动VisualDL查看输入图片在训练过程中的变化**\n",
    "\n",
    "- 查看不同迭代次数训练下的图片数据\n",
    "\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/4e78a9f53f3c4256beabdf13f66739d343db636cd1274b939f9f3694d34437cb)\n",
    "\n",
    "- 查看输入图片经过每一层网络训练的输出：\n",
    "\t* 输入图片经过LeNet网络第一层池化（左图）和第二层卷积（右图）：\n",
    "    ![](https://ai-studio-static-online.cdn.bcebos.com/d051e48e98534560af58d897b16c3b2e36de282b7a8d410687d4b41b5a09ba20)\n",
    "    \n",
    "    * 输入图片经过AlexNet网络第一层池化（左图）和第二层卷积（右图）：\n",
    "    ![](https://ai-studio-static-online.cdn.bcebos.com/7379218091a24f4284eeaebc76c9348ce602538695344305815d1475b212ef1d)\n",
    "\n",
    "通过观察图片随训练的变化，我们可以直观的看到每一层网络对于图片的影响，进而辅助我们改善模型结构的设计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 总结\n",
    "\n",
    "本项目为读者介绍了如何使用VisualDL可视化训练参数、图像数据，以及对比五种经典的图像分类模型的在眼疾筛查数据集上的训练效果。\n",
    "\n",
    "- 创建日志文件记录：使用LogWriter()并明确文件路径\n",
    "- 训练参数实时可视化：使用add_scalar()并明确参数名称以及值\n",
    "- 多组实验对比：创建多组子日志文件，如\n",
    "\t* 'log/lenet'\n",
    "    * 'log/alexnet'\n",
    "    \n",
    "    * 'log/vgg'\n",
    "    \n",
    "\t* 'log/googlenet'\n",
    "    \n",
    "    * 'log/resnet'\n",
    "    \n",
    "      接着在写入数据时，同一类参数使用统一tag名称写入即可\n",
    "    \n",
    "- 图像数据训练过程可视化：\n",
    "\t* 导出每一层网络的输出图片，并存入一个'list'，后续写入日志文件实现可视化\n",
    "    * 使用add_image()并明确图片名称、图片数据（array格式）、所处迭代次数\n",
    "\n",
    "\n",
    "\n",
    "详细说明请参考[使用指南](https://github.com/PaddlePaddle/VisualDL/blob/develop/docs/components/README.md)\n",
    "\n",
    "欢迎[加入VisualDL官方QQ群](https://jq.qq.com/?_wv=1027&k=TyzyVT4C)：1045783368\n",
    "\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/830248838e5c4d159b2496d6f4cc2eaa65377984f69a4cd086729e37f75f0954\" width = \"200\" height = \"100\" align=center />\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
